{"./":{"url":"./","title":"RabbitMQ中文文档","keywords":"","body":"RabbitMQ 中文文档 欢迎大家在 GitHub项目 中参与文档翻译。 "},"description.html":{"url":"description.html","title":"RabbitMQ能为你做些什么？","keywords":"","body":"RabbitMQ能为你做些什么？ 消息系统允许软件、应用相互连接和扩展．这些应用可以相互链接起来组成一个更大的应用，或者将用户设备和数据进行连接．消息系统通过将消息的发送和接收分离来实现应用程序的异步和解偶． 或许你正在考虑进行数据投递，非阻塞操作或推送通知。或许你想要实现发布／订阅，异步处理，或者工作队列。所有这些都可以通过消息系统实现。 RabbitMQ是一个消息代理 - 一个消息系统的媒介。它可以为你的应用提供一个通用的消息发送和接收平台，并且保证消息在传输过程中的安全。 技术亮点 可靠性 RabbitMQ提供了多种技术可以让你在性能和可靠性之间进行权衡。这些技术包括持久性机制、投递确认、发布者证实和高可用性机制。 灵活的路由 消息在到达队列前是通过交换机进行路由的。RabbitMQ为典型的路由逻辑提供了多种内置交换机类型。如果你有更复杂的路由需求，可以将这些交换机组合起来使用，你甚至可以实现自己的交换机类型，并且当做RabbitMQ的插件来使用。 集群 在相同局域网中的多个RabbitMQ服务器可以聚合在一起，作为一个独立的逻辑代理来使用。 联合 对于服务器来说，它比集群需要更多的松散和非可靠链接。为此RabbitMQ提供了联合模型。 高可用的队列 在同一个集群里，队列可以被镜像到多个机器中，以确保当其中某些硬件出现故障后，你的消息仍然安全。 多协议 RabbitMQ 支持多种消息协议的消息传递。 广泛的客户端 只要是你能想到的编程语言几乎都有与其相适配的RabbitMQ客户端。 可视化管理工具 RabbitMQ附带了一个易于使用的可视化管理工具，它可以帮助你监控消息代理的每一个环节。 追踪 如果你的消息系统有异常行为，RabbitMQ还提供了追踪的支持，让你能够发现问题所在。 插件系统 RabbitMQ附带了各种各样的插件来对自己进行扩展。你甚至也可以写自己的插件来使用。 还有什么呢... 商业支持 可以提供商业支持，包括培训和咨询。 大型社区 围绕着RabbitMQ有一个大型的社区，那儿有着各种各样的客户端、插件、指南等等。快加入我们的邮件列表参与其中吧！ "},"installation/Installing_on_Debian_Ubuntu.html":{"url":"installation/Installing_on_Debian_Ubuntu.html","title":"在Debian及Ubuntu系统上进行安装","keywords":"","body":" 原文：Installing on Debian / Ubuntu状态：校对完成翻译：Ping校对：Ping 安装到 Debian / Ubuntu 系统中 下载服服务器 Description Download Packaged as .deb for Debian-based Linux rabbitmq-server_3.4.3-1_all.deb (Signature) 自Debian since 6.0 (squeeze) 和 Ubuntu 9.04 之后，rabbitmq-server就已经被内置其中了。然而这些被包含在内的版本往往过低。所以从我们网站上下载 .deb 文件来安装可以达到更好的效果。查看 Debian安装包 和 Ubuntu安装包 来确认适用于指定发行版的可用版本。 你可以使用dpkg来安装从上边下载来的安装包，也可以使用我们的APT库（下边介绍）。 所有的依赖都会被自动安装。 运行RabbitMQ服务器 自定义RabbitMQ环境变量 服务器会以默认方式启动。你可以自定义RabbitMQ的环境。也可以查看如何配置组件。 开启服务器 当RabbitMQ安装完毕的时候服务器就会像后台程序一般运行起来了。作为一个管理员，可以像平常一样在Debian中使用以下命令启动和关闭服务invoke-rc.d rabbitmq-server stop/start/etc. 注意：服务器是使用rabbitmq这个系统用户来运行的。如果你改变了Mnesia数据库或者日志的位置，那么你必须确认这些文件属于此用户（同时更新系统变量）。 我们的APT库 使用我们的APT库： 将以下的行添加到你的 /etc/apt/sources.list 文件中： deb http://www.rabbitmq.com/debian/ testing main （请注意上边行中的 testing 指的是RabbitMQ发行状态，而不是指特定的Debian发行版。你可以将它使用在Debain的稳定版、测试版、非稳定版本中。对Ubuntu来说也是如此。我们之所以将版本描述为 testing 这个词是为了强调我们会频繁发布一些新的东西。） （可选的）为了避免未签名的错误信息，请使用apt-key(8)命令将我们的公钥添加到你的可信任密钥列表中： wget http://www.rabbitmq.com/rabbitmq-signing-key-public.asc sudo apt-key add rabbitmq-signing-key-public.asc 运行 apt-get update` 像平常一样安装软件包即可；例如 sudo apt-get install rabbitmq-server 控制系统限制 如果要调整系统限制（尤其是打开文件的句柄的数量）的话，可以通过编辑 /etc/default/rabbitmq-server 文件让服务启动的时候调用ulimit，例如： ulimit -n 1024 这将会设置此服务打开文件句柄的最大数量为1024个（这也是默认设置）。 安全和端口 SELinux和类似机制或许会通过绑定端口的方式阻止RabbitMQ。当这种情况发生时，RabbitMQ会启动失败。请确认以下的端口是可以被打开的： 4369 (epmd), 25672 (Erlang distribution) 5672, 5671 (启用了 或者 未启用 TLS 的 AMQP 0-9-1) 15672 (如果管理插件被启用) 61613, 61614 (如果 STOMP 被启用) 1883, 8883 (如果 MQTT 被启用) 默认用户访问 代理会建立一个用户名为“guest”密码为“guest”的用户。未经配置的客户端通常会使用这个凭据。默认情况下，这些凭据只能在链接到本机上的代理时使用，所以在链接到其他设备的代理之前，你需要做一些事情。 查看访问控制，了解如何新建更多的用户，删除“guest”用户或者给“guest”用户赋予远程访问权限。 管理代理 如果想要停止或者查看服务器状态等，你可以调用rabbitmqctl（在管理员权限下）。如果没有任何代理在运行，所有的rabbitmqctl命令都会给出“结点未找到”的报告。 调用rabbitmqctl stop来关闭服务器。 调用rabbitmqctl status来查看代理是否运行。 更多信息请查看 rabbitmqctl 信息 日志 服务器的输出被发送到 RABBITMQ_LOG_BASE 目录的 RABBITMQ_NODENAME.log 文件中。一些额外的信息会被写入到 RABBITMQ_NODENAME-sasl.log 文件中。 代理总是会把新的信息添加到日志文件尾部，所以完整的日志历史可以被保存下来。 你可以使用 logrotate 程序来执行必要的循环和压缩工作，并且你还可以更改它。默认情况下，这个位于 /var/log/rabbitmq 文件中的脚本会每周执行一次。你可以查看 /etc/logrotate.d/rabbitmq-server 来对 logrotate 进行配置。 "},"installation/Platforms_supported_by_RabbitMQ.html":{"url":"installation/Platforms_supported_by_RabbitMQ.html","title":"RabbitMQ所支持的平台","keywords":"","body":" 原文：Supported Platforms状态：校对完成翻译：Ping校对：Ping 支持的平台 我们的目标是让RabbitMQ运行在尽可能广泛的平台之上。RabbitMQ有着运行在所有Erlang所支持的平台之上的潜力，从嵌入式系统到多核心集群还有基于云端的服务器。 以下的平台是Erlang语言所支持的，因此RabbitMQ可以运行其上： Solaris BSD Linux MacOSX TRU64 Windows NT/2000/XP/Vista/Windows 7/Windows 8 Windows Server 2003/2008/2012 Windows 95, 98 VxWorks RabbitMQ的开源版本通常被部署在以下的平台上： Ubuntu和其他基于Debian的Linux发行版 Fedora和其他基于RPM包管理方式的Linux发行版 openSUSE和衍生的发行版（包括SLES和SLERT） Mac OS X Windows XP 和 后续版本 Windows RabbitMQ会运行在Windows XP及其之后的版本之上（Server 2003, Vista, Windows 7, Windows 8, Server 2008 and Server 2012）。尽管没有经过测试，但它应该也可以在Windows NT 以及 Windows 2000上良好的运行。 Windows Erlang 虚拟机能够以32位（所有可用版本）和64位（R15B往后）方式使用。将32位虚拟机运行在64位系统上的时候会有一些限制（如地址空间）存在。 常见的 UNIX 尽管没有官方支持，但Erlang和RabbitMQ还是可以运行在大多数系统的POSIX层上，包括Solaris, FreeBSD, NetBSD, OpenBSD等等。 虚拟平台 RabbitMQ可以运行在物理的或模拟的硬件中。这个特性同样允许将不支持的平台模拟成一个支持的平台来运行RabbitMQ。 如果要将RabbitMQ运行在EC2上，点击 EC2 guide 查看更多细节。 商业平台支持 RabbitMQ commercial documentation上有一系列你可以付费购买的RabbitMQ商业支持平台。 不支持的平台 一些平台是不被支持的，而且很可能永远不会： z/OS 和大多数的大型机 有内存限制的机器（小于16Mb） 如果你的平台不在此列或者你需要其他的帮助，请联系我们 "},"AMQP/AMQP_0-9-1_Model_Explained.html":{"url":"AMQP/AMQP_0-9-1_Model_Explained.html","title":"AMQP 0.9.1 模型解析","keywords":"","body":" 原文：AMQP 0-9-1 Model Explained翻译：Ping AMQP 0-9-1 简介 关于本指南 本指南介绍了RabbitMQ所使用的 AMQP 0-9-1版本。原始版本由Michael Klishin贡献，Chris Duncan编辑。 AMQP 0-9-1 和 AMQP 模型高阶概述 AMQP是什么 AMQP（高级消息队列协议）是一个网络协议。它支持符合要求的客户端应用（application）和消息中间件代理（messaging middleware broker）之间进行通信。 消息代理和他们所扮演的角色 消息代理（message brokers）从发布者（publishers）亦称生产者（producers）那儿接收消息，并根据既定的路由规则把接收到的消息发送给处理消息的消费者（consumers）。 由于AMQP是一个网络协议，所以这个过程中的发布者，消费者，消息代理 可以存在于不同的设备上。 AMQP 0-9-1 模型简介 AMQP 0-9-1的工作过程如下图：消息（message）被发布者（publisher）发送给交换机（exchange），交换机常常被比喻成邮局或者邮箱。然后交换机将收到的消息根据路由规则分发给绑定的队列（queue）。最后AMQP代理会将消息投递给订阅了此队列的消费者，或者消费者按照需求自行获取。 发布者（publisher）发布消息时可以给消息指定各种消息属性（message meta-data）。有些属性有可能会被消息代理（brokers）使用，然而其他的属性则是完全不透明的，它们只能被接收消息的应用所使用。 从安全角度考虑，网络是不可靠的，接收消息的应用也有可能在处理消息的时候失败。基于此原因，AMQP模块包含了一个消息确认（message acknowledgements）的概念：当一个消息从队列中投递给消费者后（consumer），消费者会通知一下消息代理（broker），这个可以是自动的也可以由处理消息的应用的开发者执行。当“消息确认”被启用的时候，消息代理不会完全将消息从队列中删除，直到它收到来自消费者的确认回执（acknowledgement）。 在某些情况下，例如当一个消息无法被成功路由时，消息或许会被返回给发布者并被丢弃。或者，如果消息代理执行了延期操作，消息会被放入一个所谓的死信队列中。此时，消息发布者可以选择某些参数来处理这些特殊情况。 队列，交换机和绑定统称为AMQP实体（AMQP entities）。 AMQP是一个可编程的协议 AMQP 0-9-1是一个可编程协议，某种意义上说AMQP的实体和路由规则是由应用本身定义的，而不是由消息代理定义。包括像声明队列和交换机，定义他们之间的绑定，订阅队列等等关于协议本身的操作。 这虽然能让开发人员自由发挥，但也需要他们注意潜在的定义冲突。当然这在实践中很少会发生，如果发生，会以配置错误（misconfiguration）的形式表现出来。 应用程序（Applications）声明AMQP实体，定义需要的路由方案，或者删除不再需要的AMQP实体。 交换机和交换机类型 交换机是用来发送消息的AMQP实体。交换机拿到一个消息之后将它路由给一个或零个队列。它使用哪种路由算法是由交换机类型和被称作绑定（bindings）的规则所决定的。AMQP 0-9-1的代理提供了四种交换机 Name（交换机类型） Default pre-declared names（预声明的默认名称） Direct exchange（直连交换机） (Empty string) and amq.direct Fanout exchange（扇型交换机） amq.fanout Topic exchange（主题交换机） amq.topic Headers exchange（头交换机） amq.match (and amq.headers in RabbitMQ) 除交换机类型外，在声明交换机时还可以附带许多其他的属性，其中最重要的几个分别是： Name Durability （消息代理重启后，交换机是否还存在） Auto-delete （当所有与之绑定的消息队列都完成了对此交换机的使用后，删掉它） Arguments（依赖代理本身） 交换机可以有两个状态：持久（durable）、暂存（transient）。持久化的交换机会在消息代理（broker）重启后依旧存在，而暂存的交换机则不会（它们需要在代理再次上线后重新被声明）。然而并不是所有的应用场景都需要持久化的交换机。 默认交换机 默认交换机（default exchange）实际上是一个由消息代理预先声明好的没有名字（名字为空字符串）的直连交换机（direct exchange）。它有一个特殊的属性使得它对于简单应用特别有用处：那就是每个新建队列（queue）都会自动绑定到默认交换机上，绑定的路由键（routing key）名称与队列名称相同。 举个栗子：当你声明了一个名为\"search-indexing-online\"的队列，AMQP代理会自动将其绑定到默认交换机上，绑定（binding）的路由键名称也是为\"search-indexing-online\"。因此，当携带着名为\"search-indexing-online\"的路由键的消息被发送到默认交换机的时候，此消息会被默认交换机路由至名为\"search-indexing-online\"的队列中。换句话说，默认交换机看起来貌似能够直接将消息投递给队列，尽管技术上并没有做相关的操作。 直连交换机 直连型交换机（direct exchange）是根据消息携带的路由键（routing key）将消息投递给对应队列的。直连交换机用来处理消息的单播路由（unicast routing）（尽管它也可以处理多播路由）。下边介绍它是如何工作的： 将一个队列绑定到某个交换机上，同时赋予该绑定一个路由键（routing key） 当一个携带着路由键为R的消息被发送给直连交换机时，交换机会把它路由给绑定值同样为R的队列。 直连交换机经常用来循环分发任务给多个工作者（workers）。当这样做的时候，我们需要明白一点，在AMQP 0-9-1中，消息的负载均衡是发生在消费者（consumer）之间的，而不是队列（queue）之间。 直连型交换机图例： 扇型交换机 扇型交换机（funout exchange）将消息路由给绑定到它身上的所有队列，而不理会绑定的路由键。如果N个队列绑定到某个扇型交换机上，当有消息发送给此扇型交换机时，交换机会将消息的拷贝分别发送给这所有的N个队列。扇型用来交换机处理消息的广播路由（broadcast routing）。 因为扇型交换机投递消息的拷贝到所有绑定到它的队列，所以他的应用案例都极其相似： 大规模多用户在线（MMO）游戏可以使用它来处理排行榜更新等全局事件 体育新闻网站可以用它来近乎实时地将比分更新分发给移动客户端 分发系统使用它来广播各种状态和配置更新 在群聊的时候，它被用来分发消息给参与群聊的用户。（AMQP没有内置presence的概念，因此XMPP可能会是个更好的选择） 扇型交换机图例： 主题交换机 主题交换机（topic exchanges）通过对消息的路由键和队列到交换机的绑定模式之间的匹配，将消息路由给一个或多个队列。主题交换机经常用来实现各种分发/订阅模式及其变种。主题交换机通常用来实现消息的多播路由（multicast routing）。 主题交换机拥有非常广泛的用户案例。无论何时，当一个问题涉及到那些想要有针对性的选择需要接收消息的 多消费者/多应用（multiple consumers/applications） 的时候，主题交换机都可以被列入考虑范围。 使用案例： 分发有关于特定地理位置的数据，例如销售点 由多个工作者（workers）完成的后台任务，每个工作者负责处理某些特定的任务 股票价格更新（以及其他类型的金融数据更新） 涉及到分类或者标签的新闻更新（例如，针对特定的运动项目或者队伍） 云端的不同种类服务的协调 分布式架构/基于系统的软件封装，其中每个构建者仅能处理一个特定的架构或者系统。 头交换机 有时消息的路由操作会涉及到多个属性，此时使用消息头就比用路由键更容易表达，头交换机（headers exchange）就是为此而生的。头交换机使用多个消息属性来代替路由键建立路由规则。通过判断消息头的值能否与指定的绑定相匹配来确立路由规则。 我们可以绑定一个队列到头交换机上，并给他们之间的绑定使用多个用于匹配的头（header）。这个案例中，消息代理得从应用开发者那儿取到更多一段信息，换句话说，它需要考虑某条消息（message）是需要部分匹配还是全部匹配。上边说的“更多一段消息”就是\"x-match\"参数。当\"x-match\"设置为“any”时，消息头的任意一个值被匹配就可以满足条件，而当\"x-match\"设置为“all”的时候，就需要消息头的所有值都匹配成功。 头交换机可以视为直连交换机的另一种表现形式。头交换机能够像直连交换机一样工作，不同之处在于头交换机的路由规则是建立在头属性值之上，而不是路由键。路由键必须是一个字符串，而头属性值则没有这个约束，它们甚至可以是整数或者哈希值（字典）等。 队列 AMQP中的队列（queue）跟其他消息队列或任务队列中的队列是很相似的：它们存储着即将被应用消费掉的消息。队列跟交换机共享某些属性，但是队列也有一些另外的属性。 Name Durable（消息代理重启后，队列依旧存在） Exclusive（只被一个连接（connection）使用，而且当连接关闭后队列即被删除） Auto-delete（当最后一个消费者退订后即被删除） Arguments（一些消息代理用他来完成类似与TTL的某些额外功能） 队列在声明（declare）后才能被使用。如果一个队列尚不存在，声明一个队列会创建它。如果声明的队列已经存在，并且属性完全相同，那么此次声明不会对原有队列产生任何影响。如果声明中的属性与已存在队列的属性有差异，那么一个错误代码为406的通道级异常就会被抛出。 队列名称 队列的名字可以由应用（application）来取，也可以让消息代理（broker）直接生成一个。队列的名字可以是最多255字节的一个utf-8字符串。若希望AMQP消息代理生成队列名，需要给队列的name参数赋值一个空字符串：在同一个通道（channel）的后续的方法（method）中，我们可以使用空字符串来表示之前生成的队列名称。之所以之后的方法可以获取正确的队列名是因为通道可以默默地记住消息代理最后一次生成的队列名称。 以\"amq.\"开始的队列名称被预留做消息代理内部使用。如果试图在队列声明时打破这一规则的话，一个通道级的403 (ACCESS_REFUSED)错误会被抛出。 队列持久化 持久化队列（Durable queues）会被存储在磁盘上，当消息代理（broker）重启的时候，它依旧存在。没有被持久化的队列称作暂存队列（Transient queues）。并不是所有的场景和案例都需要将队列持久化。 持久化的队列并不会使得路由到它的消息也具有持久性。倘若消息代理挂掉了，重新启动，那么在重启的过程中持久化队列会被重新声明，无论怎样，只有经过持久化的消息才能被重新恢复。 绑定 绑定（Binding）是交换机（exchange）将消息（message）路由给队列（queue）所需遵循的规则。如果要指示交换机“E”将消息路由给队列“Q”，那么“Q”就需要与“E”进行绑定。绑定操作需要定义一个可选的路由键（routing key）属性给某些类型的交换机。路由键的意义在于从发送给交换机的众多消息中选择出某些消息，将其路由给绑定的队列。 打个比方： 队列（queue）是我们想要去的位于纽约的目的地 交换机（exchange）是JFK机场 绑定（binding）就是JFK机场到目的地的路线。能够到达目的地的路线可以是一条或者多条 拥有了交换机这个中间层，很多由发布者直接到队列难以实现的路由方案能够得以实现，并且避免了应用开发者的许多重复劳动。 如果AMQP的消息无法路由到队列（例如，发送到的交换机没有绑定队列），消息会被就地销毁或者返还给发布者。如何处理取决于发布者设置的消息属性。 消费者 消息如果只是存储在队列里是没有任何用处的。被应用消费掉，消息的价值才能够体现。在AMQP 0-9-1 模型中，有两种途径可以达到此目的： 将消息投递给应用 (\"push API\") 应用根据需要主动获取消息 (\"pull API\") 使用push API，应用（application）需要明确表示出它在某个特定队列里所感兴趣的，想要消费的消息。如是，我们可以说应用注册了一个消费者，或者说订阅了一个队列。一个队列可以注册多个消费者，也可以注册一个独享的消费者（当独享消费者存在时，其他消费者即被排除在外）。 每个消费者（订阅者）都有一个叫做消费者标签的标识符。它可以被用来退订消息。消费者标签实际上是一个字符串。 消息确认 消费者应用（Consumer applications） - 用来接受和处理消息的应用 - 在处理消息的时候偶尔会失败或者有时会直接崩溃掉。而且网络原因也有可能引起各种问题。这就给我们出了个难题，AMQP代理在什么时候删除消息才是正确的？AMQP 0-9-1 规范给我们两种建议： 当消息代理（broker）将消息发送给应用后立即删除。（使用AMQP方法：basic.deliver或basic.get-ok） 待应用（application）发送一个确认回执（acknowledgement）后再删除消息。（使用AMQP方法：basic.ack） 前者被称作自动确认模式（automatic acknowledgement model），后者被称作显式确认模式（explicit acknowledgement model）。在显式模式下，由消费者应用来选择什么时候发送确认回执（acknowledgement）。应用可以在收到消息后立即发送，或将未处理的消息存储后发送，或等到消息被处理完毕后再发送确认回执（例如，成功获取一个网页内容并将其存储之后）。 如果一个消费者在尚未发送确认回执的情况下挂掉了，那AMQP代理会将消息重新投递给另一个消费者。如果当时没有可用的消费者了，消息代理会死等下一个注册到此队列的消费者，然后再次尝试投递。 拒绝消息 当一个消费者接收到某条消息后，处理过程有可能成功，有可能失败。应用可以向消息代理表明，本条消息由于“拒绝消息（Rejecting Messages）”的原因处理失败了（或者未能在此时完成）。当拒绝某条消息时，应用可以告诉消息代理如何处理这条消息——销毁它或者重新放入队列。当此队列只有一个消费者时，请确认不要由于拒绝消息并且选择了重新放入队列的行为而引起消息在同一个消费者身上无限循环的情况发生。 Negative Acknowledgements 在AMQP中，basic.reject方法用来执行拒绝消息的操作。但basic.reject有个限制：你不能使用它决绝多个带有确认回执（acknowledgements）的消息。但是如果你使用的是RabbitMQ，那么你可以使用被称作negative acknowledgements（也叫nacks）的AMQP 0-9-1扩展来解决这个问题。更多的信息请参考帮助页面 预取消息 在多个消费者共享一个队列的案例中，明确指定在收到下一个确认回执前每个消费者一次可以接受多少条消息是非常有用的。这可以在试图批量发布消息的时候起到简单的负载均衡和提高消息吞吐量的作用。For example, if a producing application sends messages every minute because of the nature of the work it is doing.（？？？例如，如果生产应用每分钟才发送一条消息，这说明处理工作尚在运行。） 注意，RabbitMQ只支持通道级的预取计数，而不是连接级的或者基于大小的预取。 消息属性和有效载荷（消息主体） AMQP模型中的消息（Message）对象是带有属性（Attributes）的。有些属性及其常见，以至于AMQP 0-9-1 明确的定义了它们，并且应用开发者们无需费心思思考这些属性名字所代表的具体含义。例如： Content type（内容类型） Content encoding（内容编码） Routing key（路由键） Delivery mode (persistent or not) 投递模式（持久化 或 非持久化） Message priority（消息优先权） Message publishing timestamp（消息发布的时间戳） Expiration period（消息有效期） Publisher application id（发布应用的ID） 有些属性是被AMQP代理所使用的，但是大多数是开放给接收它们的应用解释器用的。有些属性是可选的也被称作消息头（headers）。他们跟HTTP协议的X-Headers很相似。消息属性需要在消息被发布的时候定义。 AMQP的消息除属性外，也含有一个有效载荷 - Payload（消息实际携带的数据），它被AMQP代理当作不透明的字节数组来对待。消息代理不会检查或者修改有效载荷。消息可以只包含属性而不携带有效载荷。它通常会使用类似JSON这种序列化的格式数据，为了节省，协议缓冲器和MessagePack将结构化数据序列化，以便以消息的有效载荷的形式发布。AMQP及其同行者们通常使用\"content-type\" 和 \"content-encoding\" 这两个字段来与消息沟通进行有效载荷的辨识工作，但这仅仅是基于约定而已。 消息能够以持久化的方式发布，AMQP代理会将此消息存储在磁盘上。如果服务器重启，系统会确认收到的持久化消息未丢失。简单地将消息发送给一个持久化的交换机或者路由给一个持久化的队列，并不会使得此消息具有持久化性质：它完全取决与消息本身的持久模式（persistence mode）。将消息以持久化方式发布时，会对性能造成一定的影响（就像数据库操作一样，健壮性的存在必定造成一些性能牺牲）。 消息确认 由于网络的不确定性和应用失败的可能性，处理确认回执（acknowledgement）就变的十分重要。有时我们确认消费者收到消息就可以了，有时确认回执意味着消息已被验证并且处理完毕，例如对某些数据已经验证完毕并且进行了数据存储或者索引操作。 这种情形很常见，所以 AMQP 0-9-1 内置了一个功能叫做 消息确认（message acknowledgements），消费者用它来确认消息已经被接收或者处理。如果一个应用崩溃掉（此时连接会断掉，所以AMQP代理亦会得知），而且消息的确认回执功能已经被开启，但是消息代理尚未获得确认回执，那么消息会被从新放入队列（并且在还有还有其他消费者存在于此队列的前提下，立即投递给另外一个消费者）。 协议内置的消息确认功能将帮助开发者建立强大的软件。 AMQP 0-9-1 方法 AMQP 0-9-1由许多方法（methods）构成。方法即是操作，这跟面向对象编程中的方法没半毛钱关系。AMQP的方法被分组在类（class）中。这里的类仅仅是对AMQP方法的逻辑分组而已。在 AMQP 0-9-1参考 中有对AMQP方法的详细介绍。 让我们来看看交换机类，有一组方法被关联到了交换机的操作上。这些方法如下所示： exchange.declare exchange.declare-ok exchange.delete exchange.delete-ok （请注意，RabbitMQ网站参考中包含了特用于RabbitMQ的交换机类的扩展，这里我们不对其进行讨论） 以上的操作来自逻辑上的配对：exchange.declare 和 exchange.declare-ok，exchange.delete 和 exchange.delete-ok. 这些操作分为“请求 - requests”（由客户端发送）和“响应 - responses”（由代理发送，用来回应之前提到的“请求”操作）。 如下的例子：客户端要求消息代理使用exchange.declare方法声明一个新的交换机： 如上图所示，exchange.declare方法携带了好几个参数。这些参数可以允许客户端指定交换机名称、类型、是否持久化等等。 操作成功后，消息代理使用exchange.declare-ok方法进行回应： exchange.declare-ok方法除了通道号之外没有携带任何其他参数（通道-channel 会在本指南稍后章节进行介绍）。 AMQP队列类的配对方法 - queue.declare方法 和 queue.declare-ok有着与其他配对方法非常相似的一系列事件： 不是所有的AMQP方法都有与其配对的“另一半”。许多（basic.publish是最被广泛使用的）都没有相对应的“响应”方法，另外一些（如basic.get）有着一种以上与之对应的“响应”方法。 连接 AMQP连接通常是长连接。AMQP是一个使用TCP提供可靠投递的应用层协议。AMQP使用认证机制并且提供TLS（SSL）保护。当一个应用不再需要连接到AMQP代理的时候，需要优雅的释放掉AMQP连接，而不是直接将TCP连接关闭。 通道 有些应用需要与AMQP代理建立多个连接。无论怎样，同时开启多个TCP连接都是不合适的，因为这样做会消耗掉过多的系统资源并且使得防火墙的配置更加困难。AMQP 0-9-1提供了通道（channels）来处理多连接，可以把通道理解成共享一个TCP连接的多个轻量化连接。 在涉及多线程/进程的应用中，为每个线程/进程开启一个通道（channel）是很常见的，并且这些通道不能被线程/进程共享。 一个特定通道上的通讯与其他通道上的通讯是完全隔离的，因此每个AMQP方法都需要携带一个通道号，这样客户端就可以指定此方法是为哪个通道准备的。 虚拟主机 为了在一个单独的代理上实现多个隔离的环境（用户、用户组、交换机、队列 等），AMQP提供了一个虚拟主机（virtual hosts - vhosts）的概念。这跟Web servers虚拟主机概念非常相似，这为AMQP实体提供了完全隔离的环境。当连接被建立的时候，AMQP客户端来指定使用哪个虚拟主机。 AMQP是可扩展的 AMQP 0-9-1 拥有多个扩展点： 定制化交换机类型 可以让开发者们实现一些开箱即用的交换机类型尚未很好覆盖的路由方案。例如 geodata-based routing。 交换机和队列的声明中可以包含一些消息代理能够用到的额外属性。例如RabbitMQ中的per-queue message TTL即是使用该方式实现。 特定消息代理的协议扩展。例如RabbitMQ所实现的扩展。 新的 AMQP 0-9-1 方法类可被引入。 消息代理可以被其他的插件扩展，例如RabbitMQ的管理前端 和 已经被插件化的HTTP API。 这些特性使得AMQP 0-9-1模型更加灵活，并且能够适用于解决更加宽泛的问题。 AMQP 0-9-1 客户端生态系统 AMQP 0-9-1 拥有众多的适用于各种流行语言和框架的客户端。其中一部分严格遵循AMQP规范，提供AMQP方法的实现。另一部分提供了额外的技术，方便使用的方法和抽象。有些客户端是异步的（非阻塞的），有些是同步的（阻塞的），有些将这两者同时实现。有些客户端支持“供应商的特定扩展”（例如RabbitMQ的特定扩展）。 因为AMQP的主要目标之一就是实现交互性，所以对于开发者来讲，了解协议的操作方法而不是只停留在弄懂特定客户端的库就显得十分重要。这样一来，开发者使用不同类型的库与协议进行沟通时就会容易的多。 "},"AMQP/amqp-0-9-1-quickref.html":{"url":"AMQP/amqp-0-9-1-quickref.html","title":"AMQP 0.9.1 快速参考指南","keywords":"","body":"﻿>原文：AMQP 0-9-1 Quick Reference 翻译：Ping AMQP 0-9-1 快速参考指南 本文提供了 AMQP 0-9-1 的 RabbitMQ 实现指南。作为对 AMQP 规范所定义的类和方法的有力补充，RabbitMQ 还提供了一系列协议扩展，同样在此列出。原始以及扩展规范可以在协议页面中进行下载。 为方便大家使用，相关章节内提供了 Java 和 .Net 客户端的API指南的链接。每个方法及其参数的完整细节可以从完整的AMQP 0-9-1 参考中查看。 Basic basic.ack(delivery-tag delivery-tag, bit multiple) 支持： 完整对一条或多条消息进行确认。 当确认回执(acknowledgement)由客户端发送时，此方法用来确认单条或多条消息已经由 Deliver 或 Get-Ok 方法成功发送。当确认回执由服务器端发送时，此方用来确认单条或多条消息已经由 Publish 方法通过 confirm 模式下的信道（channel）成功发布。确认回执可用于单条消息甚至于一个消息集合，并且可以包含一条特定信息。 javadoc | dotnetdoc | amqpdoc basic.cancel(consumer-tag consumer-tag, no-wait no-wait) ➔ cancel-ok 支持： 完整结束队列消费者 此方法用来清除消费者。它不会影响到已经成功投递的消息，但是会使得服务器不再将新的消息投送给此消费者。客户端会在发送cancel方法和收到cancel-ok回复的过程中收到任意数量的消息。当消费者端发生不可预估的错误时，此方法也有可能由服务器发送给客户端（也就是说结束行为不是由客户端发送给服务器的basic.cancel方法所触发）。这种情况下客户端可以接收到由于队列被删除等原因引起的消费者丢失通知。需要注意的是，客户端从服务器接收basic.cancel方法并不是必须实现的，它通过消息代理可以辨识以协商手段接受basic.cancel的客户端的特性来正常工作。 javadoc | dotnetdoc | amqpdoc basic.consume(short reserved-1, queue-name queue, consumer-tag consumer-tag, no-local no-local, no-ack no-ack, bit exclusive, no-wait no-wait, table arguments) ➔ consume-ok 支持：部分启动队列消费者 此方法告知服务器开启一个“消费者”，此消费者实质是一个针对特定队列消息的持久化请求。消费者在声明过的信道（channel）中会一直存在，直到客户端清除他们为止。 javadoc | dotnetdoc | amqpdoc basic.deliver(consumer-tag consumer-tag, delivery-tag delivery-tag, redelivered redelivered, exchange-name exchange, shortstr routing-key) 支持：完整将消费者消息通知给客户端 此方法将一条消息通过消费者投递给客户端。在异步消息投递模式中，客户端通过Consume方法启动消费者，然后服务器使用Deliver方法将消息送达。 amqpdoc basic.get(short reserved-1, queue-name queue, no-ack no-ack) ➔ get-ok | get-empty 支持：完整直接访问队列 此方法提供了通过同步通讯的方式直接访问队列内消息的途径。它针对的是一些有特殊需求的应用，例如对应用来说同步的功能性意义远大于应用性能。 javadoc | dotnetdoc | amqpdoc basic.nack(delivery-tag delivery-tag, bit multiple, bit requeue) 此方法为RabbitMQ特有的AMQP扩展 拒绝单条或多条输入消息。 此方法允许客户端拒绝单条或多条输入消息。它可以用来打断或清除大体积消息的输入，或者将无法处理的消息返回给消息的原始队列。这个方法也可以在确认模式（confirm mode）下被服务器用来通知信道（channel）上的消息发布者有未被处理的消息存在。 RabbitMQ Documentationjavadoc | dotnetdoc | amqpdoc basic.publish(short reserved-1, exchange-name exchange, shortstr routing-key, bit mandatory, bit immediate) 支持：完整发布单条消息 此方法用来发布单条消息到指定的交换机（exchange）。消息将会通过配置好的交换机根据既定规则路由给队列（queues），之后，如果存在事务处理（transaction），并且事务已经被提交，就会分发给活跃的消费者。 javadoc | dotnetdoc | amqpdoc basic.qos(long prefetch-size, short prefetch-count, bit global) ➔ qos-ok 支持：部分指定服务质量 此方法指定服务的服务质量。QoS可以分配给当前的信道（channel）或者链接内的所有信道。qos方法的特定属性和语义依赖于内容类的语义。虽然qos方法原则上可以用于服务端及客户端，但在这里此方法仅适用于服务器端。 javadoc | dotnetdoc | amqpdoc basic.recover(bit requeue) 支持：部分重新投递未被确认的消息。 此方法会要求服务器重新投递特定信道内所有未确认的消息。零条或多条消息会被重新投递。此方法用于替代异步恢复（asynchronous Recover）。 javadoc | dotnetdoc | amqpdoc basic.recover-async(bit requeue) 重新投递未确认的消息。 此方法会要求服务器重新投递特定信道内所有未确认的消息。零条或多条消息会被重新投递。此方法已经弃用，取而代之的是同步 Recover/Recover-Ok 方法。 javadoc | dotnetdoc | amqpdoc basic.reject(delivery-tag delivery-tag, bit requeue) 支持：部分拒绝单条输入消息。 此方法允许客户端拒绝单条或多条输入消息。它可以用来打断或清除大体积消息的输入，或者将无法处理的消息返回给消息的原始队列。 RabbitMQ blog postjavadoc | dotnetdoc | amqpdoc basic.return(reply-code reply-code, reply-text reply-text, exchange-name exchange, shortstr routing-key) 支持： 部分返回单条处理失败的消息 此方法将发布时打有\"immediate\"标签的无法投递的，或发布时打有\"mandatory\"标签的无法正确路由的单条消息返回。应答代码或文字中会注明失败原因。 amqpdoc Channel channel.close(reply-code reply-code, reply-text reply-text, class-id class-id, method-id method-id) ➔ close-ok 支持：完整请求关闭信道。 此方法表明发送者希望关闭信道。这通常是由于内部条件（如强制关闭）或者由于处理特定方法引起的错误（也就是Exception）触发。当关闭行为是由 exception 触发时，发送者需提供引起 exception 的方法的 class id 和 method id。 [javadoc] | [dotnetdoc] | [amqpdoc] channel.flow(bit active) ➔ flow-ok 支持：部分启用/禁用对端流 此方法要求对端暂停或者重启消费者发送的内容数据流。这是一个简单的流控制机制，用来避免信道的队列溢出或者发现信道接收的消息是否超出了其处理能力。需要注意的是，此方法目的不在于控制窗口。它不会影响到Basic.Get-Ok方法返回的内容。 [amqpdoc] channel.open(shortstr reserved-1) ➔ open-ok 支持：完整打开一个信道使用。 此方法会打开一个信道用于与服务器通讯。 [amqpdoc] Confirm 此类为RabbitMQ特有的AMQP扩展 confirm.select(bit nowait) ➔ select-ok . 此方法用来设置信道以便使用发布者确认回执（acknowledgements）。客户端仅可将此方法用于非事务性信道。 RabbitMQ Documentation[javadoc] | [dotnetdoc] | [amqpdoc] Exchange exchange.bind(short reserved-1, exchange-name destination, exchange-name source, shortstr routing-key, no-wait no-wait, table arguments) ➔ bind-ok 此方法为RabbitMQ特有的AMQP扩展 将两个交换机进行绑定。 此方法将一个交换机绑定到另一个交换机上。 RabbitMQ DocumentationRabbitMQ blog post[javadoc] | [dotnetdoc] | [amqpdoc] exchange.declare(short reserved-1, exchange-name exchange, shortstr type, bit passive, bit durable, bit auto-delete*, bit internal*, no-wait no-wait, table arguments) ➔ declare-ok RabbitMQ针对AMQP协议的扩展 支持：完整验证交换机是否存在，如有需要创建之。 如果指定交换机不存在，此方法会新建之。如果交换机已经存在，会验证其类型是否正确。 RabbitMQ针对AMQP规范实现了一个扩展，此扩展允许将无法正确路由的消息投递到一个替代交换机中（AE）。替代交换机的特性可以帮助判断客户端何时发布了无法路由的消息，并且能够提供 \"or else\" 路由语义去对某些消息做特殊处理，其他的消息则由通用方法进行处理。 AE documention[javadoc] | [dotnetdoc] | [amqpdoc] exchange.delete(short reserved-1, exchange-name exchange, bit if-unused, no-wait no-wait) ➔ delete-ok 支持：部分删除交换机 此方法用于删除交换机。当一个交换机被删除后，与其绑定的所有队列都会被清除。 [javadoc] | [dotnetdoc] | [amqpdoc] exchange.unbind(short reserved-1, exchange-name destination, exchange-name source, shortstr routing-key, no-wait no-wait, table arguments) ➔ unbind-ok 此方法为RabbitMQ特有的AMQP扩展 解除两个交换机之间的绑定关系 此方法用于解除两个交换机之间的绑定关系。 [javadoc] | [dotnetdoc] | [amqpdoc] Queue queue.bind(short reserved-1, queue-name queue, exchange-name exchange, shortstr routing-key, no-wait no-wait, table arguments) ➔ bind-ok 支持：完整将队列绑定到交换机 此方法用于绑定队列到交换机。队列绑定到交换机之前不会接收到任何消息。在经典消息模型中，存储转发队列绑定到直连交换机，订阅队列绑定到主题交换机。 [javadoc] | [dotnetdoc] | [amqpdoc] queue.declare(short reserved-1, queue-name queue, bit passive, bit durable, bit exclusive, bit auto-delete, no-wait no-wait, table arguments) ➔ declare-ok 支持：完整声明队列，如果队列不存在创建之。 此方法用于创建或检查队列。当新建一个队列时，客户端可以指定一系列属性用于控制队列的持久性及其内容，还有队列的分享等级。 RabbitMQ为AMQP规范实现了一些扩展，允许队列创建者控制队列各个方面的行为。 每个队列的消息生命周期这个扩展决定了一条消息从发布到被服务器丢弃的生存时间。此方法中设置生存时间的参数为 x-message-ttl。 队列的过期时间队列可以在声明时指定租约时限。租约时限指的是如果队列一直未被使用，多久之后服务器会将其自动删除。租约时限由此方法的x-expires参数指定。 x-message-ttl documentationx-expires documentation [javadoc] | [dotnetdoc] | [amqpdoc] queue.delete(short reserved-1, queue-name queue, bit if-unused, bit if-empty, no-wait no-wait) ➔ delete-ok 支持：部分删除队列。 此方法用于删除一个队列。如果服务器设置了死信队列（dead-letter queue），当队列被某个删除时，任何依存于此队列的消息都会被发送到死信队列中，队列上的所有消费者都会被清除掉。 [javadoc] | [dotnetdoc] | [amqpdoc] queue.purge(short reserved-1, queue-name queue, no-wait no-wait) ➔ purge-ok 支持：完整清空队列。 此方法会将队列中的所有不处于等待 确认回执（acknowledgment）状态的消息全部移除。 [javadoc] | [dotnetdoc] | [amqpdoc] queue.unbind(short reserved-1, queue-name queue, exchange-name exchange, shortstr routing-key, table arguments) ➔ unbind-ok 支持：部分解除队列与交换机的绑定。 此方法用于解除队列与交换机的绑定关系。 [javadoc] | [dotnetdoc] | [amqpdoc] Tx tx.commit() ➔ commit-ok 支持：完整提交当前事务。 此方法用于提交当前事务中所有的消息发布以及确（acknowledgments）认执行动作。 [javadoc] | [dotnetdoc] | [amqpdoc] tx.rollback() ➔ rollback-ok 支持：完整终止当前事务。 此方法用于终止当前事务中的所有消息发布以及确认提交操作。回滚动作完成后，一个新的事务随即开始。如果有必要，应该发布一个明确的恢复操作。 [javadoc] | [dotnetdoc] | [amqpdoc] tx.select() ➔ select-ok 支持：完整选择标准事务模式。 此方法设置信道使用标准事务模式。客户端在使用提交（Commit）或者（回滚）方法之前，需要至少在信道上使用一次此方法。 [javadoc] | [dotnetdoc] | [amqpdoc] "},"ClientDocumentation/java-api-guide.html":{"url":"ClientDocumentation/java-api-guide.html","title":"Java客户端指南","keywords":"","body":" 原文：Java Client API Guide翻译：mr-ping状态：待校对许可： Java客户端接口（API）指南 概览 本篇覆盖了 RabbitMQ Java 客户端 和它的公共接口(API)。这里假设您使用的是客户端最新的主版本，并且对基本操作已经有所了解。 指南包含以下的关键部分： [toc] 也可以单独使用 API参考（JavaDoc）。 支持的时间线 访问 RabbitMQ Java 库支持页面 了解所支持的时间线。 JDK 和 Android 版本支持 本库的5.x系列的编译和运行需要JDK 8,。对安卓来说，代表着只支持 Android 7.0 或以上 版本。 4.x系列支持JDK 6 以及安卓7.0之前的版本。 许可 本库在 GitHub上开源，并遵循以下三个许可 Apache Public License 2.0 Mozilla Public License 2.0 GPL 2.0 这意味着用户可以根据需要遵循所列出的三个许可中的任意一个即可。例如，用户可以选择依照Apache Public License 2.0许可将客户端应用于商业产品中。GPLv2下的代码库可以选择依照GPLv2许可，以此类推。 概览 客户端API提供了 AMQP 0-9-1 协议模型 中的关键内容，并且额外提供了易于使用的抽象。 RabbitMQ Java 客户端使用com.rabbitmq.client作为它的顶级包。关键的类和接口有： Channel: 代表 AMQP 0-9-1通道，并提供了大多数操作（协议方法）。 Connection: 代表 AMQP 0-9-1 连接 ConnectionFactory: 构建Connection实例 Consumer: 代表消息的消费者 DefaultConsumer: 消费者通用的基类 BasicProperties: 消息的属性（元信息） BasicProperties.Builder: BasicProperties的构建器 通过Channel（通道）的接口可以对协议进行操作。Connection（连接）用于开启通道，注册连接的生命周期内的处理事件，并且关闭不再需要的连接。ConnectionFactory用于实例化Connection对象，并且可以通过ConnectionFactory来进行诸如vhost、username等属性的设置。 连接（Connections） 和 通道（Channels） 核心的接口类为Connection和Channel，分别代表AMQP 0-9-1的连接和通道。通常在使用之前将他们引入： import com.rabbitmq.client.Connection; import com.rabbitmq.client.Channel; 连接到RabbitMQ 以下代码演示使用给定的参数（如主机名、端口号）连接到RabbitMQ节点： ConnectionFactory factory = new ConnectionFactory(); // \"guest\"/\"guest\" by default, limited to localhost connections factory.setUsername(userName); factory.setPassword(password); factory.setVirtualHost(virtualHost); factory.setHost(hostName); factory.setPort(portNumber); Connection conn = factory.newConnection(); 对于运行在本地的RabbitMQ节点而言，这些参数都有合适的默认值。 如果在创建连接前没有指定参数值，则会使用默认参数： Property Default Value Username \"guest\" Password \"guest\" Virtual host \"/\" Hostname \"localhost\" port 5672 for regular connections, 5671 for connections that use TLS 也可以使用 URIs 代替： ConnectionFactory factory = new ConnectionFactory(); factory.setUri(\"amqp://userName:password@hostName:portNumber/virtualHost\"); Connection conn = factory.newConnection(); 对于已经运行在本地的RabbitMQ服务器来说，所有这些参数都有合适的默认值。 成功和不成功的客户端连接都可以在服务器节点日志中找到。 需要注意的是，默认情况下guest（来宾）用户只能用本地进行连接。目的是为了限制已知凭证在生产系统中的使用。 应用的开发者可以自定义连接名称。如果配置了，自定义的名字也会在RabbitMQ节点日志和 管理界面里体现出来。 接下来，Connection接口就可以用来开启通道(Channel)了： Channel channel = conn.createChannel(); 通道可用于消息的发送和接收，之后的部分里会进行介绍。 关闭RabbitMQ连接 通过简单的对通道和连接进行关闭即可关闭掉RabbitMQ的连接： channel.close(); conn.close(); 需要注意的是，虽然将通道关闭掉是最佳实践，但并不是必须的操作。因为无论何种情况，通道都会在底层的连接关闭时自动关闭掉。 客户端关闭操作的事件可以在 服务器节点日志 中找到。 连接 和 通道 的寿命 客户端connections是长连接。底层协议的设计和优化都考虑到了长连接的需求。这意味着对诸如消息发送之类的每个操作都建立一个连接的形式是极其不推荐的，那样做会产生大量的网络往返和开销。 Channels 虽然也是长期存活的，但是由于有大量的可恢复的协议错误会导致通道关闭，通道的存活期会比连接断一些。虽然每个操作都打开和关闭一个通道不是必须的操作，但是也不是不可行。有的选的情况下，还是优先考虑通道的复用为好。 类似于尝试从一个不存在的队列里消费消息这种 通道级别的异常 会导致通道关闭。已经关闭的通道不可以再被使用，也不会再接收到如消息投递之类的服务器事件。RabbitMQ会记录下通道级别的异常，并且会为通道初始化一个关闭顺序（下边会进行介绍）。 由客户端提供的链接名称 RabbitMQ 节点可以持有有限的的客户端信息： 客户端的TCP节点（来源IP地址和端口） 使用的凭证 凭借这些信息就可以定位出现问题的应用或者实例，特别是在可以共享凭证且客户端通过负载均衡器进行连接但无法启用代理协议的情况下。 包括RabbitMQ Java客户端在内的AMQP 0-9-1客户端链接可以提供一个自定义标识符，一遍在服务器日志 和管理界面中方便地对客户端进行区分。设置好后，日志内容额管理界面中便会对标识符有所体现。标识符即为客户端提供的连接名称。名称可以用于标识应用或应用中特定的组件。虽然名称是可选的，但是强烈建议提供一个，这将大大简化某些操作任务。 RabbitMQ Java 客户端的 ConnectionFactory#newConnection 方法 覆写了) 接收客户端提供的连接名称。这是一个修改过的连接样例，用于提供连接名称： ConnectionFactory factory = new ConnectionFactory(); factory.setUri(\"amqp://userName:password@hostName:portNumber/virtualHost\"); // provides a custom connection name Connection conn = factory.newConnection(\"app:audit component:event-consumer\"); 交换机（Exchanges）和 队列（Queues）的使用 客户端使用用利用交换机和队列这些高级的协议构建块工作。在使用事前必须对他们进行声明。简单来讲，对任何一种对象类型进行声明的目的是为了确保它们已经存在，并在需要的时候对其进行创建。 接着上边的例子，以下代码声明了一个交换机以及一个服务端命名的队列，然后将它们绑定到一起。 channel.exchangeDeclare(exchangeName, \"direct\", true); String queueName = channel.queueDeclare().getQueue(); channel.queueBind(queueName, exchangeName, routingKey); 这将会主动声明以下对象，这两个对象都可以使用附加参数进行自定义。但在这里，没有给他们俩定义特殊的参数。 持久化、非自动删除的“直连”形交换机 具有系统生成的名称的，非持久化、独占、自动删除的队列 上边调用的函数使用给定的路由键将队列和交换机绑定起来。 注意，当只有一个客户端打算工作于次队列时，这是一个典型的队列声明方式。队列不需要既定的名称，没有其他客户端使用此队列（独占），队列会被自动清理掉（自动删除）。如果有多个客户端消费打算消费一个既定名称的队列，一下代码更为合适： channel.exchangeDeclare(exchangeName, \"direct\", true); channel.queueDeclare(queueName, true, false, false, null); channel.queueBind(queueName, exchangeName, routingKey); 这将会主动进行以下声明： 持久化、非自动删除的“直连”交换机 拥有既定名称的，持久化、非独占、非自动删除的队列 许多Channel接口方法都是被重载的。这里用到的关于 exchangeDeclare, queueDeclare 和 queueBind的短结构的重载方法使用了合适的默认值，更易于使用。当然也有更多参数的长结构的重载方法，使用那些方法可以将一些必要的默认参数进行重写，进行更全面的控制。 这种“短结构、长结构”的模式在客户端接口的使用中涉及。 被动声明 队列和交换机可以被动地进行声明。被动声明会简单地检查提供的名称所对应的实体是否存在。如果不存在则不会做任何操作。对成功检测到的队列来说，被动声明会返回跟非被动声明同样的信息，即队列中处于就绪状态的消费者和消息数量。 如果对应的实体不存在，操作会抛出一个通道级别的异常。然后通道就不可以继续使用了，需要打开一个新的通道。通常在进行被动声明的时候使用临时的一次性通道。 Channel#queueDeclarePassive 和 Channel#exchangeDeclarePassive 方法被用来进行被动声明。下边演示Channel#queueDeclarePassive 的使用： Queue.DeclareOk response = channel.queueDeclarePassive(\"queue-name\"); // returns the number of messages in Ready state in the queue response.getMessageCount(); // returns the number of consumers the queue has response.getConsumerCount(); Channel#exchangeDeclarePassive 方法的返回值没包含什么有用的信息。只要方法正确返回，并且没有通道异常发生，就意味着交换机已经存在了。 可选响应的操作 一些常见的操作还带有“非等待”版本，这种版本的操作不会等待服务器的响应。例如，以下方法会声明一个队列并且通知服务器不要发送任何响应 channel.queueDeclareNoWait(queueName, true, false, false, null); “非等待”版本的操作会更具效率，但是安全保障较低，例如，它们更依赖心跳机制去检测失败的操作。如果不确定，就从标准版本的操作用起。“非等待”版本只是在高级拓扑结构（队列、绑定）的情况下需要。 删除实体和清除消息 可以显示地将队列和交换机删除： channel.queueDelete(\"queue-name\") 也可以做到当队列为空时对其进行删除： channel.queueDelete(\"queue-name\", false, true) 或者当它不再被使用的时候（没有任何消费者对其进行消费）： channel.queueDelete(\"queue-name\", true, false) 队列可以被清除（删除里边的所有消息）： channel.queuePurge(\"queue-name\") 发布消息 使用 Channel.basicPublish 将消息发布到交换机中： byte[] messageBodyBytes = \"Hello, world!\".getBytes(); channel.basicPublish(exchangeName, routingKey, null, messageBodyBytes); 想要实现更完善的控制，可以使用重载的变体来指定mandatory标识，或者发送预设好消息属性的消息（详见发布指南 ） channel.basicPublish(exchangeName, routingKey, mandatory, MessageProperties.PERSISTENT_TEXT_PLAIN, messageBodyBytes); 以下示例发送消息的时候会指定投递模式为2（持久化），优先级为1并且消息体类型（content-type）为\"text/plain\"。使用Builder类去创建一个需要指定多个属性的消息属性对象，例如： channel.basicPublish(exchangeName, routingKey, new AMQP.BasicProperties.Builder() .contentType(\"text/plain\") .deliveryMode(2) .priority(1) .userId(\"bob\") .build(), messageBodyBytes); 以下是发布带有自定义headers消息的示例： Map headers = new HashMap(); headers.put(\"latitude\", 51.5252949); headers.put(\"longitude\", -0.0905493); channel.basicPublish(exchangeName, routingKey, new AMQP.BasicProperties.Builder() .headers(headers) .build(), messageBodyBytes); 以下例子会发布一条具有过期时间属性的消息： channel.basicPublish(exchangeName, routingKey, new AMQP.BasicProperties.Builder() .expiration(\"60000\") .build(), messageBodyBytes); 这里我们并没有展示所有的可能性。 注意BasicProperties是AMQP自动生成的持有类的内置类。 如果发生 资源驱动的报警，那Channel#basicPublish的调用最终会被阻塞掉。 通道和并发的注意事项（线程安全） 依经验而言，应该尽量避免在线程间共享通道对象。应用应该尽可能每个线程都使用单独的通道，而不是将通道共享给多个线程。 虽然可以安全地并发调用通道上的某些操作，但有些操作则不能并发调用，如果那样做会导致错误的帧交错在网络上，或造成重复确认等问题。 在共享的通道上并发执行发布会导致错误的帧交错在网络上，触发连接级别的协议异常并导致连接被代理直接关闭。因此，需要在应用程序代码中进行显式同步（必须在关键部分调用Channel＃basicPublish）。线程之间共享通道也会干扰发布者确认。最好能够完全避免在共享的通道上上进行并发发布，例如通过每个线程使用一个通道的方式实现并发。 也可以通过通道池的方式来避免在共享通道上并发发布消息：一旦一个线程使用完了某个通道，就将通道归还到池中，使得通道可以被其他线程再次使用。通道池可以视为一个特殊的同步解决方案。建议使用现成的池库来实现，而不是自己实现。例如开箱即用的 Spring AMQP 。 通道是吃资源的，而且大多数应用情景下同一个JVM进程很少会开放小几百的通道出来。设想我们应用的每个线程都持有一个通道（由于同一个通道不应被用于并发操作），单个JVM里上千个线程已经会是一个相当大的开销，这些开销本来是可以避免的。此外，一小部分快速的发布者可以很轻松地占满网络接口和代理节点，这种情况通常发生在发布行为的工作量小于路由、存储和消息投递的工作量的情况下。 一个需要避免的经典的反模式就是为每个发布的消息开放单独的通道。通道应该是长时间存货的，并且开放一个通道是一个网络往返的过程，所以上边提到的这种模式是相当没效率的。 一个线程用于消费，另一个线程在共享通道上推送是安全的。 服务推送投递（下边介绍）是以并发的方式分发的，并能确保每个通道顺序的固定。分发机制在每个连接中使用一个java.util.concurrent.ExecutorService。使用ConnectionFactory#setSharedExecutor setter 的ConnectionFactory生成的所有连接都可以共享一个自定义的executor。 当使用手动确认 的时候，需要考虑到是线程完成的确认动作。这根线程收取投递（例如Consumer#handleDelivery将交付处理委派给其他线程）不同，确认操作将multiple这个参数设置成true是不安全的，可能会导致两次确认，还会触发通道级别异常并且关闭通道。在同一时间单独确认一条独立的消息是没问题的。 通过订阅来接收消息 (\"推送接口\") import com.rabbitmq.client.Consumer; import com.rabbitmq.client.DefaultConsumer; 接收消息最高效的方式是使用Consumer接口设置订阅。消息在到达时被自动投递到其中，而不是显示的去请求。 当调用Consumers相关的接口方法时，单个订阅始终由其消费者标签引用。消费者标签可以由客户端或者服务器来生成，用于消费者的身份识别。想让RabbitMQ生成一个节点范围内的唯一标签，可以使用不含有消费者标签属性的Channel#basicConsume 重载，或者传递一个空字符串做为消费者标签，然后使用Channel#basicConsume返回的值。消费者标签同样用于清除消费者之用。 不同的消费者实例必须持有不同的消费者标签。非常不建议在同一个连接上出现重复的消费者标签，这回导致 自动连接覆盖 问题，并在监控消费者时混淆监控数据。 实现Consumer最简单的方式是子类化DefaultConsumer。此子类的实例化对象可以当做basicConsume调用时的参数进行传递，用于设置订阅： boolean autoAck = false; channel.basicConsume(queueName, autoAck, \"myConsumerTag\", new DefaultConsumer(channel) { @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException { String routingKey = envelope.getRoutingKey(); String contentType = properties.getContentType(); long deliveryTag = envelope.getDeliveryTag(); // (process the message components here ...) channel.basicAck(deliveryTag, false); } }); 这里由于我们设置了autoAck = false，需要手动对投递到Consumer的消息进行确认。最简便的方式就是如上边介绍的一样在handleDelivery中进行。 更复杂的消费者需要去覆写其他方法。特别说明的是，当通道和连接关闭时，handleShutdownSignal会被调用，handleConsumeOk会在调用其他Consumer回调之前被传递给消费者标签。 Consumers同样可以通过实现handleCancelOk和handleCancel方法来分别被告知是通过显式还是隐式方式进行取消。 你可以通过Channel.basicCancel显式地取消一个指定的Consumer。 channel.basicCancel(consumerTag); 传递消费者标签。 就像发布者一样，这里同样也需要考虑到消费者的并发安全性。 消费者的回调的调度是在一个独立的线程池里完成的，这个线程池跟通道实例化的那个池是分开的。这表示Consumers可以安全的调用类似于Channel#queueDeclare和Channel#basicCancel这种链接和通道的阻塞方法。 每个通道都有自己的调度线程。对于大多数常见的每个Channel一个Consumer的场景下，这意味着消费者之间不会相互影响。需要注意，如果一个通道里有多个消费者，长时间运行的消费者会阻挡通道中其他消费者回调方法的调度。 请参考并发注意事项（线程安全）部分，来获取有关于并发和并发安全危害的其他主题。 检索单条消息 (\"拉取接口\") 按需检索单条消息也是可以的 (\"pull API\" 又名 polling)。这种消费方法的效率是极低的，比如它使用的是轮训的方式，即使大多数请求结果尚未生成，应用也会重复地去请求结果。因此这种方法是强烈不建议使用的。 使用Channel.basicGet来进行消息的“拉取”。返回值是包含有头信息（属性）和消息体的GetResponse对象实例。 boolean autoAck = false; GetResponse response = channel.basicGet(queueName, autoAck); if (response == null) { // No message retrieved. } else { AMQP.BasicProperties props = response.getProps(); byte[] body = response.getBody(); long deliveryTag = response.getEnvelope().getDeliveryTag(); // ... 由于此例使用手动确认(the autoAck = false above)，所以你需要调用Channel.basicAckto确认已经成功接收到了消息（译者注：一般在成功对接收到的消息处理完毕后进行确认）。 // ... channel.basicAck(method.deliveryTag, false); // acknowledge receipt of the message } 处理无法路由的消息 如果发布的消息设置了mandatory标识，但是没有被成功路由，代理会将其返回给发送的客户端（通过AMQP.Basic.Return命令）。 客户端可以通过实现ReturnListener接口并调用Channel.addReturnListener来收到此类退还通知。如果客户端没有为特定的通道配置退还监听，那返回的相应消息会被默默地丢弃掉。 channel.addReturnListener(new ReturnListener() { public void handleReturn(int replyCode, String replyText, String exchange, String routingKey, AMQP.BasicProperties properties, byte[] body) throws IOException { ... } }); 例如，客户端发布了一条带有mandatory标识的消息，此消息设置了交换机类型为“直连”，但是交换机并没有绑定到队列上，此时退还监听就会被调用。 关闭协议 客户端关闭进程概览 AMQP 0-9-1连接和通道使用相同的通用方法来管理网络故障，内部故障和显式本地关闭。 AMQP 0-9-1连接和通道具有以下生命周期状态： 打开：对象可以使用了 正在关闭：已经明确通知对象在本地进行关闭，已经向所有支持的底层对象发出了关闭请求，并且正在等待其关闭过程完成 已关闭：对象已经接收到所有底层对方发出的关闭完成的通知，然后自己也完成了关闭操作。 这些对象只管完成关闭状态，而不关心造成关闭的原因是什么。像应用请求、客户端内部库错误、远程网络请求或者网络错误一概不管。 连接和通道对象会处理如下所示的跟关闭有关的方法： addShutdownListener(ShutdownListener listener) 和 removeShutdownListener(ShutdownListener listener)用来管理监听器，当对象转换为关闭状态时触发。需要注意的是，给一个已经关闭的对象添加关闭监听器会立即出发监听行为。 getCloseReason()用来获取对象关闭的原因 isOpen()在测试对象开启状态时很有用 close(int closeCode, String closeMessage)用来显式地通知对象执行关闭操作 监听器的简单应用如下： import com.rabbitmq.client.ShutdownSignalException; import com.rabbitmq.client.ShutdownListener; connection.addShutdownListener(new ShutdownListener() { public void shutdownCompleted(ShutdownSignalException cause) { ... } }); 有关关闭情况的信息 可以通过显式调用getCloseReason()方法或通过使用带有cause参数的ShutdownListener类的service(ShutdownSignalException cause)方法来获取ShutdownSignalException，其中包含有关关闭原因的所有可用信息。 ShutdownSignalException类提供了用于分析关闭原因的方法。通过调用isHardError()方法，我们可以知道是不是因为连接或者通道错误导致，getReason()则会以返回AMQP方法的方式提供关闭的有关信息，包括AMQP.Channel.Close或者AMQP.Connection.Close（如果是客户端库引起的异常，比如网络通讯失败则会返回null，这种情况可以通过getCause()来获取异常） public void shutdownCompleted(ShutdownSignalException cause) { if (cause.isHardError()) { Connection conn = (Connection)cause.getReference(); if (!cause.isInitiatedByApplication()) { Method reason = cause.getReason(); ... } ... } else { Channel ch = (Channel)cause.getReference(); ... } } 原子性和isOpen()方法的使用 由于通道和连接的isOpen()的返回值依赖于关闭原因是否存在，所以在生产环境中不建议使用这个方法。以下代码对竞争条件的可能性进行了说明： public void brokenMethod(Channel channel) { if (channel.isOpen()) { // The following code depends on the channel being in open state. // However there is a possibility of the change in the channel state // between isOpen() and basicQos(1) call ... channel.basicQos(1); } } 相反，我们应该忽略类似的检查，简单地尝试自己所需要执行的动作即可。如果代码执行过程中通道或者连接关闭了，会抛出ShutdownSignalException来表示对象是无效的。除此之外，我们还需要捕获由于代理意外关闭连接造成的SocketException和代理发起清理关闭所造成的ShutdownSignalException所引发的IOException异常。 public void validMethod(Channel channel) { try { ... channel.basicQos(1); } catch (ShutdownSignalException sse) { // possibly check if channel was closed // by the time we started action and reasons for // closing it ... } catch (IOException ioe) { // check why connection was closed ... } } 高级连接选项 消费者操作线程池 默认情况下，消费者线程（参见下边的 接收 ）会通过一个新的ExecutorService线程池分配。如果需要更大的控制权，可以使用newConnection()去应用ExecutorService以进行替代。这是一个应用一个比常规分配额更大的线程池的示例： ExecutorService es = Executors.newFixedThreadPool(20); Connection conn = factory.newConnection(es); Executors和ExecutorService类都在java.util.concurrent package里。 当连接关闭时，默认提供的ExecutorService也会执行shutdown()，但是用户提供的ExecutorService（如上所示）则不会执行shutdown()。提供自定义ExecutorService的客户端必须确保其最终会被关闭（即调用shutdown() 方法），否则线程池会影响JVM的中止。 相同的executor服务可能会被多个连接共享，或者接连不断的重复使用、重复连接，但是无论如何当它关闭后是不可以再用的。 应该在有证据表明处理消费回调存在严重瓶颈时才去考虑使用这个功能。如果没有或者只有少量消费者回调需要执行，那默认分配的线程就足够了。即使偶尔会有消费者活动陡增的情况，最初的负载是很小的，并且线程资源的分配和不能无限扩大。 主机列表的使用 把一个Address数组传给newConnection()是没问题的。Address是一个com.rabbitmq.client package中包含 主机 和 端口组件的简单的便捷类。 例如： Address[] addrArr = new Address[]{ new Address(hostname1, portnumber1) , new Address(hostname2, portnumber2)}; Connection conn = factory.newConnection(addrArr); 这样会先去尝试连接hostname1:portnumber1，失败的话会再尝试hostname2:portnumber2。返回的连接对象是第一次成功的数组元素的(没抛出IOException的话)。这跟分别设置主机和端口然后依次调用factory.newConnection()直到成功的操作一毛一样。 如果同时也提供了ExecutorService（在factory.newConnection(es, addrArr)中使用），那线程池也是对应的第一次成功连接的那个。 如果想要实现连接的更多控制，参见 服务发现支持. 使用AddressResolver接口实现服务发现 我们可以使用AddressResolver接口实现来改变连接时的端点解析算法： Connection conn = factory.newConnection(addressResolver); The AddressResolver interface is like the following: AddressResolver接口类似于： public interface AddressResolver { List getAddresses() throws IOException; } 就跟 主机列表一样，先尝试返回的第一个Address，如果失败了再试第二个，直到成功为止。 如果同时也提供了ExecutorService（在factory.newConnection(es, addrArr)中使用），那线程池也是对应的第一次成功连接的那个。 AddressResolver是实现自定义服务发现逻辑的最佳方式，在动态基础设施的状况下尤其有用。结合 自动发现]，客户端可以自动连接到首次启动时尚未出现故障的节点。姻亲和负载均衡是自定义AddressResolver能做的另外两个情景。 Java客户端附带了以下实现（详见javadoc）： DnsRecordIpAddressResolver：根据给定的主机名，返回其IP地址（针对DNS服务器平台的解析）。这对简单的基于DNS的如在均衡很帮助很大。 DnsSrvRecordAddressResolver：根据给定的服务的名字，返回其所在的主机名/端口对。搜索服务基于DNS SRV请求实现。如果需要类似于HashiCorp Consul的服务注册功能的话，这也相当实用。 心跳超时 想了解更多关于心跳的信息和如何在java客户端进行配置，请参阅Heartbeats guide 自定义线程工厂 类似 Google App Engine (GAE) 的环境能够 限制直接将线程实例化.想要在这种环境里使用RabbitMQ Java客户端，就需要使用适当的方法配置自定义的ThreadFactory来实例化线程，例如GAE 的 ThreadManager. 以下是针对Google App Engine的示例： import com.google.appengine.api.ThreadManager; ConnectionFactory cf = new ConnectionFactory(); cf.setThreadFactory(ThreadManager.backgroundThreadFactory()); 支持Java的非阻塞IO Java客户端4.0版本带来了对Java非阻塞IO（也叫Java NIO）的支持。NIO的目的不是为了比阻塞IO更快，而是为了更方便的实现简单的资源控制（这里指的是线程）。 在默认的阻塞IO模式下，每个连接使用一个线程去从网络套接字(network socket)读取内容。在NIO模式下，你可以控制读取和写入网络套接字的线程的数量。 如果你的Java进程使用了很多连接（数百个之多）的情况下，可以使用NIO模式。你需要使用比默认阻塞模式下更少的线程。设置合适的线程数量的情况下，你不会损失任何性能，特别是连接不是特别繁忙的情况下。 NIO需要显示的开启允许： ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.useNio(); The NIO mode can be configured through the NioParams class: NIO模式可以通过NioParams类进行配置： connectionFactory.setNioParams(new NioParams().setNbIoThreads(4)); 虽然NIO模式默认值是合理的，但是你也有可能需要根据自身的工作负载来对其进行修改。其中一些设置包括：使用的总的IO线程数量，缓存大小，IO循环所使用的服务执行器（service executor），内存中写队列的参数（将请求发送到网络之前写入队列）。阅读Javadoc来了解更多细节和默认值。 自动恢复网络故障 恢复连接 客户端和RabbitMQ节点之间的网络连接会发生失败。RabbitMQ的Java客户端支持自动恢复连接和拓扑（队列，交换机，绑定和消费者）。 多应用的自动恢复过程依照一下步骤进行： 重连 恢复连接监听 重开通道 恢复通道监听 恢复通道的basic.qos设置，发布确认和事务设置 拓扑的恢复包含以下动作，会应用到每个通道 重新声明交换机（预定义的除外） 重新声明队列 恢复所有绑定 恢复所有消费者 在Java客户端4.0.0版本中，自动恢复默认是开启的（拓扑的恢复也一样）。 拓扑恢复依赖于实体的每个连接缓存（队列，交换机，绑定，消费者）。当声明一个队列的时候，此队列也会被添加到缓存中。当它被删除或者列入删除计划时（例如是一个 自动删除队列），缓存会被移除。此模型有以下限制。 使用factory.setAutomaticRecoveryEnabled(boolean)方法开启或停用自动连接恢复。以下代码片段展示了如何显式地开启自动恢复（例如针对Java客户端4.0.0之前的版本）： ConnectionFactory factory = new ConnectionFactory(); factory.setUsername(userName); factory.setPassword(password); factory.setVirtualHost(virtualHost); factory.setHost(hostName); factory.setPort(portNumber); factory.setAutomaticRecoveryEnabled(true); // connection that will recover automatically Connection conn = factory.newConnection(); 如果因为异常导致恢复失败（比如RabbitMQ节点尚不可用），会在固定的时间间隔（默认5秒）进行重试。间隔可以进行配置： ConnectionFactory factory = new ConnectionFactory(); // attempt recovery every 10 seconds factory.setNetworkRecoveryInterval(10000); When a list of addresses is provided, the list is shuffled and all addresses are tried, one after the next: 当提供了地址列表的情况下，列表会被随机重排并逐一尝试： ConnectionFactory factory = new ConnectionFactory(); Address[] addresses = {new Address(\"192.168.1.4\"), new Address(\"192.168.1.5\")}; factory.newConnection(addresses); 连接的自动恢复何时会被触发? 如果开启了连接自动恢复，会依照一下时间来进行触发： 连接的I/O循环中抛出了I/O异常 套接字(socket)读操作超时 检测到服务器丢失 心跳 连接的I/O循环中抛出了其他不可预期的异常 以先发生的为准。 如果客户端到RabbitMQ节点的连接初始化失败，连接自动恢复不会生效。应用的开发者需要负责重试连接，记录下失败的尝试，实现重试的次数限制等。这里是一个非常基本的示例： ConnectionFactory factory = new ConnectionFactory(); // configure various connection settings try { Connection conn = factory.newConnection(); } catch (java.net.ConnectException e) { Thread.sleep(5000); // apply retry logic } 当连接被应用使用Connection.Close方法关闭的的情况下，连接恢复不会启动。 通道级异常不会触发任何恢复，因为这些异常通常指出的是应用程序中的语义问题（例如从一个不存在的队列进行消费）。 恢复监听 可以在可恢复的连接上注册一个或多个恢复监听。当连接恢复开启时，ConnectionFactory#newConnection和Connection#createChannel返回的连接实现了 com.rabbitmq.client.Recoverable，并且提供了两个相当具有描述性名字的方法。 addRecoveryListener removeRecoveryListener 请注意，当前需要将连接和通道强制转换为Recoverable才能使用这些方法。 对发布的影响 当连接失效时，通过Channel.basicPublish发布的消息会丢失掉。客户端不会将其放入队列以用连接恢复后进行投递。想要确认发布的消息是否已经到达RabbitMQ，应用需要使用 发布确认 并且解决连接失败。 拓扑恢复 拓扑的恢复涉及到交换机、队列、绑定和消费者的恢复。自动恢复启用时拓扑恢复也会随之启用。客户端的当代版本都默认启用了拓扑恢复。 有需要的话，拓扑恢复可以显式的关闭： ConnectionFactory factory = new ConnectionFactory(); Connection conn = factory.newConnection(); // enable automatic recovery (e.g. Java client prior 4.0.0) factory.setAutomaticRecoveryEnabled(true); // disable topology recovery factory.setTopologyRecoveryEnabled(false); 故障检测和恢复的限制 连接自动恢复有一些局限性和应用程序开发人员需要注意的有意设计的策略。 拓扑恢复依赖于实体的每个连接缓存（队列，交换机，绑定，消费者）。当声明一个队列的时候，此队列也会被添加到缓存中。当它被删除或者列入删除计划时（例如是一个 自动删除队列），缓存会被移除。这样就可以在不同的通道上声明和删除实体，而不会产生意外的结果。这也意味着，使用自动连接恢复的消费者标签（特定通道的标识符）在所有通道上必须是唯一的。 当连接断开或丢失时，需要花费一些时间进行检测。因此，库和应用程序意识到有连接失败之前有一个窗口期。在这端时间内发布的所有消息都将照常进行序列化并写入TCP套接字。只有通过发布者确认才能保证将它们成功交付给了代理：按照设计，AMQP 0-9-1的发布过程完全是异步的。 如果在启用了自动恢复的连接中检测到套接字或I / O操作错误，则恢复将在默认的5秒延迟后开始（这个延迟时间是可配置的）。 该设计假定即使许多网络故障是暂时的并且通常持续时间很短，但也不会立即就恢复。 延迟还可以避免在相同连接上发生服务器端资源清除（例如独占或自动删除队列删除）和打开新连接之间的资源竞争。 默认情况下，连接恢复尝试将以相同的时间间隔进行，直到成功打开新连接为止。 通过将实现RecoveryDelayHandler的实例化对象提供给ConnectionFactory＃setRecoveryDelayHandler，可以实现恢复延迟的动态化。 实现动态计算的延迟间隔应避免使用过低的值（根据经验，小于2秒就算过低了）。 当连接处于恢复状态时，在其通道上尝试进行的任何发布都将被拒绝，但也有例外。 客户端当前不对此类传出消息执行任何内部缓冲。 跟踪此类消息并在恢复成功后重新发布它们是应用程序开发人员的责任。 发布者确认是协议的扩展，发布者可以利用其避免消息丢失。 当发生通道级别异常而导致通道干壁时，连接恢复不会生效。 此类异常通常表示的是应用程序级别的问题。 库无法在这种情况下采取适合的应对措施。 如果通道的关闭是通过显式关闭的或者是由于上述通道级别异常引发的。 即使启动了连接恢复，也不会恢复已关闭的通道。 手动确认和自动恢复 当使用手动确认的情况下，可能会发生连接在消息投递成功但并未进行确认的空挡中失效的情况。在连接恢复后，RabbitMQ会在通道里重置投递标签。 这意味着旧的投递标签的basic.ack, basic.nack, 和 basic.reject 会导致通道异常发生。为了避免这种情况，RabbitMQ的Java客户端会保持对投递标签的追踪和更新，以使它们在恢复过程中单调增长。 之后，Channel.basicAck, Channel.basicNack, 和 Channel.basicReject会将调整后的传递标签转换为RabbitMQ使用的传递标签。 带有过时的投递标签的确认将不会发送。使用手动确认和自动恢复的应用必须能够对重新投递的消息进行处理。 通道的生命周期和拓扑恢复 连接自动恢复对应用程序开发人员来说应尽可能透明，这就是为什么即使好几个连接失效，然后在后台恢复的情况下，Channel实例任然会保持相同的原因。 从技术上讲，启用自动恢复时，通道实例充当代理或装饰器：它们将AMQP业务委派给实际的AMQP通道实现，并围绕它实施一些恢复机制。 这就是为什么您不应该在通道完成了一些资源创建（队列，交换，绑定）之后对其进行关闭，这会导致稍后的扑恢复失败。 在应用程序的整个生命周期中都应该保持通道的打开状态。 未处理的异常 跟连接、通道、恢复和消费者生命周期有关的未处理的异常会委托给“异常处理”。“异常处理”是对ExceptionHandler接口的一个实现。默认情况下，会使用DefaultExceptionHandler实例。它会把异常的细节打印到标准输出中。 也可以用ConnectionFactory#setExceptionHandler来覆盖默认异常处理。这会应用到所有通过工厂创建的连接中。 ConnectionFactory factory = new ConnectionFactory(); cf.setExceptionHandler(customHandler); 异常处理应该将异常记录到日志当中。 指标和监控 客户端会收集活动的连接的运行时指标（例如发布消息的数量）。指标收集是需要在ConnectionFactory级别使用setMetricsCollector(metricsCollector)方法进行配置的可选功能。此方法需要的MetricsCollector实例会在客户端代码中的多处用到。 4.3版本的客户端开始支持 Micrometer 和 Dropwizard Metrics ，开箱即用。 以下是收集的指标： 开启的连接数量 开启的通道数量 发布的消息数量 消费的消息数量 确认的消息数量 拒绝的消息数量 Micrometer 和 Dropwizard Metrics 都提供了与消息指标相关的计数器，也提供了平均速率，最后5分钟速率等。他们也支持用于监控和报告的通用工具（如 JMX, Graphite, Ganglia, Datadog等）。更多详细信息，下边会专门进行说明。 启用指标收集时，开发人员应牢记一些注意事项。 要使用Micrometer 或者 Dropwizard Metrics 的话，别忘了添加相关依赖（ (在Maven, Gradle, 或者 JAR 文件里)）到JVM classpath中。 指标的收集是可以扩展的。推荐为特定目的实现自定义的MetricsCollector。 虽然MetricsCollector是在ConnectionFactory层定义的，但是也可以在不同的实例中共享。 指标的收集不支持事务。举例来说，如果一个确认（acknowledgment）通过事务发送，然后事务回滚了，那这个确认就已经被客户端指标（很显然不是通过代理）累计了。需要注意的是，确认（acknowledgment）确实已经发送到代理了，然后又被事务回滚给清除了，所以客户端指标对于确认的处理是没问题的。总之，不要把客户端指标用作关键的业务逻辑，因为不保证它们完全准确无误。它们存在的目的在于简单的解释系统的运行情况并且让操作更具效率。 Micrometer的支持 首先指标收集已经被开启了： Micrometer 按照以下方式: ConnectionFactory connectionFactory = new ConnectionFactory(); MicrometerMetricsCollector metrics = new MicrometerMetricsCollector(); connectionFactory.setMetricsCollector(metrics); ... metrics.getPublishedMessages(); // get Micrometer's Counter object Micrometer支持 多种报告后台：Netflix Atlas, Prometheus, Datadog, Influx, JMX, 等。 通常情况下会将MeterRegistry的实例传给MicrometerMetricsCollector，这里是使用JMX的示例： JmxMeterRegistry registry = new JmxMeterRegistry(); MicrometerMetricsCollector metrics = new MicrometerMetricsCollector(registry); ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setMetricsCollector(metrics); Dropwizard Metrics的支持 如下开启指标收集的 Dropwizard 支持： ConnectionFactory connectionFactory = new ConnectionFactory(); StandardMetricsCollector metrics = new StandardMetricsCollector(); connectionFactory.setMetricsCollector(metrics); ... metrics.getPublishedMessages(); // get Metrics' Meter object Dropwizard Metrics支持多种报告后台: console, JMX, HTTP, Graphite, Ganglia, 等. 通常你可以将MetricsRegistry实例传给StandardMetricsCollector，以下是关于JMX的示例： MetricRegistry registry = new MetricRegistry(); StandardMetricsCollector metrics = new StandardMetricsCollector(registry); ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setMetricsCollector(metrics); JmxReporter reporter = JmxReporter .forRegistry(registry) .inDomain(\"com.rabbitmq.client.jmx\") .build(); reporter.start(); Google App Engine上的RabbitMQ Java客户端 Using RabbitMQ Java client on Google App Engine (GAE) requires using a custom thread factory that instantiates thread using GAE's ThreadManager (see above). In addition, it is necessary to set a low heartbeat interval (4-5 seconds) to avoid running into the low InputStream read timeouts on GAE: 要在Google App Engine (GAE)上使用RabbitMQ Java客户端的话，需要使用GAE's ThreadManager (see above)这个自定义的线程工具去实例化线程。另外需要设置一个比较低的心跳间隔（4-5秒）来避免GAE上的InputStream读取超时过低。 ConnectionFactory factory = new ConnectionFactory(); cf.setRequestedHeartbeat(5); 注意事项和限制 为了实现拓扑的自动恢复，RabbitMQ Java客户端维护了一个用于声明队列、交换机和绑定的缓存。缓存是按连接来对应的。欧谢RabbitMQ的功能会导致客户端无法观察到拓扑功能的变更，例如当队列因TTL被删除的情况。大多数情况下，RabbitMQ Java客户端会尝试让缓存实体无效： When a queue is deleted. 当队列被删除的时候。 When an exchange is deleted. 当交换机被删除的时候。 When a binding is deleted. 当绑定被删除的时候。 When a consumer is cancelled on an auto-deleted queue. 当消费者因队列的自动删除动作而被清理掉的时候。 When a queue or exchange is unbound from an auto-deleted exchange. 当交换机或队列从自动删的的交换机上解绑的时候。 但是，客户端无法跟踪单个连接以外的拓扑变化。 依赖于自动删除队列或交换机以及队列TTL（请注意：不是消息TTL！）和使用连接自动恢复的应用应该显式删除已知的未被使用或已被删除的实体，以清除客户端拓扑缓存。 Channel＃queueDelete，Channel＃exchangeDelete，Channel＃queueUnbind和Channel＃exchangeUnbind在RabbitMQ 3.3.x中是幂等的（删除不存在的内容不会导致异常）这个特性有助于实现这一操作。 远程过程调用-RPC (请求/回复)模式: 示例 为了方便编写程序，Java客户端提供了使用一个临时回复队列来实现的RpcClient类，这样就通过AMQP 0-9-1 实现了简单的 RPC-风格通讯。 此类没有在RPC属性和返回值方面新增任何特殊格式。它只是简单的实现了附带路由键发送消息到给定的交换机，并且等待在回复队列里等待回应的机制。 import com.rabbitmq.client.RpcClient; RpcClient rpc = new RpcClient(channel, exchangeName, routingKey); （此类使用AMQP 0-9-1的实现细节如下：发送请求消息时，其basic.correlation_id字段设置为该RpcClient实例的唯一值，而basic.reply_to设置为回复队列的名称。） 一旦创建了此类的实例，就可以使用一下任一方法来发送RPC请求了： byte[] primitiveCall(byte[] message); String stringCall(String message) Map mapCall(Map message) Map mapCall(Object[] keyValuePairs) primitiveCall方法将原始字节数组作为请求和响应主体进行传输。 方法stringCall是primitiveCall的一个轻量化封装，将消息正文作为默认字符编码的String实例来处理。 mapCall这种变体稍微有点复杂：他们将包含普通Java值的java.util.Map编码为AMQP 0-9-1二进制表来表示，并以相同的方式来对收到的响应进行解码。 （注意，此处可以使用哪种值类型有一些限制，详细信息请参见javadoc。） 所有编组/解组的便捷方法都使用primitiveCall作为传输机制，仅在它之上提供包装层。 TLS 的支持 可以通过 使用 TLS 加密客户端到代理之间的通讯。也可以支持客户端\\服务器身份认证（也叫对等认证）。以下是一个使用Java客户端实现的最原始的简单示例： ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"localhost\"); factory.setPort(5671); // Only suitable for development. // This code will not perform peer certificate chain verification and prone // to man-in-the-middle attacks. // See the main TLS guide to learn about peer verification and how to enable it. factory.useSslProtocol(); 注意，以上样例客户端默认不强制任何服务器验证（对等证书链认证），使用了”信任所有证书“的TrustManager。这在本地开发的时候很是方便，但是容易收到中间人攻击，所以 不推荐在用在生产环境中 想要对RabbitMQ的TSL支持进行进一步学习，可以参见TLS 指南。如果只打算配置Java客户端（特别是对等认证和信任管理者部分），可以只阅读一下TLS指南的 相关部分 即可。 OAuth 2 的支持 客户端可以通过 UAA这样的OAuth 2 服务器来进行身份认证。服务器端需要启用 OAuth 2 插件，并配置跟客户端使用同一个OAuth 2 服务器 。 获取 OAuth 2 令牌 Java客户端提供了OAuth2ClientCredentialsGrantCredentialsProvider类，用来从OAuth 2 客户端凭证流获取JWT令牌。客户端会在打开连接的时候将令牌放在password字段中进行发送。然后代理会在授权之前验证JWT令牌的签名、有效性和权限，并授予对请求的虚拟主机的访问权限。 优先使用OAuth2ClientCredentialsGrantCredentialsProviderBuilder来创建OAuth2ClientCredentialsGrantCredentialsProvider实例，然后用它来配置ConnectionFactory。以下片段展示了如何为配置 OAuth 2 插件的示例设置和创建OAuth 2 credentials provider实例： import com.rabbitmq.client.impl.OAuth2ClientCredentialsGrantCredentialsProvider. OAuth2ClientCredentialsGrantCredentialsProviderBuilder; ... CredentialsProvider credentialsProvider = new OAuth2ClientCredentialsGrantCredentialsProviderBuilder() .tokenEndpointUri(\"http://localhost:8080/uaa/oauth/token/\") .clientId(\"rabbit_client\").clientSecret(\"rabbit_secret\") .grantType(\"password\") .parameter(\"username\", \"rabbit_super\") .parameter(\"password\", \"rabbit_super\") .build(); connectionFactory.setCredentialsProvider(credentialsProvider); 在生产环境中，确认令牌断电URI使用的是HTTPS，并且根据需要为HTTPS请求配置了SSLContext（用来验证和信任OAuth 2 服务器的身份）。以下代码片段使用OAuth2ClientCredentialsGrantCredentialsProviderBuilder的tls().sslContext()方法实现了上边所提及事项： SSLContext sslContext = ... // create and initialise SSLContext CredentialsProvider credentialsProvider = new OAuth2ClientCredentialsGrantCredentialsProviderBuilder() .tokenEndpointUri(\"http://localhost:8080/uaa/oauth/token/\") .clientId(\"rabbit_client\").clientSecret(\"rabbit_secret\") .grantType(\"password\") .parameter(\"username\", \"rabbit_super\") .parameter(\"password\", \"rabbit_super\") .tls() // configure TLS .sslContext(sslContext) // set SSLContext .builder() // back to main configuration .build(); 更多选项请参照Javadoc。 刷新令牌 令牌是会或过期的，代理会拒绝带有过期令牌的连接所请求的操作。可以使用CredentialsProvider#refresh()在令牌过期前使用新令牌发送请求，以防止此情况的发生。应用自己来实现是比较麻烦的，所以Java客户端提供了DefaultCredentialsRefreshService来给予一定帮助。这个工具用来追踪使用的令牌，在过期前进行刷新，并将新令牌发送给所负责的连接。 以下代码片段展示了如何创建DefaultCredentialsRefreshService实例，并且将其配置到ConnectionFactory上。 import com.rabbitmq.client.impl.DefaultCredentialsRefreshService. DefaultCredentialsRefreshServiceBuilder; ... CredentialsRefreshService refreshService = new DefaultCredentialsRefreshServiceBuilder().build(); cf.setCredentialsRefreshService(refreshService); DefaultCredentialsRefreshService会在令牌有效期超过80%后进行刷新，例如，如果令牌在60分钟后过期，DefaultCredentialsRefreshService会在48分钟的时候进行刷新。这是默认的行为，更多的细节可以通过 Javadoc 了解。 获取帮助和提供建议 如果你对本指南的内容或RabbitMQ的其他主题有任何疑问。可以通多 RabbitMQ 邮件列表进行提问。 "},"tutorials_with_python/[1]Hello_World.html":{"url":"tutorials_with_python/[1]Hello_World.html","title":"Hello World","keywords":"","body":"介绍 RabbitMQ是一个消息代理。它的工作就是接收和转发消息。你可以把它想像成一个邮局：你把信件放入邮箱，邮递员就会把信件投递到你的收件人处。在这个比喻中，RabbitMQ就扮演着邮箱、邮局以及邮递员的角色。 RabbitMQ和邮局的主要区别在于，它处理纸张，而是接收、存储和发送消息（message）这种二进制数据。 下面是RabbitMQ和消息所涉及到的一些术语。 生产(Producing)的意思就是发送。发送消息的程序就是一个生产者(producer)。我们一般用\"P\"来表示: 队列(queue)就是存在于RabbitMQ中邮箱的名称。虽然消息的传输经过了RabbitMQ和你的应用程序，但是它只能被存储于队列当中。实质上队列就是个巨大的消息缓冲区，它的大小只受主机内存和硬盘限制。多个生产者（producers）可以把消息发送给同一个队列，同样，多个消费者（consumers）也能够从同一个队列（queue）中获取数据。队列可以绘制成这样（图上是队列的名称）： 在这里，消费（Consuming）和接收(receiving)是同一个意思。一个消费者（consumer）就是一个等待获取消息的程序。我们把它绘制为\"C\"： 需要指出的是生产者、消费者、代理需不要待在同一个设备上；事实上大多数应用也确实不在会将他们放在一台机器上。 Hello World! （使用pika 0.10.0 Python客户端） 接下来我们用Python写两个小程序。一个发送单条消息的生产者（producer）和一个接收消息并将其输出的消费者（consumer）。传递的消息是\"Hello World\"。 下图中，“P”代表生产者，“C”代表消费者，中间的盒子代表为消费者保留的消息缓冲区，也就是我们的队列。 生产者（producer）把消息发送到一个名为“hello”的队列中。消费者（consumer）从这个队列中获取消息。 RabbitMQ库 RabbitMQ使用的是AMQP 0.9.1协议。这是一个用于消息传递的开放、通用的协议。针对不同编程语言有大量的RabbitMQ客户端可用。在这个系列教程中，RabbitMQ团队推荐使用Pika这个Python客户端。大家可以通过pip这个包管理工具进行安装： 发送 我们第一个程序send.py会发送一个消息到队列中。首先要做的事情就是建立一个到RabbitMQ服务器的连接。 #!/usr/bin/env python import pika connection = pika.BlockingConnection(pika.ConnectionParameters('localhost')) channel = connection.channel() 现在我们已经跟本地机器的代理建立了连接。如果你想连接到其他机器的代理上，需要把代表本地的localhost改为指定的名字或IP地址。 接下来，在发送消息之前，我们需要确认服务于消费者的队列已经存在。如果将消息发送给一个不存在的队列，RabbitMQ会将消息丢弃掉。下面我们创建一个名为\"hello\"的队列用来将消息投递进去。 channel.queue_declare(queue='hello') 这时候我们就可以发送消息了，我们第一条消息只包含了Hello World!字符串，我们打算把它发送到hello队列。 在RabbitMQ中，消息是不能直接发送到队列中的，这个过程需要通过交换机（exchange）来进行。但是为了不让细节拖累我们的进度，这里我们只需要知道如何使用由空字符串表示的默认交换机即可。如果你想要详细了解交换机，可以查看我们教程的第三部分来获取更多细节。默认交换机比较特别，它允许我们指定消息究竟需要投递到哪个具体的队列中，队列名字需要在routing_key参数中指定。 channel.basic_publish(exchange='', routing_key='hello', body='Hello World!') print(\" [x] Sent 'Hello World!'\") 在退出程序之前，我们需要确认网络缓冲已经被刷写、消息已经投递到RabbitMQ。通过安全关闭连接可以做到这一点。 connection.close() 发送不成功！ 如果这是你第一次使用RabbitMQ，并且没有看到“Sent”消息出现在屏幕上，你可能会抓耳挠腮不知所以。这也许是因为没有足够的磁盘空间给代理使用所造成的（代理默认需要200MB的空闲空间），所以它才会拒绝接收消息。查看一下代理的日志文件进行确认，如果需要的话也可以减少限制。配置文件文档会告诉你如何更改磁盘空间限制（disk_free_limit）。 接收 我们的第二个程序receive.py，将会从队列中获取消息并将其打印到屏幕上。 这次我们还是需要要先连接到RabbitMQ服务器。连接服务器的代码和之前是一样的。 下一步也和之前一样，我们需要确认队列是存在的。我们可以多次使用queue_declare命令来创建同一个队列，但是只有一个队列会被真正的创建。 channel.queue_declare(queue='hello') 你也许要问: 为什么要重复声明队列呢 —— 我们已经在前面的代码中声明过它了。如果我们确定了队列是已经存在的，那么我们可以不这么做，比如此前预先运行了send.py程序。可是我们并不确定哪个程序会首先运行。这种情况下，在程序中重复将队列重复声明一下是种值得推荐的做法。 列出所有队列 你也许希望查看RabbitMQ中有哪些队列、有多少消息在队列中。此时你可以使用rabbitmqctl工具（使用有权限的用户）： sudo rabbitmqctl list_queues （在Windows中不需要sudo命令） rabbitmqctl list_queues 从队列中获取消息相对来说稍显复杂。需要为队列定义一个回调（callback）函数。当我们获取到消息的时候，Pika库就会调用此回调函数。这个回调函数会将接收到的消息内容输出到屏幕上。 def callback(ch, method, properties, body): print(\" [x] Received %r\" % body) 下一步，我们需要告诉RabbitMQ这个回调函数将会从名为\"hello\"的队列中接收消息： channel.basic_consume(callback, queue='hello', no_ack=True) 要成功运行这些命令，我们必须保证队列是存在的，我们的确可以确保它的存在——因为我们之前已经使用queue_declare将其声明过了。 no_ack参数稍后会进行介绍。 最后，我们运行一个用来等待消息数据并且在需要的时候运行回调函数的无限循环。 print(' [*] Waiting for messages. To exit press CTRL+C') channel.start_consuming() 将代码整合到一起 send.py的完整代码： #!/usr/bin/env python import pika connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.queue_declare(queue='hello') channel.basic_publish(exchange='', routing_key='hello', body='Hello World!') print(\" [x] Sent 'Hello World!'\") connection.close() (send.py源码) receive.py的完整代码： #!/usr/bin/env python import pika connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost')) channel = connection.channel() channel.queue_declare(queue='hello') def callback(ch, method, properties, body): print(\" [x] Received %r\" % body) channel.basic_consume(callback, queue='hello', no_ack=True) print(' [*] Waiting for messages. To exit press CTRL+C') channel.start_consuming() (receive.py源码) 现在我们可以在终端中尝试一下我们的程序了。首先我们启动一个消费者，它会持续的运行来等待投递到达。 python receive.py # => [*] Waiting for messages. To exit press CTRL+C # => [x] Received 'Hello World!' 然后启动生产者，生产者程序每次执行后都会停止运行。 python send.py # => [x] Sent 'Hello World!' 成功了！我们已经通过RabbitMQ发送第一条消息。你也许已经注意到了，receive.py程序并没有退出。它一直在准备获取消息，你可以通过Ctrl-C来中止它。 试下在新的终端中再次运行send.py。 我们已经学会如何发送消息到一个已知队列中并接收消息。是时候移步到第二部分了，我们将会建立一个简单的工作队列（work queue）。 原文：Hello WorldUpdated at 2017-06-16 "},"tutorials_with_python/[2]Work_Queues.html":{"url":"tutorials_with_python/[2]Work_Queues.html","title":"工作队列","keywords":"","body":" 原文：Work Queues状态：待校对翻译：Adam校对：Ping 工作队列 （使用pika 0.9.5 Python客户端） 在第一篇教程中，我们已经写了一个从已知队列中发送和获取消息的程序。在这篇教程中，我们将创建一个工作队列（Work Queue），它会发送一些耗时的任务给多个工作者（Worker）。 工作队列（又称：任务队列——Task Queues）是为了避免等待一些占用大量资源、时间的操作。当我们把任务（Task）当作消息发送到队列中，一个运行在后台的工作者（worker）进程就会取出任务然后处理。当你运行多个工作者（workers），任务就会在它们之间共享。 这个概念在网络应用中是非常有用的，它可以在短暂的HTTP请求中处理一些复杂的任务。 准备 之前的教程中，我们发送了一个包含“Hello World!”的字符串消息。现在，我们将发送一些字符串，把这些字符串当作复杂的任务。我们没有真实的例子，例如图片缩放、pdf文件转换。所以使用time.sleep()函数来模拟这种情况。我们在字符串中加上点号（.）来表示任务的复杂程度，一个点（.）将会耗时1秒钟。比如\"Hello...\"就会耗时3秒钟。 我们对之前教程的send.py做些简单的调整，以便可以发送随意的消息。这个程序会按照计划发送任务到我们的工作队列中。我们把它命名为new_task.py： import sys message = ' '.join(sys.argv[1:]) or \"Hello World!\" channel.basic_publish(exchange='', routing_key='hello', body=message) print \" [x] Sent %r\" % (message,) 我们的旧脚本（receive.py）同样需要做一些改动：它需要为消息体中每一个点号（.）模拟1秒钟的操作。它会从队列中获取消息并执行，我们把它命名为worker.py： import time def callback(ch, method, properties, body): print \" [x] Received %r\" % (body,) time.sleep( body.count('.') ) print \" [x] Done\" 循环调度: 使用工作队列的一个好处就是它能够并行的处理队列。如果堆积了很多任务，我们只需要添加更多的工作者（workers）就可以了，扩展很简单。 首先，我们先同时运行两个worker.py脚本，它们都会从队列中获取消息，到底是不是这样呢？我们看看。 你需要打开三个终端，两个用来运行worker.py脚本，这两个终端就是我们的两个消费者（consumers）—— C1 和 C2。 shell1$ python worker.py [*] Waiting for messages. To exit press CTRL+C shell2$ python worker.py [*] Waiting for messages. To exit press CTRL+C 第三个终端，我们用来发布新任务。你可以发送一些消息给消费者（consumers）： shell3$ python new_task.py First message. shell3$ python new_task.py Second message.. shell3$ python new_task.py Third message... shell3$ python new_task.py Fourth message.... shell3$ python new_task.py Fifth message..... 看看到底发送了什么给我们的工作者（workers）： shell1$ python worker.py [*] Waiting for messages. To exit press CTRL+C [x] Received 'First message.' [x] Received 'Third message...' [x] Received 'Fifth message.....' shell2$ python worker.py [*] Waiting for messages. To exit press CTRL+C [x] Received 'Second message..' [x] Received 'Fourth message....' 默认来说，RabbitMQ会按顺序得把消息发送给每个消费者（consumer）。平均每个消费者都会收到同等数量得消息。这种发送消息得方式叫做——轮询（round-robin）。试着添加三个或更多得工作者（workers）。 消息确认 当处理一个比较耗时得任务的时候，你也许想知道消费者（consumers）是否运行到一半就挂掉。当前的代码中，当消息被RabbitMQ发送给消费者（consumers）之后，马上就会在内存中移除。这种情况，你只要把一个工作者（worker）停止，正在处理的消息就会丢失。同时，所有发送到这个工作者的还没有处理的消息都会丢失。 我们不想丢失任何任务消息。如果一个工作者（worker）挂掉了，我们希望任务会重新发送给其他的工作者（worker）。 为了防止消息丢失，RabbitMQ提供了消息响应（acknowledgments）。消费者会通过一个ack（响应），告诉RabbitMQ已经收到并处理了某条消息，然后RabbitMQ就会释放并删除这条消息。 如果消费者（consumer）挂掉了，没有发送响应，RabbitMQ就会认为消息没有被完全处理，然后重新发送给其他消费者（consumer）。这样，及时工作者（workers）偶尔的挂掉，也不会丢失消息。 消息是没有超时这个概念的；当工作者与它断开连的时候，RabbitMQ会重新发送消息。这样在处理一个耗时非常长的消息任务的时候就不会出问题了。 消息响应默认是开启的。之前的例子中我们可以使用no_ack=True标识把它关闭。是时候移除这个标识了，当工作者（worker）完成了任务，就发送一个响应。 def callback(ch, method, properties, body): print \" [x] Received %r\" % (body,) time.sleep( body.count('.') ) print \" [x] Done\" ch.basic_ack(delivery_tag = method.delivery_tag) channel.basic_consume(callback, queue='hello') 运行上面的代码，我们发现即使使用CTRL+C杀掉了一个工作者（worker）进程，消息也不会丢失。当工作者（worker）挂掉这后，所有没有响应的消息都会重新发送。 忘记确认 一个很容易犯的错误就是忘了basic_ack，后果很严重。消息在你的程序退出之后就会重新发送，如果它不能够释放没响应的消息，RabbitMQ就会占用越来越多的内存。 为了排除这种错误，你可以使用rabbitmqctl命令，输出messages_unacknowledged字段： $ sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged Listing queues ... hello 0 0 ...done. 消息持久化 如果你没有特意告诉RabbitMQ，那么在它退出或者崩溃的时候，将会丢失所有队列和消息。为了确保信息不会丢失，有两个事情是需要注意的：我们必须把“队列”和“消息”设为持久化。 首先，为了不让队列消失，需要把队列声明为持久化（durable）： channel.queue_declare(queue='hello', durable=True) 尽管这行代码本身是正确的，但是仍然不会正确运行。因为我们已经定义过一个叫hello的非持久化队列。RabbitMq不允许你使用不同的参数重新定义一个队列，它会返回一个错误。但我们现在使用一个快捷的解决方法——用不同的名字，例如task_queue。 channel.queue_declare(queue='task_queue', durable=True) 这个queue_declare必须在生产者（producer）和消费者（consumer）对应的代码中修改。 这时候，我们就可以确保在RabbitMq重启之后queue_declare队列不会丢失。另外，我们需要把我们的消息也要设为持久化——将delivery_mode的属性设为2。 channel.basic_publish(exchange='', routing_key=\"task_queue\", body=message, properties=pika.BasicProperties( delivery_mode = 2, # make message persistent )) 注意：消息持久化 将消息设为持久化并不能完全保证不会丢失。以上代码只是告诉了RabbitMq要把消息存到硬盘，但从RabbitMq收到消息到保存之间还是有一个很小的间隔时间。因为RabbitMq并不是所有的消息都使用fsync(2)——它有可能只是保存到缓存中，并不一定会写到硬盘中。并不能保证真正的持久化，但已经足够应付我们的简单工作队列。如果你一定要保证持久化，你需要改写你的代码来支持事务（transaction）。 公平调度 你应该已经发现，它仍旧没有按照我们期望的那样进行分发。比如有两个工作者（workers），处理奇数消息的比较繁忙，处理偶数消息的比较轻松。然而RabbitMQ并不知道这些，它仍然一如既往的派发消息。 这时因为RabbitMQ只管分发进入队列的消息，不会关心有多少消费者（consumer）没有作出响应。它盲目的把第n-th条消息发给第n-th个消费者。 我们可以使用basic.qos方法，并设置prefetch_count=1。这样是告诉RabbitMQ，再同一时刻，不要发送超过1条消息给一个工作者（worker），直到它已经处理了上一条消息并且作出了响应。这样，RabbitMQ就会把消息分发给下一个空闲的工作者（worker）。 channel.basic_qos(prefetch_count=1) 关于队列大小 如果所有的工作者都处理繁忙状态，你的队列就会被填满。你需要留意这个问题，要么添加更多的工作者（workers），要么使用其他策略。 整合代码 new_task.py的完整代码： #!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters( host='localhost')) channel = connection.channel() channel.queue_declare(queue='task_queue', durable=True) message = ' '.join(sys.argv[1:]) or \"Hello World!\" channel.basic_publish(exchange='', routing_key='task_queue', body=message, properties=pika.BasicProperties( delivery_mode = 2, # make message persistent )) print \" [x] Sent %r\" % (message,) connection.close() (new_task.py源码) 我们的worker： #!/usr/bin/env python import pika import time connection = pika.BlockingConnection(pika.ConnectionParameters( host='localhost')) channel = connection.channel() channel.queue_declare(queue='task_queue', durable=True) print ' [*] Waiting for messages. To exit press CTRL+C' def callback(ch, method, properties, body): print \" [x] Received %r\" % (body,) time.sleep( body.count('.') ) print \" [x] Done\" ch.basic_ack(delivery_tag = method.delivery_tag) channel.basic_qos(prefetch_count=1) channel.basic_consume(callback, queue='task_queue') channel.start_consuming() (worker.py source) 使用消息响应和prefetch_count你就可以搭建起一个工作队列了。这些持久化的选项使得在RabbitMQ重启之后仍然能够恢复。 现在我们可以移步教程3学习如何发送相同的消息给多个消费者（consumers）。 "},"tutorials_with_python/[3]Publish_Subscribe.html":{"url":"tutorials_with_python/[3]Publish_Subscribe.html","title":"发布/订阅","keywords":"","body":" 原文：Publish/Subscribe状态：校对完毕翻译：Adam校对：Ping 发布／订阅 （使用pika 0.9.5 Python客户端） 在上篇教程中，我们搭建了一个工作队列，每个任务只分发给一个工作者（worker）。在本篇教程中，我们要做的跟之前完全不一样 —— 分发一个消息给多个消费者（consumers）。这种模式被称为“发布／订阅”。 为了描述这种模式，我们将会构建一个简单的日志系统。它包括两个程序——第一个程序负责发送日志消息，第二个程序负责获取消息并输出内容。 在我们的这个日志系统中，所有正在运行的接收方程序都会接受消息。我们用其中一个接收者（receiver）把日志写入硬盘中，另外一个接受者（receiver）把日志输出到屏幕上。 最终，日志消息被广播给所有的接受者（receivers）。 交换机（Exchanges） 前面的教程中，我们发送消息到队列并从中取出消息。现在是时候介绍RabbitMQ中完整的消息模型了。 让我们简单的概括一下之前的教程： 发布者（producer）是发布消息的应用程序。 队列（queue）用于消息存储的缓冲。 消费者（consumer）是接收消息的应用程序。 RabbitMQ消息模型的核心理念是：发布者（producer）不会直接发送任何消息给队列。事实上，发布者（producer）甚至不知道消息是否已经被投递到队列。 发布者（producer）只需要把消息发送给一个交换机（exchange）。交换机非常简单，它一边从发布者方接收消息，一边把消息推送到队列。交换机必须知道如何处理它接收到的消息，是应该推送到指定的队列还是是多个队列，或者是直接忽略消息。这些规则是通过交换机类型（exchange type）来定义的。 有几个可供选择的交换机类型：直连交换机（direct）, 主题交换机（topic）, （头交换机）headers和 扇型交换机（fanout）。我们在这里主要说明最后一个 —— 扇型交换机（fanout）。先创建一个fanout类型的交换机，命名为logs： channel.exchange_declare(exchange='logs', type='fanout') 扇型交换机（fanout）很简单，你可能从名字上就能猜测出来，它把消息发送给它所知道的所有队列。这正是我们的日志系统所需要的。 交换器列表 rabbitmqctl能够列出服务器上所有的交换器： $ sudo rabbitmqctl list_exchanges Listing exchanges ... logs fanout amq.direct direct amq.topic topic amq.fanout fanout amq.headers headers ...done. 这个列表中有一些叫做amq.*的交换器。这些都是默认创建的，不过这时候你还不需要使用他们。 匿名的交换器 前面的教程中我们对交换机一无所知，但仍然能够发送消息到队列中。因为我们使用了命名为空字符串(\"\")默认的交换机。 回想我们之前是如何发布一则消息： channel.basic_publish(exchange='', routing_key='hello', body=message) exchange参数就是交换机的名称。空字符串代表默认或者匿名交换机：消息将会根据指定的routing_key分发到指定的队列。 现在，我们就可以发送消息到一个具名交换机了： channel.basic_publish(exchange='logs', routing_key='', body=message) 临时队列 你还记得之前我们使用的队列名吗（ hello和task_queue）？给一个队列命名是很重要的——我们需要把工作者（workers）指向正确的队列。如果你打算在发布者（producers）和消费者（consumers）之间共享同队列的话，给队列命名是十分重要的。 但是这并不适用于我们的日志系统。我们打算接收所有的日志消息，而不仅仅是一小部分。我们关心的是最新的消息而不是旧的。为了解决这个问题，我们需要做两件事情。 首先，当我们连接上RabbitMQ的时候，我们需要一个全新的、空的队列。我们可以手动创建一个随机的队列名，或者让服务器为我们选择一个随机的队列名（推荐）。我们只需要在调用queue_declare方法的时候，不提供queue参数就可以了： result = channel.queue_declare() 这时候我们可以通过result.method.queue获得已经生成的随机队列名。它可能是这样子的：amq.gen-U0srCoW8TsaXjNh73pnVAw==。 第二步，当与消费者（consumer）断开连接的时候，这个队列应当被立即删除。exclusive标识符即可达到此目的。 result = channel.queue_declare(exclusive=True) 绑定（Bindings） 我们已经创建了一个扇型交换机（fanout）和一个队列。现在我们需要告诉交换机如何发送消息给我们的队列。交换器和队列之间的联系我们称之为绑定（binding）。 channel.queue_bind(exchange='logs', queue=result.method.queue) 现在，logs交换机将会把消息添加到我们的队列中。 绑定（binding）列表 你可以使用rabbitmqctl list_bindings 列出所有现存的绑定。 代码整合 发布日志消息的程序看起来和之前的没有太大区别。最重要的改变就是我们把消息发送给logs交换机而不是匿名交换机。在发送的时候我们需要提供routing_key参数，但是它的值会被扇型交换机（fanout exchange）忽略。以下是emit_log.py脚本： #!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters( host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='logs', exchange_type='fanout') message = ' '.join(sys.argv[1:]) or \"info: Hello World!\" channel.basic_publish(exchange='logs', routing_key='', body=message) print \" [x] Sent %r\" % (message,) connection.close() (emit_log.py 源文件) 正如你看到的那样，在连接成功之后，我们声明了一个交换器，这一个是很重要的，因为不允许发布消息到不存在的交换器。 如果没有绑定队列到交换器，消息将会丢失。但这个没有所谓，如果没有消费者监听，那么消息就会被忽略。 receive_logs.py的代码： #!/usr/bin/env python import pika connection = pika.BlockingConnection(pika.ConnectionParameters( host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='logs', exchange_type='fanout') result = channel.queue_declare(exclusive=True) queue_name = result.method.queue channel.queue_bind(exchange='logs', queue=queue_name) print ' [*] Waiting for logs. To exit press CTRL+C' def callback(ch, method, properties, body): print \" [x] %r\" % (body,) channel.basic_consume(callback, queue=queue_name, no_ack=True) channel.start_consuming() (receive_logs.py source) 这样我们就完成了。如果你想把日志保存到文件中，只需要打开控制台输入： $ python receive_logs.py > logs_from_rabbit.log 如果你想在屏幕中查看日志，那么打开一个新的终端然后运行： $ python receive_logs.py 当然还要发送日志： $ python emit_log.py 使用rabbitmqctl list_bindings你可确认已经创建的队列绑定。你可以看到运行中的两个receive_logs.py程序： $ sudo rabbitmqctl list_bindings Listing bindings ... ... logs amq.gen-TJWkez28YpImbWdRKMa8sg== [] logs amq.gen-x0kymA4yPzAT6BoC/YP+zw== [] ...done. 显示结果很直观：logs交换器把数据发送给两个系统命名的队列。这就是我们所期望的。 如何监听消息的子集呢？让我们移步教程4 "},"tutorials_with_python/[4]Routing.html":{"url":"tutorials_with_python/[4]Routing.html","title":"路由","keywords":"","body":" 原文：Routing状态：翻译完成翻译：Adam校对：Ping 路由(Routing) （使用pika 0.9.5 Python客户端） 在前面的教程中，我们实现了一个简单的日志系统。可以把日志消息广播给多个接收者。 本篇教程中我们打算新增一个功能 —— 使得它能够只订阅消息的一个字集。例如，我们只需要把严重的错误日志信息写入日志文件（存储到磁盘），但同时仍然把所有的日志信息输出到控制台中 绑定（Bindings） 前面的例子，我们已经创建过绑定（bindings），代码如下： channel.queue_bind(exchange=exchange_name, queue=queue_name) 绑定（binding）是指交换机（exchange）和队列（queue）的关系。可以简单理解为：这个队列（queue）对这个交换机（exchange）的消息感兴趣。 绑定的时候可以带上一个额外的routing_key参数。为了避免与basic_publish的参数混淆，我们把它叫做绑定键（binding key）。以下是如何创建一个带绑定键的绑定。 channel.queue_bind(exchange=exchange_name, queue=queue_name, routing_key='black') 绑定键的意义取决于交换机（exchange）的类型。我们之前使用过的扇型交换机（fanout exchanges）会忽略这个值。 直连交换机（Direct exchange） 我们的日志系统广播所有的消息给所有的消费者（consumers）。我们打算扩展它，使其基于日志的严重程度进行消息过滤。例如我们也许只是希望将比较严重的错误（error）日志写入磁盘，以免在警告（warning）或者信息（info）日志上浪费磁盘空间。 我们使用的扇型交换机（fanout exchange）没有足够的灵活性 —— 它能做的仅仅是广播。 我们将会使用直连交换机（direct exchange）来代替。路由的算法很简单 —— 交换机将会对绑定键（binding key）和路由键（routing key）进行精确匹配，从而确定消息该分发到哪个队列。 下图能够很好的描述这个场景： 在这个场景中，我们可以看到直连交换机 X和两个队列进行了绑定。第一个队列使用orange作为绑定键，第二个队列有两个绑定，一个使用black作为绑定键，另外一个使用green。 这样以来，当路由键为orange的消息发布到交换机，就会被路由到队列Q1。路由键为black或者green的消息就会路由到Q2。其他的所有消息都将会被丢弃。 多个绑定（Multiple bindings） 多个队列使用相同的绑定键是合法的。这个例子中，我们可以添加一个X和Q1之间的绑定，使用black绑定键。这样一来，直连交换机就和扇型交换机的行为一样，会将消息广播到所有匹配的队列。带有black路由键的消息会同时发送到Q1和Q2。 发送日志 我们将会发送消息到一个直连交换机，把日志级别作为路由键。这样接收日志的脚本就可以根据严重级别来选择它想要处理的日志。我们先看看发送日志。 我们需要创建一个交换机（exchange）： channel.exchange_declare(exchange='direct_logs', type='direct') 然后我们发送一则消息： channel.basic_publish(exchange='direct_logs', routing_key=severity, body=message) 我们先假设“severity”的值是info、warning、error中的一个。 订阅 处理接收消息的方式和之前差不多，只有一个例外，我们将会为我们感兴趣的每个严重级别分别创建一个新的绑定。 result = channel.queue_declare(exclusive=True) queue_name = result.method.queue for severity in severities: channel.queue_bind(exchange='direct_logs', queue=queue_name, routing_key=severity) 代码整合 emit_log_direct.py的代码： #!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters( host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='direct_logs', type='direct') severity = sys.argv[1] if len(sys.argv) > 1 else 'info' message = ' '.join(sys.argv[2:]) or 'Hello World!' channel.basic_publish(exchange='direct_logs', routing_key=severity, body=message) print \" [x] Sent %r:%r\" % (severity, message) connection.close() receive_logs_direct.py的代码： #!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters( host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='direct_logs', type='direct') result = channel.queue_declare(exclusive=True) queue_name = result.method.queue severities = sys.argv[1:] if not severities: print >> sys.stderr, \"Usage: %s [info] [warning] [error]\" % \\ (sys.argv[0],) sys.exit(1) for severity in severities: channel.queue_bind(exchange='direct_logs', queue=queue_name, routing_key=severity) print ' [*] Waiting for logs. To exit press CTRL+C' def callback(ch, method, properties, body): print \" [x] %r:%r\" % (method.routing_key, body,) channel.basic_consume(callback, queue=queue_name, no_ack=True) channel.start_consuming() 如果你希望只是保存warning和error级别的日志到磁盘，只需要打开控制台并输入： $ python receive_logs_direct.py warning error > logs_from_rabbit.log 如果你希望所有的日志信息都输出到屏幕中，打开一个新的终端，然后输入： $ python receive_logs_direct.py info warning error [*] Waiting for logs. To exit press CTRL+C 如果要触发一个error级别的日志，只需要输入： $ python emit_log_direct.py error \"Run. Run. Or it will explode.\" [x] Sent 'error':'Run. Run. Or it will explode.' 这里是完整的代码：(emit_log_direct.py和receive_logs_direct.py) "},"tutorials_with_python/[5]Topics.html":{"url":"tutorials_with_python/[5]Topics.html","title":"主题交换机","keywords":"","body":" 原文：Topics状态：翻译完成翻译：Ping校对：Ping 为什么需要主题交换机？ （使用Python 客户端 —— pika 0.9.8） 上一篇教程里，我们改进了我们的日志系统。我们使用直连交换机替代了扇型交换机，从只能盲目的广播消息改进为有可能选择性的接收日志。 尽管直连交换机能够改善我们的系统，但是它也有它的限制 —— 没办法基于多个标准执行路由操作。 在我们的日志系统中，我们不只希望订阅基于严重程度的日志，同时还希望订阅基于发送来源的日志。Unix工具syslog就是同时基于严重程度-severity (info/warn/crit...) 和 设备-facility (auth/cron/kern...)来路由日志的。 如果这样的话，将会给予我们非常大的灵活性，我们既可以监听来源于“cron”的严重程度为“critical errors”的日志，也可以监听来源于“kern”的所有日志。 为了实现这个目的，接下来我们学习如何使用另一种更复杂的交换机 —— 主题交换机。 主题交换机 发送到主题交换机（topic exchange）的消息不可以携带随意什么样子的路由键（routing_key），它的路由键必须是一个由.分隔开的词语列表。这些单词随便是什么都可以，但是最好是跟携带它们的消息有关系的词汇。以下是几个推荐的例子：\"stock.usd.nyse\", \"nyse.vmw\", \"quick.orange.rabbit\"。词语的个数可以随意，但是不要超过255字节。 绑定键也必须拥有同样的格式。主题交换机背后的逻辑跟直连交换机很相似 —— 一个携带着特定路由键的消息会被主题交换机投递给绑定键与之想匹配的队列。但是它的绑定键和路由键有两个特殊应用方式： * (星号) 用来表示一个单词. # (井号) 用来表示任意数量（零个或多个）单词。 下边用图说明： 这个例子里，我们发送的所有消息都是用来描述小动物的。发送的消息所携带的路由键是由三个单词所组成的，这三个单词被两个.分割开。路由键里的第一个单词描述的是动物的手脚的利索程度，第二个单词是动物的颜色，第三个是动物的种类。所以它看起来是这样的： ..。 我们创建了三个绑定：Q1的绑定键为 *.orange.*，Q2的绑定键为 *.*.rabbit 和 lazy.# 。 这三个绑定键被可以总结为： Q1 对所有的桔黄色动物都感兴趣。 Q2 则是对所有的兔子和所有懒惰的动物感兴趣。 一个携带有 quick.orange.rabbit 的消息将会被分别投递给这两个队列。携带着 lazy.orange.elephant 的消息同样也会给两个队列都投递过去。另一方面携带有 quick.orange.fox 的消息会投递给第一个队列，携带有 lazy.brown.fox 的消息会投递给第二个队列。携带有 lazy.pink.rabbit 的消息只会被投递给第二个队列一次，即使它同时匹配第二个队列的两个绑定。携带着 quick.brown.fox 的消息不会投递给任何一个队列。 如果我们违反约定，发送了一个携带有一个单词或者四个单词（\"orange\" or \"quick.orange.male.rabbit\"）的消息时，发送的消息不会投递给任何一个队列，而且会丢失掉。 但是另一方面，即使 \"lazy.orange.male.rabbit\" 有四个单词，他还是会匹配最后一个绑定，并且被投递到第二个队列中。 主题交换机 主题交换机是很强大的，它可以表现出跟其他交换机类似的行为 当一个队列的绑定键为 \"#\"（井号） 的时候，这个队列将会无视消息的路由键，接收所有的消息。 当 * (星号) 和 # (井号) 这两个特殊字符都未在绑定键中出现的时候，此时主题交换机就拥有的直连交换机的行为。 组合在一起 接下来我们会将主题交换机应用到我们的日志系统中。在开始工作前，我们假设日志的路由键由两个单词组成，路由键看起来是这样的：. 代码跟上一篇教程差不多。 emit_log_topic.py的代码： #!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters( host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='topic_logs', type='topic') routing_key = sys.argv[1] if len(sys.argv) > 1 else 'anonymous.info' message = ' '.join(sys.argv[2:]) or 'Hello World!' channel.basic_publish(exchange='topic_logs', routing_key=routing_key, body=message) print \" [x] Sent %r:%r\" % (routing_key, message) connection.close() receive_logs_topic.py的代码： #!/usr/bin/env python import pika import sys connection = pika.BlockingConnection(pika.ConnectionParameters( host='localhost')) channel = connection.channel() channel.exchange_declare(exchange='topic_logs', type='topic') result = channel.queue_declare(exclusive=True) queue_name = result.method.queue binding_keys = sys.argv[1:] if not binding_keys: print >> sys.stderr, \"Usage: %s [binding_key]...\" % (sys.argv[0],) sys.exit(1) for binding_key in binding_keys: channel.queue_bind(exchange='topic_logs', queue=queue_name, routing_key=binding_key) print ' [*] Waiting for logs. To exit press CTRL+C' def callback(ch, method, properties, body): print \" [x] %r:%r\" % (method.routing_key, body,) channel.basic_consume(callback, queue=queue_name, no_ack=True) channel.start_consuming() 执行下边命令 接收所有日志：python receive_logs_topic.py \"#\" 执行下边命令 接收来自”kern“设备的日志：python receive_logs_topic.py \"kern.*\" 执行下边命令 只接收严重程度为”critical“的日志：python receive_logs_topic.py \"*.critical\" 执行下边命令 建立多个绑定：python receive_logs_topic.py \"kern.*\" \"*.critical\" 执行下边命令 发送路由键为 \"kern.critical\" 的日志：python emit_log_topic.py \"kern.critical\" \"A critical kernel error\" 执行上边命令试试看效果吧。另外，上边代码不会对路由键和绑定键做任何假设，所以你可以在命令中使用超过两个路由键参数。 如果你现在还没被搞晕，想想下边问题: 绑定键为 * 的队列会取到一个路由键为空的消息吗？ 绑定键为 #.* 的队列会获取到一个名为..的路由键的消息吗？它会取到一个路由键为单个单词的消息吗？ a.*.# 和 a.#的区别在哪儿？ （完整代码参见emit_logs_topic.py and receive_logs_topic.py) 移步至教程 6 学习RPC。 "},"tutorials_with_python/[6]RPC.html":{"url":"tutorials_with_python/[6]RPC.html","title":"远程过程调用","keywords":"","body":" 原文：Remote procedure call (RPC)状态：翻译完成翻译：Ping校对：Ping 远程过程调用（RPC） （Python客户端 —— 使用 pika 0.9.8） 在第二篇教程中我们介绍了如何使用工作队列（work queue）在多个工作者（woker）中间分发耗时的任务。 可是如果我们需要将一个函数运行在远程计算机上并且等待从那儿获取结果时，该怎么办呢？这就是另外的故事了。这种模式通常被称为远程过程调用（Remote Procedure Call）或者RPC。 这篇教程中，我们会使用RabbitMQ来构建一个RPC系统：包含一个客户端和一个RPC服务器。现在的情况是，我们没有一个值得被分发的足够耗时的任务，所以接下来，我们会创建一个模拟RPC服务来返回斐波那契数列。 客户端接口 为了展示RPC服务如何使用，我们创建了一个简单的客户端类。它会暴露出一个名为“call”的方法用来发送一个RPC请求，并且在收到回应前保持阻塞。 fibonacci_rpc = FibonacciRpcClient() result = fibonacci_rpc.call(4) print \"fib(4) is %r\" % (result,) 关于RPC的注意事项： 尽管RPC在计算领域是一个常用模式，但它也经常被诟病。当一个问题被抛出的时候，程序员往往意识不到这到底是由本地调用还是由较慢的RPC调用引起的。同样的困惑还来自于系统的不可预测性和给调试工作带来的不必要的复杂性。跟软件精简不同的是，滥用RPC会导致不可维护的面条代码. 考虑到这一点，牢记以下建议： 确保能够明确的搞清楚哪个函数是本地调用的，哪个函数是远程调用的。给你的系统编写文档。保持各个组件间的依赖明确。处理错误案例。明了客户端改如何处理RPC服务器的宕机和长时间无响应情况。 当对避免使用RPC有疑问的时候。如果可以的话，你应该尽量使用异步管道来代替RPC类的阻塞。结果被异步地推送到下一个计算场景。 回调队列 一般来说通过RabbitMQ来实现RPC是很容易的。一个客户端发送请求信息，服务器端将其应用到一个回复信息中。为了接收到回复信息，客户端需要在发送请求的时候同时发送一个回调队列（callback queue）的地址。我们试试看： result = channel.queue_declare(exclusive=True) callback_queue = result.method.queue channel.basic_publish(exchange='', routing_key='rpc_queue', properties=pika.BasicProperties( reply_to = callback_queue, ), body=request) # ... and some code to read a response message from the callback_queue ... 消息属性 AMQP协议给消息预定义了一系列的14个属性。大多数属性很少会用到，除了以下几个： delivery_mode（投递模式）：将消息标记为持久的（值为2）或暂存的（除了2之外的其他任何值）。第二篇教程里接触过这个属性，记得吧？ content_type（内容类型）:用来描述编码的mime-type。例如在实际使用中常常使用application/json来描述JOSN编码类型。 reply_to（回复目标）：通常用来命名回调队列。 correlation_id（关联标识）：用来将RPC的响应和请求关联起来。 关联标识 上边介绍的方法中，我们建议给每一个RPC请求新建一个回调队列。这不是一个高效的做法，幸好这儿有一个更好的办法 —— 我们可以为每个客户端只建立一个独立的回调队列。 这就带来一个新问题，当此队列接收到一个响应的时候它无法辨别出这个响应是属于哪个请求的。correlation_id 就是为了解决这个问题而来的。我们给每个请求设置一个独一无二的值。稍后，当我们从回调队列中接收到一个消息的时候，我们就可以查看这条属性从而将响应和请求匹配起来。如果我们接手到的消息的correlation_id是未知的，那就直接销毁掉它，因为它不属于我们的任何一条请求。 你也许会问，为什么我们接收到未知消息的时候不抛出一个错误，而是要将它忽略掉？这是为了解决服务器端有可能发生的竞争情况。尽管可能性不大，但RPC服务器还是有可能在已将应答发送给我们但还未将确认消息发送给请求的情况下死掉。如果这种情况发生，RPC在重启后会重新处理请求。这就是为什么我们必须在客户端优雅的处理重复响应，同时RPC也需要尽可能保持幂等性。 总结 我们的RPC如此工作: 当客户端启动的时候，它创建一个匿名独享的回调队列。 在RPC请求中，客户端发送带有两个属性的消息：一个是设置回调队列的 reply_to 属性，另一个是设置唯一值的 correlation_id 属性。 将请求发送到一个 rpc_queue 队列中。 RPC工作者（又名：服务器）等待请求发送到这个队列中来。当请求出现的时候，它执行他的工作并且将带有执行结果的消息发送给reply_to字段指定的队列。 客户端等待回调队列里的数据。当有消息出现的时候，它会检查correlation_id属性。如果此属性的值与请求匹配，将它返回给应用。 整合到一起 rpc_server.py代码： #!/usr/bin/env python import pika connection = pika.BlockingConnection(pika.ConnectionParameters( host='localhost')) channel = connection.channel() channel.queue_declare(queue='rpc_queue') def fib(n): if n == 0: return 0 elif n == 1: return 1 else: return fib(n-1) + fib(n-2) def on_request(ch, method, props, body): n = int(body) print \" [.] fib(%s)\" % (n,) response = fib(n) ch.basic_publish(exchange='', routing_key=props.reply_to, properties=pika.BasicProperties(correlation_id = \\ props.correlation_id), body=str(response)) ch.basic_ack(delivery_tag = method.delivery_tag) channel.basic_qos(prefetch_count=1) channel.basic_consume(on_request, queue='rpc_queue') print \" [x] Awaiting RPC requests\" channel.start_consuming() 服务器端代码相当简单： （4）像往常一样，我们建立连接，声明队列 （11）我们声明我们的fibonacci函数，它假设只有合法的正整数当作输入。（别指望这个函数能处理很大的数值，函数递归你们都懂得...） （19）我们为 basic_consume 声明了一个回调函数，这是RPC服务器端的核心。它执行实际的操作并且作出响应。 （32）或许我们希望能在服务器上多开几个线程。为了能将负载平均地分摊到多个服务器，我们需要将 prefetch_count 设置好。 rpc_client.py 代码: #!/usr/bin/env python import pika import uuid class FibonacciRpcClient(object): def __init__(self): self.connection = pika.BlockingConnection(pika.ConnectionParameters( host='localhost')) self.channel = self.connection.channel() result = self.channel.queue_declare(exclusive=True) self.callback_queue = result.method.queue self.channel.basic_consume(self.on_response, no_ack=True, queue=self.callback_queue) def on_response(self, ch, method, props, body): if self.corr_id == props.correlation_id: self.response = body def call(self, n): self.response = None self.corr_id = str(uuid.uuid4()) self.channel.basic_publish(exchange='', routing_key='rpc_queue', properties=pika.BasicProperties( reply_to = self.callback_queue, correlation_id = self.corr_id, ), body=str(n)) while self.response is None: self.connection.process_data_events() return int(self.response) fibonacci_rpc = FibonacciRpcClient() print \" [x] Requesting fib(30)\" response = fibonacci_rpc.call(30) print \" [.] Got %r\" % (response,) 客户端代码稍微有点难懂： （7）建立连接、通道并且为回复（replies）声明独享的回调队列。 （16）我们订阅这个回调队列，以便接收RPC的响应。 （18）“on_response”回调函数对每一个响应执行一个非常简单的操作，检查每一个响应消息的correlation_id属性是否与我们期待的一致，如果一致，将响应结果赋给self.response，然后跳出consuming循环。 （23）接下来，我们定义我们的主要方法 call 方法。它执行真正的RPC请求。 （24）在这个方法中，首先我们生成一个唯一的 correlation_id 值并且保存起来，'on_response'回调函数会用它来获取符合要求的响应。 （25）接下来，我们将带有 reply_to 和 correlation_id 属性的消息发布出去。 （32）现在我们可以坐下来，等待正确的响应到来。 （33）最后，我们将响应返回给用户。 我们的RPC服务已经准备就绪了，现在启动服务器端： $ python rpc_server.py [x] Awaiting RPC requests 运行客户端，请求一个fibonacci队列。 $ python rpc_client.py [x] Requesting fib(30) 此处呈现的设计并不是实现RPC服务的唯一方式，但是他有一些重要的优势： 如果RPC服务器运行的过慢的时候，你可以通过运行另外一个服务器端轻松扩展它。试试在控制台中运行第二个 rpc_server.py 。 在客户端，RPC请求只发送或接收一条消息。不需要像 queue_declare 这样的异步调用。所以RPC客户端的单个请求只需要一个网络往返。 我们的代码依旧非常简单，而且没有试图去解决一些复杂（但是重要）的问题，如： 当没有服务器运行时，客户端如何作出反映。 客户端是否需要实现类似RPC超时的东西。 如果服务器发生故障，并且抛出异常，应该被转发到客户端吗？ 在处理前，防止混入无效的信息（例如检查边界） 如果你想做一些实验，你会发现rabbitmq-management plugin在观测队列方面是很有用处的。 （完整的rpc_client.py 和 rpc_server.py代码) "},"tutorials_with_csharp/HelloWorld.html":{"url":"tutorials_with_csharp/HelloWorld.html","title":"Hello World","keywords":"","body":" 原文：Hello World翻译：mr-ping 前置条件 本教程假设RabbitMQ已经安装在你本机的 (5672)端口。如果你使用了不同的主机、端口或者凭证，连接设置就需要作出一些对应的调整。 如何获得帮助 如果你在使用本教程的过程中遇到了麻烦，你可以通过邮件列表来联系我们。 介绍 RabbitMQ 是一个消息代理：它用来接收消息，并将其进行转发。 你可以把它想象成一个邮局：当你把想要邮寄的邮件放到邮箱里后，邮递员就会把邮件最终送达到目的地。 在这个比喻中，RabbitMQ既代表了邮箱，也同时扮演着邮局和邮递员的角色. RabbitMQ和邮局主要区别在于，RabbitMQ不处理纸质信件，取而代之，它接收、存储和转发的是被称为消息的二进制数据块。 下面介绍下通常情况下会用到的一些RabbitMQ和messaging术语： 生产就是指的发送。一个用来发送消息的生产者程序： 队列指的是存在于RabbitMQ当中的邮箱。虽然消息是在RabbbitMQ和你的应用程序之间流转，但他们是存储在队列中的。队列只收到主机内存和磁盘的限制，它实质上是存在于主机内存和硬盘中的消息缓冲区。多个生产者可以发送消息到同一个队列中，多个消费者也可以从同一个队列中接收消息。我们这样来描述一个队列： 消费跟接收基本是一个意思。一个消费者基本上就是一个用来等待接收消息的程序： 需要注意的是，生产者、消费者和代理不需要存在于同一个主机上; 实际上，大多数应用中也确实如此。另外，一个应用程序也可以同时充当生产者和消费者两个角色。 \"Hello World\" (使用 .NET/C# 客户端) 在教程的这个部分，我们会使用C#语言编写两个程序；一个生产者负责发送单条信息，一个消费者负责接收这条信息并将其打印出来。我们会有意忽略.NET 客户端接口的一些细节，专注于利用这个及其简单的例子来打开局面。这个例子就是传送\"Hello World\"消息。 下方的图例中，“P”是我们的生产者，“C”是我们的消费者。中间的盒子代表RabbitMQ中用来为消费者保持消息的缓冲区——队列。 [|||] -> (C)\"> .NET客户端库 RabbitMQ有多种协议可用。本教程用的是AMQP 0-9-1这个用于消息传输的，开放的通用协议。RabbitMQ有许多针对 不同语言的客户端。这里我们使用RabbitMQ出品的.NET客户端。 此客户端支持 .NET Core 以及 .NET Framework 4.5.1+。本教程会使用RabbitMQ .NET client 5.0 和 .NET Core，所以你需要确保已经安装了他们，并且配置到了PATH当中。 当然你也可以使用.NET Framework来完成这个教程，但是安装配置过程会有所不同。 RabbitMQ .NET 客户端 5.0 是通过nuget来分发的。 本教程假设你使用的是Windows中的powershell。在MacOS 和 Linux 中几乎所有的shell都可以正常完成我们的工作。 安装 首先，让我们验证一下你的PATH中是否有.NET Core工具连。 dotnet --help 这时应该会生成一个帮助信息。 现在我们来生成两个项目，一个作为发布者（译者注：指的就是生产者），一个作为消费者。 dotnet new console --name Send mv Send/Program.cs Send/Send.cs dotnet new console --name Receive mv Receive/Program.cs Receive/Receive.cs 这样就会分别创建两个名为Send和Receive的目录。 然后我们来添加客户端依赖。 cd Send dotnet add package RabbitMQ.Client dotnet restore cd ../Receive dotnet add package RabbitMQ.Client dotnet restore 这样.NET项目就配置成功，我们可以着手写代码了。 发送 [|||]\"> 我们将消息发布者（发送者）命名为Send.cs，将消息消费者（接收者）命名为Receive.cs。发布者将会连接到RabbitMQ，发送一条消息，然后退出。 在 Send.cs 中, 我们需要使用一些命名空间： using System; using RabbitMQ.Client; using System.Text; 配置类： class Send { public static void Main() { ... } } 然后创建到服务器的连接： class Send { public static void Main() { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using (var connection = factory.CreateConnection()) { using (var channel = connection.CreateModel()) { ... } } } } 此连接为我们抽象了套接字的链接，协议版本的协商以及验证。此处我们连接的是本地机器的代理，所以写的是localhost。如果我们打算链接其他机器上的代理，这里得写上那台机器的机器名或者IP地址。 接下来我们来创建一个信道，大部分API的工作都在此信道的基础上完成。 为了发送消息，我们必须声明一个用于送达消息的队列，然后我们会将消息发布到此队列中： using System; using RabbitMQ.Client; using System.Text; class Send { public static void Main() { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using(var connection = factory.CreateConnection()) using(var channel = connection.CreateModel()) { channel.QueueDeclare(queue: \"hello\", durable: false, exclusive: false, autoDelete: false, arguments: null); string message = \"Hello World!\"; var body = Encoding.UTF8.GetBytes(message); channel.BasicPublish(exchange: \"\", routingKey: \"hello\", basicProperties: null, body: body); Console.WriteLine(\" [x] Sent {0}\", message); } Console.WriteLine(\" Press [enter] to exit.\"); Console.ReadLine(); } } 队列的声明是幂等的，只有当这个队列不存在的时候才会被创建。消息的内容是一个比特数组，所以你可以按照自己的喜好对其进行编码。 当上方的代码运行完成之后，信道和连接会被销毁掉。以上就是我们的发布者。 这是完整的Send.cs类代码. 没有发送成功! 如果这是你第一次使用RabbitMQ，而且没有成功看到\"Sent\"信息的输出，估计你会抓耳挠腮，不得其解。有可能只是因为你的硬盘没有足够的空间了（默认需要50MB空闲空间），所以才会把消息拒绝掉。你可以查看代理日志文件来进行确认，并且降低此限制条件。配置文件文档 会告诉你如何设置disk_free_limit. 接收 消费者会监听来自与RabbitMQ的消息。所以不同于发布者只发送一条消息，我们会让消费者保持持续运行来监听消息，并将消息打印出来。 (C)\"> 此代码(在 Receive.cs中) 跟Send代码非常相似： using RabbitMQ.Client; using RabbitMQ.Client.Events; using System; using System.Text; 配置工作跟发布者是一样的；我们打开一个连接和一个信道，声明一个我们想要从其中获取消息的队列。注意这个队列需要与Send发布到信息的那个队列相匹配。 class Receive { public static void Main() { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using (var connection = factory.CreateConnection()) { using (var channel = connection.CreateModel()) { channel.QueueDeclare(queue: \"hello\", durable: false, exclusive: false, autoDelete: false, arguments: null); ... } } } } 你可能注意到了，这里我们又把队列声明了一次。这是因为，我们可能会先把消费者启动起来，而不是发布者。我们希望确保用于消费的队列是确实存在的。 接下来我们通知服务器可以将消息从队列里发送过来了。由于服务器会异步地将消息推送给我们，所以我们这里提供一个回调方法。这就是EventingBasicConsumer.Receivedevent所做的工作。 using RabbitMQ.Client; using RabbitMQ.Client.Events; using System; using System.Text; class Receive { public static void Main() { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using(var connection = factory.CreateConnection()) using(var channel = connection.CreateModel()) { channel.QueueDeclare(queue: \"hello\", durable: false, exclusive: false, autoDelete: false, arguments: null); var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) => { var body = ea.Body; var message = Encoding.UTF8.GetString(body); Console.WriteLine(\" [x] Received {0}\", message); }; channel.BasicConsume(queue: \"hello\", autoAck: true, consumer: consumer); Console.WriteLine(\" Press [enter] to exit.\"); Console.ReadLine(); } } } 这是 Receive.cs 类的完整代码. 将它们整合到一起 打开两个终端。 运行消费者： cd Receive dotnet run 然后运行生产者： cd Send dotnet run 消费者会接收到发布者通过RabbitMQ发送的消息，并将其打印出来。消费者会一直保持运行状态来等待接受消息（可以使用Ctrl-C 来将其停止），接下来我们可以试着在另一个终端里运行发布者代码来尝试发送消息了。 ß 接下来，我们可以移步第二部分 ，创建一个简单的工作队列。 "},"tutorials_with_csharp/WorkQueue.html":{"url":"tutorials_with_csharp/WorkQueue.html","title":"工作队列","keywords":"","body":" 原文：Work Queues翻译：mr-ping 前置条件 本教程假设RabbitMQ已经安装在你本机的 (5672)端口。如果你使用了不同的主机、端口或者凭证，连接设置就需要作出一些对应的调整。 如何获得帮助 如果你在使用本教程的过程中遇到了麻烦，你可以通过邮件列表来联系我们。 工作队列 (使用 .NET 客户端) 在第一个教程中，我们写了一个用于向命名过的队列发送消息并且从其中进行接收的程序。本教程中，我们会创建一个用于在多个工作者（worker）当中分发耗时任务的工作队列（work queue）。 工作队列 (亦称 任务队列) 的主要目的在于避免资源密集型任务被立即执行，执行者需要一直等到它完成为止。相反，我们会安排任务稍后完成。我们将任务封装成一条消息，并将其发送给队列。运行于后台的工作者程序会丢弃掉这条消息（译者注：首先从工作队列中接收到消息），并最终将消息所描述的任务执行完。当你有多个工作者的情况下，任务会在多个工作者中共享。 由于web应用无法在一个短暂的HTTP请求过程中执行比较复杂的任务，所以这种概念在web应用当中特别有用。 准备 上个教程中，我们发送了一条\"Hellow World!\"消息。这次，我们会发送一个用于表示复杂任务的字符串。由于我们当下没有一个类似于图片缩放，渲染pdf文件这种真实的任务需要执行，因此我们会使用Thread.Sleep()函数来伪造繁忙的状态（要使用有关线程的接口，需要在文件顶部添加using System.Threading;的引用）。我们会在字符串中使用英文句号来表示任务的复杂程度。每一个点代表一秒钟的工作者执行的耗时。举个例子，如果一个伪造的任务用Hello...来表示，那就意味着它会耗时三秒钟。 我们会稍微改造下上个教程中的Send程序，以便于可以通过命令行发送任意一条消息。这个程序会用来为我们的工作队列规划任务，让我们称它为NewTask： 跟 教程一 一样，我们需要生成两个项目： dotnet new console --name NewTask mv NewTask/Program.cs NewTask/NewTask.cs dotnet new console --name Worker mv Worker/Program.cs Worker/Worker.cs cd NewTask dotnet add package RabbitMQ.Client dotnet restore cd ../Worker dotnet add package RabbitMQ.Client dotnet restore var message = GetMessage(args); var body = Encoding.UTF8.GetBytes(message); var properties = channel.CreateBasicProperties(); properties.Persistent = true; channel.BasicPublish(exchange: \"\", routingKey: \"task_queue\", basicProperties: properties, body: body); 为从命令行参数获取消息内容提供一些帮助： private static string GetMessage(string[] args) { return ((args.Length > 0) ? string.Join(\" \", args) : \"Hello World!\"); } 上一版 Receive.cs 脚本也需要做一些修改：它需要为消息体中的每一个英文句号伪造一秒钟的工作耗时，所以我们将它拷贝到worker项目中，并做如下修改： var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) => { var body = ea.Body; var message = Encoding.UTF8.GetString(body); Console.WriteLine(\" [x] Received {0}\", message); int dots = message.Split('.').Length - 1; Thread.Sleep(dots * 1000); Console.WriteLine(\" [x] Done\"); }; channel.BasicConsume(queue: \"task_queue\", autoAck: true, consumer: consumer); 伪造任务来模拟执行时间： int dots = message.Split('.').Length - 1; Thread.Sleep(dots * 1000); 循环调度 使用任务队列所带来的一个高级特性是可以用简单的方式让工作具有并行执行的能力。如果我们建立的是一个阻塞的任务，那只需要通过添加更多的工作者就可以简便的进行扩展。 首先，让我们同事运行两个Worker实例。它们都可以从队列中获取消息。下面我们看看它们是如何工作的。 你需要打开三个控制台。两个用于运行Worker程序。它们分别代表两个消费者，命名为C1和C2。 # shell 1 cd Worker dotnet run # => [*] Waiting for messages. To exit press CTRL+C # shell 2 cd Worker dotnet run # => [*] Waiting for messages. To exit press CTRL+C 第三个控制台用来发布新任务。开启了消费者之后，你就可以发布新消息了： # shell 3 cd NewTask dotnet run \"First message.\" dotnet run \"Second message..\" dotnet run \"Third message...\" dotnet run \"Fourth message....\" dotnet run \"Fifth message.....\" 让我们看看投送给工作者的是什么内容： # shell 1 # => [*] Waiting for messages. To exit press CTRL+C # => [x] Received 'First message.' # => [x] Received 'Third message...' # => [x] Received 'Fifth message.....' # shell 2 # => [*] Waiting for messages. To exit press CTRL+C # => [x] Received 'Second message..' # => [x] Received 'Fourth message....' 默认情况下，RabbitMQ会将消息依次发送给下一个消费者。平均每个消费者会获得同样数量的消息。这种消息分发方法被称为循环法（round-robin）。你可以发布三条以上的消息来尝试一下。 消息确认 执行一个任务可能会耗时好几秒钟。你也许会好奇如果一个消费者在执行一个耗时任务时只完成了部分工作就挂掉的情况下会发生什么。在我们当前代码下，一旦RabbitMQ将消息投送给消费者后，它会立即将消息标示为删除状态。这个案例中，如果你将工作者杀掉的话，我们会丢失它正在处理的消息。如果有其他已经调度给这个工作者的消息没有完成，也会一起丢失。 但是我们不想丢失任何任务。如果一个工作者挂掉了，我们希望任务会投送给其他的工作者。 为了确保消息永不丢失，RabbitMQ支持 消息 确认。消费者回送一个确认信号——ack(nowledgement)给RabbitMQ，告诉它一条指定的消息已经接收到并且处理完毕，可以选择将消息删除掉了。 如果一个消费者在没有回送确认信号的情况下挂掉了（消费者的信道关闭，连接关闭或者TCP连接已经丢失），RabbitMQ会理解为此条消息没有被处理完成，并且重新将其放入队列。如果恰时有其他消费者在线，这条消息会立即被投送给其他的消费者。通过这种方式，你可以确定即使有工作者由于事故挂掉，也不会发生消息丢失的情况。 RabbitMQ不会有任何消息超时的机制，消费者挂掉之后RabbitMQ才会将此消息投送给其他消费者。所以即使消息处理需要话费超长的是时间也没有问题。 手动进行消息确认 默认为开启状态。上个例子中，我们明确地通过将autoAck (\"自动确认模式\")设置为true将其关闭掉了。这次我们移除掉这个标志，一旦任务完成，手动从工作者当中发送合适的确认标志。 var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) => { var body = ea.Body; var message = Encoding.UTF8.GetString(body); Console.WriteLine(\" [x] Received {0}\", message); int dots = message.Split('.').Length - 1; Thread.Sleep(dots * 1000); Console.WriteLine(\" [x] Done\"); channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false); }; channel.BasicConsume(queue: \"task_queue\", autoAck: false, consumer: consumer); 使用本代码，即使你在它运行时使用 CTRL+C杀掉工作者，也不会有任何东西丢失。稍后，挂掉的工作者当中未进行确认的消息会被重新投送。 确认信号必须在收到投送的同一个信道上发送。尝试在不同的信道上发送确认信号会引发信道级别的协议异常。 确认行为的文档指南 里有更多介绍。 忘记进行确认 忘记使用BasicAck是一个常见的错误。虽然是个简单的错误，但是后果严重。消息会在客户端退出后重新投送（就像是随机进行的重新投送），但是由于RabbitMQ无法释放任何未经确认的消息，内存占用会越来越严重。 想要对这种错误进行调试，你可以使用rabbitmqctl将“未经确认的消息”（messages_unacknowledged）字段打印出来 sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged On Windows, drop the sudo: 在Windows中，不需要sudo: rabbitmqctl.bat list_queues name messages_ready messages_unacknowledged 消息持久化 我们已经学过了如何让任务在消费者即使挂掉的情况也不会丢失。但我们的任务仍有可能在RabbitMQ服务器停机的时候丢失掉。 当RabbitMQ退出或崩溃的时候会忘记掉所有的队列，除非你告诉他不要这么做。如果想要确保消息不会丢失，我们需要做两件事，将队列和消息都标示成持久化。 首先，我们需要确保RabbitMQ永远不会将队列丢失。为了达到此目的，我们需要使用durable来将其持久化。 channel.QueueDeclare(queue: \"hello\", durable: true, exclusive: false, autoDelete: false, arguments: null); 虽然这个命令本身是正确的，但是它在我们当前的配置中并不起作用。原因是我们已经定义了一个名为hello的非持久化队列。RabbitMQ不允许用不同的参数去重新定义一个已经存在的队列，如果有程序尝试这样做的话，会收到一个错误的返回值。 但是有一个快捷的解决方案——我们可以定义一个不重名的队列，例如task_queue: channel.QueueDeclare(queue: \"task_queue\", durable: true, exclusive: false, autoDelete: false, arguments: null); 此QueueDeclare的改变需要应用到生产者和消费者两份代码当中。 当下，我们可以确认即使RabbitMQ重启，我们的task_queue队列也不会丢失。接下来，我们需要将IBasicProperties.SetPersistent设置为true，用来将我们的消息标示成持久化的。 var properties = channel.CreateBasicProperties(); properties.Persistent = true; 消息持久化的注释 将消息标示为持久化并不能完全保证消息不会丢失。尽管它会告诉RabbitMQ将消息存储到硬盘上，但是在RabbitMQ接收到消息并将其进行存储两个行为之间仍旧会有一个窗口期。同样的，RabbitMQ也不会对每一条消息执行fsync(2)，所以消息获取只是存到了缓存之中，而不是硬盘上。虽然持久化的保证不强，但是应对我们简单的任务队列已经足够了。如果你需要更强的保证，可以使用publisher confirms. 公平调度 你可能注意到了，调度依照我们希望的方式运行。例如在有两个工作者的情况下，当所有的奇数任务都很繁重而所有的偶数任务都很轻松的时候，其中一个工作者会一直处于忙碌之中而另一个几乎无事可做。RabbitMQ并不会对此有任何察觉，仍旧会平均分配消息。 这种情况发生的原因是由于当有消息进入队列时，RabbitMQ只负责将消息调度的工作，而不会检查某个消费者有多少未经确认的消息。它只是盲目的将第n个消息发送给第n个消费者而已。 要改变这种行为的话，我们可以在BasicQos方法中设置prefetchCount = 1。这样会告诉RabbitMQ一次不要给同一个worker提供多于一条的信息。话句话说，在一个工作者还没有处理完消息，并且返回确认标志之前，不要再给它调度新的消息。取而代之，它会将消息调度给下一个不再繁忙的工作者。 channel.BasicQos(0, 1, false); If all the workers are busy, your queue can fill up. You will want to keep an eye on that, and maybe add more workers, or have some other strategy. 整合到一起 最终的NewTask.cs 类代码： using System; using RabbitMQ.Client; using System.Text; class NewTask { public static void Main(string[] args) { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using(var connection = factory.CreateConnection()) using(var channel = connection.CreateModel()) { channel.QueueDeclare(queue: \"task_queue\", durable: true, exclusive: false, autoDelete: false, arguments: null); var message = GetMessage(args); var body = Encoding.UTF8.GetBytes(message); var properties = channel.CreateBasicProperties(); properties.Persistent = true; channel.BasicPublish(exchange: \"\", routingKey: \"task_queue\", basicProperties: properties, body: body); Console.WriteLine(\" [x] Sent {0}\", message); } Console.WriteLine(\" Press [enter] to exit.\"); Console.ReadLine(); } private static string GetMessage(string[] args) { return ((args.Length > 0) ? string.Join(\" \", args) : \"Hello World!\"); } } (NewTask.cs 源代码) 我们的 Worker.cs： using System; using RabbitMQ.Client; using RabbitMQ.Client.Events; using System.Text; using System.Threading; class Worker { public static void Main() { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using(var connection = factory.CreateConnection()) using(var channel = connection.CreateModel()) { channel.QueueDeclare(queue: \"task_queue\", durable: true, exclusive: false, autoDelete: false, arguments: null); channel.BasicQos(prefetchSize: 0, prefetchCount: 1, global: false); Console.WriteLine(\" [*] Waiting for messages.\"); var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) => { var body = ea.Body; var message = Encoding.UTF8.GetString(body); Console.WriteLine(\" [x] Received {0}\", message); int dots = message.Split('.').Length - 1; Thread.Sleep(dots * 1000); Console.WriteLine(\" [x] Done\"); channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false); }; channel.BasicConsume(queue: \"task_queue\", autoAck: false, consumer: consumer); Console.WriteLine(\" Press [enter] to exit.\"); Console.ReadLine(); } } } (Worker.cs 源代码) 使用消息确认和BasicQos，你可以设置一个工作队列。持久化选项可以使得任务即使在RabbitMQ重启后也不会丢失。 有关IModel方法和IBasicProperties的更多信息，请浏览RabbitMQ .NET client API reference online. 现在我们可以异步教程 3，学习将消息投送给多个消费者。 "},"tutorials_with_csharp/publish&subscribe.html":{"url":"tutorials_with_csharp/publish&subscribe.html","title":"发布/订阅","keywords":"","body":" 原文：Publish/Subscribe翻译：mr-ping 前置条件 本教程假设RabbitMQ已经安装在你本机的 (5672)端口。如果你使用了不同的主机、端口或者凭证，连接设置就需要作出一些对应的调整。 如何获得帮助 如果你在使用本教程的过程中遇到了麻烦，你可以通过邮件列表来联系我们。 发布/订阅 （使用 .NET 客户端） 在上个教程中，我们创建了一个工作队列。工作队列假设每个任务只会被推送给一个工作者。这部分，我们会做一些完全不同的事情——我们会将消息投送给多个消费者。这种模式被称为“发布/订阅”。 为了解释此种模式，我们将会建立一个简单的日志系统。它由两个程序组成——第一个会发送日志消息，第二个接收、并将其打印出来。 在我们的日志系统中，每一个接收程序的拷贝都会获取到消息。通过这种方式，我们可以做到让其中一个接收者将日志直接存储到硬盘上，同时运行的另一个接收者将日志输出到屏幕上用于查看。 实质上，发布的日志消息会广播给所有的接收者。 交换机 教程的上个部分里，我们通过一个队列来发送和接收消息。现在，是时候把完整的Rabbit消息模型模型介绍一下了。 让我们快速过一下上个教程中所涉及的内容。 一个“生产者”就是一个发送消息的用户应用程序。 一个“队列”就是存储消息的缓存。 一个“消费者”就是一个接收消息的用户应用程序。 RabbitMQ的消息模型中的核心思想就是生产者永远不会将任何消息直接发送给队列。实际上，通常情况下，生产者根本不知道它是否会将消息投送给任何一个队列。 真正的情况是，生产者只能将消息发送给一个交换机。交换机是个很简单概念。它做左手收生产者发送的消息，右手就将消息推送给队列。交换机必须明确的知道需要对接收到的消息做些什么。消息是需要追加到一个特定的队列中？是需要追加到多个队列中？还是需要被丢弃掉。交换机类型(exchange type)就是用来定义这种规则的。 这里有几个可用的交换机类型：直连交换机(direct), 主题交换机(topic), 头交换机(headers) 和扇形交换机(fanout)。我们会把关注点放在最后一个上。让我们来创建一个此种类型的交换机，将其命名为logs： channel.ExchangeDeclare(\"logs\", \"fanout\"); 扇形交换机非常简单。从名字就可猜出来，它只是负责将消息广播给所有它所知道的队列。这正是我们的日志系统所需要的。 交换机的监听 想要列出服务器上的交换机，可以运行rabbitmqctl这个非常有用的程序： sudo rabbitmqctl list_exchanges 在此列表中，会出现一些类似于amq.*的交换机以及默认（未命名）交换机。这些交换机是以默认方式创建的，但此刻并不需要用到它们。 默认交换机 教程的上一部分中，我们对交换机还一无所知，但是依然能将消息发送给队列。原因是我们使用了用空字符串(\"\")来标示的默认交换机。 回想一下之前我们是如何来发布消息的： var message = GetMessage(args); var body = Encoding.UTF8.GetBytes(message); channel.BasicPublish(exchange: \"\", routingKey: \"hello\", basicProperties: null, body: body); 第一个参数就是交换机的名字。空字符串用来表示默认或者无名交换机：如果队列存在的话，消息会依据路由键（routingKey）所指定的名称路由到队列中。 现在我们可以对命名过的交换机执行发布操作了： var message = GetMessage(args); var body = Encoding.UTF8.GetBytes(message); channel.BasicPublish(exchange: \"logs\", routingKey: \"\", basicProperties: null, body: body); 临时队列 你可能还记得我们上次使用的是命名过的队列（还记得hello和task_queue吗？）。可以对队列进行命名对我们来说是至关重要的——我们需要将工作者指向同一个队列。当你想在多个生产者和消费者之间共享一个队列时，给队列起个名字是很重要的。 但是我们的日志系统不需要如此。我们希望了解所有的消息，而不是其中的一个子集。而且我们只对当前正在流动的消息感兴趣，而不是那些老的消息。所以我们需要做两件事情来解决这个问题。 首先，如论我们何时连接到Rabbit，我们需要的是一个新鲜的空队列。想要做到这点，我们可以创建一个随机命名的队列，或者更简单一点——让服务器为我们选择一个随机队列名称。 其次，一旦消费者断开连接，队列需要被自动删除。 在.NET客户端中，当我们不给QueueDeclare()提供参数的情况下，就可以创建一个非持久化、独享的、可自动删除的拥有生成名称的队列。 var queueName = channel.QueueDeclare().QueueName; 你可以在guide on queues中学习到更多关于独享（exclusive）标识以及其他队列属性的相关信息。 此时，queueName包含的是一个随机的队列名称。看起来可能会类似于amq.gen-JzTY20BRgKO-HjmUJj0wLg这样。 绑定 我们已经创建了一个扇形交换机和一个队列。现在我们需要通知交换机将消息发送给我们的队列。交换机和队列之间的这种关系称为绑定(binding)。 channel.QueueBind(queue: queueName, exchange: \"logs\", routingKey: \"\"); 现在开始，logs交换机会将消息追加到我们的队列当中。 绑定的监听 你可以通过以下命令列出所有正在使用的绑定， rabbitmqctl list_bindings 组合到一起 用来发送日志消息的生产者程序看起来跟上个教程中的没多大区别。最重大的改变是，现在我们希望将消息发布到logs交换机而不是未命名的那个。发送的时候我们需要提供一个routingKey，但是它的值会被扇形交换机忽略掉。下边是EmitLog.cs文件： using System; using RabbitMQ.Client; using System.Text; class EmitLog { public static void Main(string[] args) { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using(var connection = factory.CreateConnection()) using(var channel = connection.CreateModel()) { channel.ExchangeDeclare(exchange: \"logs\", type: \"fanout\"); var message = GetMessage(args); var body = Encoding.UTF8.GetBytes(message); channel.BasicPublish(exchange: \"logs\", routingKey: \"\", basicProperties: null, body: body); Console.WriteLine(\" [x] Sent {0}\", message); } Console.WriteLine(\" Press [enter] to exit.\"); Console.ReadLine(); } private static string GetMessage(string[] args) { return ((args.Length > 0) ? string.Join(\" \", args) : \"info: Hello World!\"); } } (EmitLog.cs 源文件) 如你所见，建立连接之后，我们对交换机进行了声明。这一步是必需的，因为不允许发布消息到一个不存在的交换机。 如果尚未有队列绑定到交换机，消息会丢失掉，但是对我们来说无所谓；如果还没有消费者进行监听，我们可以安全的将消息丢弃掉。 ReceiveLogs.cs的代码： using System; using RabbitMQ.Client; using RabbitMQ.Client.Events; using System.Text; class ReceiveLogs { public static void Main() { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using(var connection = factory.CreateConnection()) using(var channel = connection.CreateModel()) { channel.ExchangeDeclare(exchange: \"logs\", type: \"fanout\"); var queueName = channel.QueueDeclare().QueueName; channel.QueueBind(queue: queueName, exchange: \"logs\", routingKey: \"\"); Console.WriteLine(\" [*] Waiting for logs.\"); var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) => { var body = ea.Body; var message = Encoding.UTF8.GetString(body); Console.WriteLine(\" [x] {0}\", message); }; channel.BasicConsume(queue: queueName, autoAck: true, consumer: consumer); Console.WriteLine(\" Press [enter] to exit.\"); Console.ReadLine(); } } } (ReceiveLogs.cs 源代码) 根据 教程一 所介绍的步骤生成 EmitLogs and ReceiveLogs项目。 如果你想要将日志保存到一个文件中，只需要在控制台中输入： cd ReceiveLogs dotnet run > logs_from_rabbit.log 如果你希望在屏幕上看到日志记录，打开一个新的终端并运行： cd ReceiveLogs dotnet run 当然，还需要通过以下方式发送日志： cd EmitLog dotnet run 使用rabbitmqctl list_bindings命令可以验证绑定和队列是否按照我们期望的方式正确运行。当有两个ReceiveLogs.cs程序运行的时候，你应该可以看到类似于这样的信息： sudo rabbitmqctl list_bindings # => Listing bindings ... # => logs exchange amq.gen-JzTY20BRgKO-HjmUJj0wLg queue [] # => logs exchange amq.gen-vso0PVvyiRIL2WoV3i48Yg queue [] # => ...done. 简单地对结果进行下解释：跟我们期待的一样，数据从logs交换机传输到两个由服务器命名的队列当中。 接下来，我们可以移步教程4来了解如何监听消息的子集。 "},"tutorials_with_csharp/routing.html":{"url":"tutorials_with_csharp/routing.html","title":"路由","keywords":"","body":" 原文：Routing翻译：mr-ping 前置条件 本教程假设RabbitMQ已经安装在你本机的 (5672)端口。如果你使用了不同的主机、端口或者凭证，连接设置就需要作出一些对应的调整。 如何获得帮助 如果你在使用本教程的过程中遇到了麻烦，你可以通过邮件列表来联系我们。 路由 （使用.NET客户端） 上个教程中，我们建立了一个简单的日志系统。我们可以将日志消息广播给多个接收者。 这个教程中我们会添加一个新功能——让它可以从日志消息中只订阅一个子集。例如，我们只将关键的错误消息定向到日志文件中（从而节省磁盘空间），同时仍旧可以将所有的日志消息打印到控制台上。 绑定 上个例子中，我们已经创建了绑定。代码如下： channel.QueueBind(queue: queueName, exchange: \"logs\", routingKey: \"\"); 一个绑定就是交换机和队列之间的一个关系。可以解读为：目标队列对此交换机的消息感兴趣。 绑定可以使用一个格外的routingKey参数。为了避免跟BasicPublish参数混淆，我们称其为绑定键(binding key)。以下是如何创建一个绑定键： channel.QueueBind(queue: queueName, exchange: \"direct_logs\", routingKey: \"black\"); 绑定键的实际意义依赖于交换机的类型。对于我们之前使用的扇形交换机来说，会简单的将其值忽略掉。 直连型交换机 上个教程中，我们的日志系统将所有的消息广播给所有的消费者。我们打算对其进行扩展以根据它们的严重性来进行过滤。例如，我们想要将日志写到磁盘上的脚本只接收关键性的错误，而不在警告信息和普通日志消息上浪费磁盘空间。 我们之前使用的扇形交换机不能提供足够的灵活性——它只能进行无意识的广播。 下面我们使用直连型交换机进行替代。直连型交换机背后的路由算法很简单——消息会传送给绑定键与消息的路由键完全匹配的那个队列。 为了说明这点，可以考虑如下设置： 这种配置下，我们可以看到有两个队列绑定到了直连交换机X上。第一个队列用的是橘色（orange）绑定键，第二个有两个绑定键，其中一个绑定键是黑色（black），另一个绑定键是绿色（green）。 在此设置中，发布到交换机的带有橘色（orange）路由键的消息会被路由给队列Q1。带有黑色（black）或绿色（green）路由键的消息会被路由给Q2。其他的消息则会被丢弃。 多个绑定 使用相同的绑定键来绑定多个队列是完全合法的。在我们的例子中，我们可以使用黑色（black）绑定键来绑定X和Q1。那种情况下，直连型交换机的行为就会跟扇形交换机类似，会将消息广播给所有匹配的队列。一个拥有黑色(black)路由键的消息会被头送给Q1和Q2两个队列。 使用相同的绑定键来绑定多个队列是完全合法的。在我们的例子中，我们可以使用黑色（black）绑定键来绑定X和Q1。那种情况下，直连型交换机（direct）的行为就会跟扇形交换机（fanout）类似，会将消息广播给所有匹配的队列。一个拥有黑色(black)路由键的消息会被头送给Q1和Q2两个队列。 发送日志 我们将会在我们日志系统中采用这种模式，将消息发送给直连交换机来替代扇形交换机。我们会提供日志的严重等级来作为路由键的值。通过这种方式脚本就可以选择其需要的严重等级来进行接收。首先让我们将关注点放到发送日志上： 像往常一样，首先我们需要创建一个交换机： channel.ExchangeDeclare(exchange: \"direct_logs\", type: \"direct\"); 然后，做好发送消息的准备： var body = Encoding.UTF8.GetBytes(message); channel.BasicPublish(exchange: \"direct_logs\", routingKey: severity, basicProperties: null, body: body); 为了保持简洁，我们假设严重等级只可以是'info', 'warning', 'error'其中一种。 订阅 除了我们会为每个我们感兴趣的严重等级创建一个新的绑定键之外，接收消息的工作方式跟前一个教程中几乎一样。 var queueName = channel.QueueDeclare().QueueName; foreach(var severity in args) { channel.QueueBind(queue: queueName, exchange: \"direct_logs\", routingKey: severity); } 整合到一起 EmitLogDirect.cs类的代码： using System; using System.Linq; using RabbitMQ.Client; using System.Text; class EmitLogDirect { public static void Main(string[] args) { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using(var connection = factory.CreateConnection()) using(var channel = connection.CreateModel()) { channel.ExchangeDeclare(exchange: \"direct_logs\", type: \"direct\"); var severity = (args.Length > 0) ? args[0] : \"info\"; var message = (args.Length > 1) ? string.Join(\" \", args.Skip( 1 ).ToArray()) : \"Hello World!\"; var body = Encoding.UTF8.GetBytes(message); channel.BasicPublish(exchange: \"direct_logs\", routingKey: severity, basicProperties: null, body: body); Console.WriteLine(\" [x] Sent '{0}':'{1}'\", severity, message); } Console.WriteLine(\" Press [enter] to exit.\"); Console.ReadLine(); } } ReceiveLogsDirect.cs的代码： using System; using RabbitMQ.Client; using RabbitMQ.Client.Events; using System.Text; class ReceiveLogsDirect { public static void Main(string[] args) { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using(var connection = factory.CreateConnection()) using(var channel = connection.CreateModel()) { channel.ExchangeDeclare(exchange: \"direct_logs\", type: \"direct\"); var queueName = channel.QueueDeclare().QueueName; if(args.Length { var body = ea.Body; var message = Encoding.UTF8.GetString(body); var routingKey = ea.RoutingKey; Console.WriteLine(\" [x] Received '{0}':'{1}'\", routingKey, message); }; channel.BasicConsume(queue: queueName, autoAck: true, consumer: consumer); Console.WriteLine(\" Press [enter] to exit.\"); Console.ReadLine(); } } } 跟往常一样创建项目（参见 教程一 ） 如果你只希望将'warning' 和 'error' (不包括 'info') 的日志信息保存到文件中，只需要打开一个控制台，输入： cd ReceiveLogsDirect dotnet run warning error > logs_from_rabbit.log 如果你希望将所有的日志信息显示在屏幕上，新开一个终端，做如下操作： cd ReceiveLogsDirect dotnet run info warning error # => [*] Waiting for logs. To exit press CTRL+C 例如，如果你想发送一条error的日志信息，只需要输入： cd EmitLogDirect dotnet run error \"Run. Run. Or it will explode.\" # => [x] Sent 'error':'Run. Run. Or it will explode.' (完整的 (EmitLogDirect.cs 源代码) 和 (ReceiveLogsDirect.cs 源代码)) 想要了解如何基于一种模式来监听消息，可以移步至 教程 5 。 "},"tutorials_with_csharp/Topics.html":{"url":"tutorials_with_csharp/Topics.html","title":"主题交换机","keywords":"","body":" 原文：Topics翻译：mr-ping 前置条件 本教程假设RabbitMQ已经安装在你本机的 (5672)端口。如果你使用了不同的主机、端口或者凭证，连接设置就需要作出一些对应的调整。 如何获得帮助 如果你在使用本教程的过程中遇到了麻烦，你可以通过邮件列表来联系我们。 主题 (使用.NET客户端) 上个教程里，我们对日志系统进行了改进。我们用直连交换机取代了只会无脑广播的扇形交换机，并且具备了选择性接收日志的能力。 尽管使用直连交换机来改进了我们的系统，但是仍有一点缺陷——仍然不能基于多个条件进行路由。 在我们的日志系统中，我们除了想要根据严重性来订阅消息外，还想根据发送日志的来源进行订阅。你之前有可能通过一个名叫 syslog的Unix工具了解过这种情形，它是通过严重性(info/warn/crit...)和设备(auth/cron/kern...)来对日志进行路由的。 通过多种条件进行路由会给我们带来很大的灵活性——比如可能我们想要监听的是来自'cron'的关键(critical)错误和来自 'kern'的所有日志。 想要在日志系统中实现以上的功能，我们需要学一下更复杂的主题交换机。 主题交换机 发送到主题交换机的消息所携带的路由键（routing_key）不能随意命名——它必须是一个用点号分隔的词列表。当中的词可以是任何单词，不过一般都会指定一些跟消息有关的特征作为这些单词。列举几个有效的路由键的例子：\"stock.usd.nyse\", \"nyse.vmw\", \"quick.orange.rabbit\"。只要不超过255个字节，词的长度由你来定。 绑定键（binding key）也得使用相同的格式。主题交换机背后的逻辑跟直连交换机比较相似——一条携带特定路由键（routing key）的消息会被投送给所有绑定键（binding key）与之相匹配的队列。尽管如此，仍然有两条与绑定键相关的特殊情况： `*` (星号) 能够替代一个单词。 `#` (井号) 能够替代零个或多个单词。 用一个例子可以很容易地解释： 此例中，我们将会发送用来描述动物的多条消息。发送的消息包含带有三个单词（两个点号）的路由键（routing key）。路由键中第一个单词描述速度，第二个单词是颜色，第三个是品种： \"..\"。 我们创建三个绑定：Q1通过\"*.orange.*\"绑定键进行绑定，Q2使用\"*.*.rabbit\" 和 \"lazy.#\"。 这些绑定可以总结为： Q1针对所有的橘色orange动物。 Q2针对每一个有关兔子rabbits和慵懒lazy的动物的消息。 一个带有\"quick.orange.rabbit\"绑定键的消息会给两个队列都进行投送。消息\"lazy.orange.elephant\"也会投送给这两个队列。另外一方面，\"quick.orange.fox\" 只会给第一个队列。\"lazy.pink.rabbit\"虽然与两个绑定键都匹配，但只会给第二个队列投送一遍。\"quick.brown.fox\" 没有匹配到任何绑定，因此会被丢弃掉。 如果我们破坏规则，发送的消息只带有一个或者四个单词，例如 \"orange\" 或者 \"quick.orange.male.rabbit\"会发生什么呢？结果是这些消息不会匹配到任何绑定，将会被丢弃。 另一方面，“lazy.orange.male.rabbit”即使有四个单词，也会与最后一个绑定匹配，并 被投送到第二个队列。 主题交换机 主题交换机非常强大，并且可以表现的跟其他交换机相似。 当一个队列使用\"#\"（井号）绑定键进行绑定。它会表现的像扇形交换机一样，不理会路由键，接收所有消息。 当绑定当中不包含任何一个 \"*\" (星号) 和 \"#\" (井号)特殊字符的时候，主题交换机会表现的跟直连交换机一毛一样。 整合到一起 我们将在日志系统中使用主题交换机。我们现从一个可行的假设开始，假设日志的路由键包含两个单词： \".\". 代码跟上个教程非常相似： EmitLogTopic.cs的代码： using System; using System.Linq; using RabbitMQ.Client; using System.Text; class EmitLogTopic { public static void Main(string[] args) { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using(var connection = factory.CreateConnection()) using(var channel = connection.CreateModel()) { channel.ExchangeDeclare(exchange: \"topic_logs\", type: \"topic\"); var routingKey = (args.Length > 0) ? args[0] : \"anonymous.info\"; var message = (args.Length > 1) ? string.Join(\" \", args.Skip( 1 ).ToArray()) : \"Hello World!\"; var body = Encoding.UTF8.GetBytes(message); channel.BasicPublish(exchange: \"topic_logs\", routingKey: routingKey, basicProperties: null, body: body); Console.WriteLine(\" [x] Sent '{0}':'{1}'\", routingKey, message); } } } ReceiveLogsTopic.cs的代码： using System; using RabbitMQ.Client; using RabbitMQ.Client.Events; using System.Text; class ReceiveLogsTopic { public static void Main(string[] args) { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using(var connection = factory.CreateConnection()) using(var channel = connection.CreateModel()) { channel.ExchangeDeclare(exchange: \"topic_logs\", type: \"topic\"); var queueName = channel.QueueDeclare().QueueName; if(args.Length { var body = ea.Body; var message = Encoding.UTF8.GetString(body); var routingKey = ea.RoutingKey; Console.WriteLine(\" [x] Received '{0}':'{1}'\", routingKey, message); }; channel.BasicConsume(queue: queueName, autoAck: true, consumer: consumer); Console.WriteLine(\" Press [enter] to exit.\"); Console.ReadLine(); } } } 运行一下例子： 接收所有日志： cd ReceiveLogsTopic dotnet run \"#\" 接收来自于\"kern\"设施的所有日志： cd ReceiveLogsTopic dotnet run \"kern.*\" 或者如果你只想接收跟”严重“（”critical“）程度有关的日志： cd ReceiveLogsTopic dotnet run \"*.critical\" 你可以创建多个绑定： cd ReceiveLogsTopic dotnet run \"kern.*\" \"*.critical\" 然后发送一个路由键为\"kern.critical\"的日志： cd EmitLogTopic dotnet run \"kern.critical\" \"A critical kernel error\" 有意思吧？需要注意的是代码并没有对路由键或者绑定键做任何假定，你仍然可以用多于两个路由参数。 (EmitLogTopic.cs的完整代码 和 ReceiveLogsTopic.cs) 接下来，可以教程 6会介绍到如何像远程过程调用一样操作一个往返的消息。 "},"tutorials_with_csharp/rpc.html":{"url":"tutorials_with_csharp/rpc.html","title":"远程过程调用","keywords":"","body":" 原文：Remote procedure call RPC翻译：mr-ping 前置条件 本教程假设RabbitMQ已经安装在你本机的 (5672)端口。如果你使用了不同的主机、端口或者凭证，连接设置就需要作出一些对应的调整。 如何获得帮助 如果你在使用本教程的过程中遇到了麻烦，你可以通过邮件列表来联系我们。 远程过程调用(RPC) (使用 .NET 客户端) 在第二个教程中，我们学习了如何使用工作队列 在多个工作者之间分配耗时任务。 不过如果我们需要在一个远程电脑上运行函数并且等待结果的时候会怎样呢。这又是另一个故事了。这种模式通常被称为远程过程调用或者RPC。 这个教程里，我们用RabbitMQ来建立一个RPC系统：一个客户端和一个可扩展的RPC服务器。因为没有任何耗时任务用于分发，我们会创建一个伪造的用来返回斐波那契数列的RPC服务。 客户端接口 为了说明如何使用一个RPC服务，我们创建一个简单的客户端类。它会暴露一个名为Call的方法，此方法发送一个RPC请求，然后阻塞到收到回答为止。 var rpcClient = new RPCClient(); Console.WriteLine(\" [x] Requesting fib(30)\"); var response = rpcClient.Call(\"30\"); Console.WriteLine(\" [.] Got '{0}'\", response); rpcClient.Close(); 有关RPC的说明 虽然RPC在运算中是个非常常见的模式，但是也常常被批评。问题出在程序员察觉不到函数调用是发生在本地还是发生在一个很慢的RPC当中。这种困惑导致了系统的不可预测性并且为调试增加了不必要的复杂度。跟简单的软件相比，RPC会导致不可维护的面条式代码（译者注：面条式代码在软件工程中是一种典型的反面模式）。 考虑到这点，请斟酌以下建议： 确保一眼就能看出来哪个方法是本地执行的，哪个方法是远程执行的。 给你的系统写好文档。让组件之间的依赖清晰可查。 处理错误用例。如果RPC宕掉的时间过长，客户端该如何反应。 当有疑虑的时候，请避免实用RPC。有可能的话，应该使用异步管道来替代RPC式的阻塞，从而将结果异步地推送给下一个计算阶段。 回调队列 通常情况下，通过RabbitMQ来使用RPC非常简单。一个客户端发送请求消息，一个服务器返回消息来进行响应。为了能够收到响应，我们需要发送一个带有回调队列地址的请求： var props = channel.CreateBasicProperties(); props.ReplyTo = replyQueueName; var messageBytes = Encoding.UTF8.GetBytes(message); channel.BasicPublish(exchange: \"\", routingKey: \"rpc_queue\", basicProperties: props, body: messageBytes); // ... then code to read a response message from the callback_queue ... // ... 然后代码从回调队列中读取返回的消息 ... 消息属性 AMQP 0-9-1 协议与定义了14个消息的属性。大部分属性很少会用到，不过以下几个例外： Persistent: 标示此信息为持久的（用值为2来表示）还是暂时的（2之外的其他任何值）。具体可以去 第二个教程 一探究竟。 DeliveryMode：那些熟悉协议的人可能会选择使用这个属性，而不是Persistent。他们办的是一个事情。 ContentType：用来描述编码的mime-type。例如对于经常用到的JSON编码来说，将此属性设置为application/json是一个很好的做法。 ReplyTo: 通常用来对一个回调队列进行命名。 CorrelationId: 用于将RPC响应和请求进行关联。 关联id 上面介绍的方法中，我们建议为每一个RPC请求创建一个回调队列。这样做效率很低，幸好我们有更好的解决办法，让我们为每个客户端创建一个单独的回调队列。 这样又有一个新问题，当我们从此队列里收到一个响应的时候并不清楚它是属于哪个请求的。这就是CorrelationId属性的用途所在了。我们为每一个请求将其设置为一个唯一值。稍后，当我们从回调队列里收到一条消息的时候，就可以通过这个属性来对响应和请求进行匹配。如果我们收到的消息的CorrelationId值是未知的，那就可以安心的把它丢弃掉，因为它并不属于我们的请求。 或许你会问，我们为什么不把回调队列里的未知消息当成错误的失败来处理，而是要把它忽略掉？这是由于服务器端存在竞争条件的可能。虽然可能性不大，但是RPC服务器是有可能在发送给我们回应之后挂掉的，可此时它并没有完成为请求发回确认（acknowledgment）的动作。一旦这种情况发生，RPC服务器会再次将那条请求处理一遍。这就是为什么我们需要在客户端里优雅的处理重复的响应，并且在理想情况下，RPC应该是幂等的。 总结 我们的RPC看起来是这样的： 当客户端启动时，会创建一个匿名的独占回调队列。 客户端发送一条带有ReplyTo和CorrelationId两个属性的消息作为一个RPC请求，ReplyTo用于设置回调队列，CorrelationId用于为每一个请求设置一个独一无二的值。 请求被发送到一个rpc_queue队列。 RPC工作者（也称为服务器）等待从那个队列中接受请求。当一个请求出现的时候，他会执行任务并且通过ReplyTo 属性所提及的队列来将带有执行结果的消息发回给客户端。 客户端从回调队列那儿等待数据。当消息出现的时候，它会检查CorrelationId属性。如果属性值跟请求相匹配，就将响应返回给应用。 将代码整合到一起 斐波那契任务： private static int fib(int n) { if (n == 0 || n == 1) return n; return fib(n - 1) + fib(n - 2); } 我们定义了斐波那契函数。函数假设输入值是合法的正整数。（不要期望这个函数能作用于很大的数字，它可能是最慢的递归实现了）。 RPC服务器代码：RPCServer.cs 看起来像这样： using System; using RabbitMQ.Client; using RabbitMQ.Client.Events; using System.Text; class RPCServer { public static void Main() { var factory = new ConnectionFactory() { HostName = \"localhost\" }; using (var connection = factory.CreateConnection()) using (var channel = connection.CreateModel()) { channel.QueueDeclare(queue: \"rpc_queue\", durable: false, exclusive: false, autoDelete: false, arguments: null); channel.BasicQos(0, 1, false); var consumer = new EventingBasicConsumer(channel); channel.BasicConsume(queue: \"rpc_queue\", autoAck: false, consumer: consumer); Console.WriteLine(\" [x] Awaiting RPC requests\"); consumer.Received += (model, ea) => { string response = null; var body = ea.Body; var props = ea.BasicProperties; var replyProps = channel.CreateBasicProperties(); replyProps.CorrelationId = props.CorrelationId; try { var message = Encoding.UTF8.GetString(body); int n = int.Parse(message); Console.WriteLine(\" [.] fib({0})\", message); response = fib(n).ToString(); } catch (Exception e) { Console.WriteLine(\" [.] \" + e.Message); response = \"\"; } finally { var responseBytes = Encoding.UTF8.GetBytes(response); channel.BasicPublish(exchange: \"\", routingKey: props.ReplyTo, basicProperties: replyProps, body: responseBytes); channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false); } }; Console.WriteLine(\" Press [enter] to exit.\"); Console.ReadLine(); } } /// /// Assumes only valid positive integer input. /// Don't expect this one to work for big numbers, and it's /// probably the slowest recursive implementation possible. /// /// 假设输入值只能是合法的正整数。 /// 不要期望它能服务于很大的数字，它可能是最慢的递归实现了。 /// private static int fib(int n) { if (n == 0 || n == 1) { return n; } return fib(n - 1) + fib(n - 2); } } 服务器代码很简单： 跟之前一样，一开始我们建立连接、信道，并且声明队列。 可能我们会希望运行多个服务器进程。为了在多个服务器间均分负载，我们需要在channel.BasicQos中设置prefetchCount。 我们使用BasicConsume去访问队列。然后我们注册一个投递处理程序，我们在这个处理程序中完成工作并发回响应。 RPC客户端代码 RPCClient.cs： using System; using System.Collections.Concurrent; using System.Text; using RabbitMQ.Client; using RabbitMQ.Client.Events; public class RpcClient { private readonly IConnection connection; private readonly IModel channel; private readonly string replyQueueName; private readonly EventingBasicConsumer consumer; private readonly BlockingCollection respQueue = new BlockingCollection(); private readonly IBasicProperties props; public RpcClient() { var factory = new ConnectionFactory() { HostName = \"localhost\" }; connection = factory.CreateConnection(); channel = connection.CreateModel(); replyQueueName = channel.QueueDeclare().QueueName; consumer = new EventingBasicConsumer(channel); props = channel.CreateBasicProperties(); var correlationId = Guid.NewGuid().ToString(); props.CorrelationId = correlationId; props.ReplyTo = replyQueueName; consumer.Received += (model, ea) => { var body = ea.Body; var response = Encoding.UTF8.GetString(body); if (ea.BasicProperties.CorrelationId == correlationId) { respQueue.Add(response); } }; } public string Call(string message) { var messageBytes = Encoding.UTF8.GetBytes(message); channel.BasicPublish( exchange: \"\", routingKey: \"rpc_queue\", basicProperties: props, body: messageBytes); channel.BasicConsume( consumer: consumer, queue: replyQueueName, autoAck: true); return respQueue.Take(); ; } public void Close() { connection.Close(); } } public class Rpc { public static void Main() { var rpcClient = new RpcClient(); Console.WriteLine(\" [x] Requesting fib(30)\"); var response = rpcClient.Call(\"30\"); Console.WriteLine(\" [.] Got '{0}'\", response); rpcClient.Close(); } } 客户端代码稍显复杂： 我们创建一个连接和信道，并且声明一个独享的callback队列用于回复。 我们订阅callback队列，这样就可以接收到RPC的响应。 我们的Call方法生成实际的RPC请求。 这里，我们首先生成一个唯一的CorrelationId数字并且保存起来——整个循环都会使用这个值来获取相对应的响应。 接下来，我们发送带有ReplyTo 和 CorrelationId属性的请求信息。 此刻，我们可以坐等匹配的回应到来。 整个循环所做的工作很简单，就是检查每个响应消息，看它们是不是我们需要的那个。如果是的话就将响应保存起来。 最后我们将响应返回给用户。 生成客户端请求： var rpcClient = new RPCClient(); Console.WriteLine(\" [x] Requesting fib(30)\"); var response = rpcClient.Call(\"30\"); Console.WriteLine(\" [.] Got '{0}'\", response); rpcClient.Close(); 现在我们可以看看 RPCClient.cs 和 RPCServer.cs 的完整的样例代码了（代码里包含了简单的异常处理）。 像往常一样进行设置（见 tutorial one）： RPC服务已经就绪，让我们启动它： cd RPCServer dotnet run # => [x] Awaiting RPC requests 运行客户端来请求一个斐波那契数： cd RPCClient dotnet run # => [x] Requesting fib(30) 这里所呈现的设计方式并不是实现RPC服务的唯一方法，但是它具备一些重要的优势： 如果RPC服务器过慢，你可以通过再运行一个服务器来进行扩展。试试在一个新的控制台中运行第二个RPCServer吧。 在客户端这边，RPC只需要发送和接收一条消息。不需要类似QueueDeclare这样的同步调用。因此RPC客户端在一次RPC请求中，只需要进行一次网络的往返。 我们的代码依旧很简洁，并且只去尝试解决重要的而不是更加复杂的问题，比如： 如果没有服务器运行，客户端是不是要做出反应？ 客户端是不是需要有针对RPC的某种超时设置？ 如果服务器发生故障，抛出异常，是不是需要转发给客户端？ 在进行处理之前防止无效的消息传入（比如检查边界、类型）。 如果你想进行一下实验。会发现管理界面 对于浏览队列来说用处很大。 "},"tutorials_with_golang/[1]Hello_World.html":{"url":"tutorials_with_golang/[1]Hello_World.html","title":"Hello World","keywords":"","body":" 原文：Hello_World状态：待校对翻译：Bingjian-Zhu校对： 前提条件 本教程假设RabbitMQ已经安装在你本机的 (5672)端口。如果你使用了不同的主机、端口或者凭证，连接设置就需要作出一些对应的调整。 介绍 RabbitMQ是一个消息代理。它的工作就是接收和转发消息。你可以把它想像成一个邮局：你把信件放入邮箱，邮递员就会把信件投递到你的收件人处。在这个比喻中，RabbitMQ就扮演着邮箱、邮局以及邮递员的角色。 RabbitMQ和邮局的主要区别在于，它处理纸张，而是接收、存储和发送消息（message）这种二进制数据。 下面是RabbitMQ和消息所涉及到的一些术语。 生产(Producing)的意思就是发送。发送消息的程序就是一个生产者(producer)。我们一般用\"P\"来表示: 队列(queue)就是存在于RabbitMQ中邮箱的名称。虽然消息的传输经过了RabbitMQ和你的应用程序，但是它只能被存储于队列当中。实质上队列就是个巨大的消息缓冲区，它的大小只受主机内存和硬盘限制。多个生产者（producers）可以把消息发送给同一个队列，同样，多个消费者（consumers）也能够从同一个队列（queue）中获取数据。队列可以绘制成这样（图上是队列的名称）： 在这里，消费（Consuming）和接收(receiving)是同一个意思。一个消费者（consumer）就是一个等待获取消息的程序。我们把它绘制为\"C\"： Hello World! （使用Go客户端） 在本教程的这一部分中，我们将在Go中编写两个小程序：发送单个消息的生产者，以及接收消息并将其打印出来的消费者。我们将忽略Go RabbitMQ API中的一些细节，这里传递“Hello World”消息。 在下图中，“P”是生产者，“C”是消费者。中间的框是一个队列（保存消息的地方）。 [|||] -> (C)\"> Go RabbitMQ客户端库 RabbitMQ使用的是AMQP 0.9.1协议。这是一个用于消息传递的开放、通用的协议。针对不同编程语言有大量的RabbitMQ客户端可用。在本教程中，我们将使用Go amqp客户端。 首先，使用go get安装amqp：go get github.com/streadway/amqp 发送 [|||]\"> 我们将编写消息生产者（发送者）send.go和我们的消息消费者（接收者）receive.go。 发布者将连接到RabbitMQ，发送单个消息，然后退出。 在send.go中，我们需要先导入包： package main import ( \"log\" \"github.com/streadway/amqp\" ) 我们还需要一个辅助函数来检查每个amqp调用的返回值 func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } 然后连接到RabbitMQ服务器 conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() 配置连接套接字，它主要定义连接的协议和身份验证等。接下来，我们创建一个channel来传递消息： ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() 发送前，我们必须声明一个队列供我们发送，然后才能向队列发送消息： q, err := ch.QueueDeclare( \"hello\", // name false, // durable false, // delete when unused false, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") body := \"Hello World!\" err = ch.Publish( \"\", // exchange q.Name, // routing key false, // mandatory false, // immediate amqp.Publishing { ContentType: \"text/plain\", Body: []byte(body), }) failOnError(err, \"Failed to publish a message\") 声明队列是幂等的——只有在它不存在的情况下才会创建它。消息内容是一个字节数组，因此你可以编写任何内容。 (C)\"> 接收 以上是消息生产者。我们的消费者需要监听来自RabbitMQ的消息，因此与生产者不同，它需要持续运行以监听消息并将其打印出来 代码receive.go具有与send相同的导入包和辅助函数： package main import ( \"log\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } 设置与生产者相同，首先打开一个连接和一个Channel，并声明我们要消费的队列。请注意，这与发送的队列相匹配 conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() q, err := ch.QueueDeclare( \"hello\", // name false, // durable false, // delete when usused false, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") 注意，在这里也做了队列声明。因为消费者可能在生产者启动前就运行了，所以要确保使用消息之前队列已经存在。 我们即将告诉服务器从队列中传递消息。因为它会异步地向我们发送消息，所以我们将在goroutine中读取来自channel （由amqp :: Consume返回）的消息。 msgs, err := ch.Consume( q.Name, // queue \"\", // consumer true, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) failOnError(err, \"Failed to register a consumer\") forever := make(chan bool) go func() { for d := range msgs { log.Printf(\"Received a message: %s\", d.Body) } }() log.Printf(\" [*] Waiting for messages. To exit press CTRL+C\") receive.go 代码整合 运行生产者：go run send.go 运行消费者：go run receive.go 消费者将通过RabbitMQ打印从生产者处获得的消息。消费者将继续运行，等待消息（使用Ctrl-C停止消息）。可以尝试从另一个终端再次运行生产者来发送消息。 我们已经学会如何发送消息到一个已知队列中并接收消息。是时候移步到第二部分了，我们将会建立一个简单的工作队列（work queue）。 "},"tutorials_with_golang/[2]Work_Queues.html":{"url":"tutorials_with_golang/[2]Work_Queues.html","title":"工作队列","keywords":"","body":" 原文：Work Queues状态：待校对翻译：Bingjian-Zhu校对： 工作队列 （使用Go客户端） 在第一篇教程中，我们已经写了一个从已知队列中发送和获取消息的程序。在这篇教程中，我们将创建一个工作队列（Work Queue），它会发送一些耗时的任务给多个工作者（Worker）。 工作队列（又称：任务队列——Task Queues）是为了避免等待一些占用大量资源、时间的操作。当我们把任务（Task）当作消息发送到队列中，一个运行在后台的工作者（worker）进程就会取出任务然后处理。当你运行多个工作者（workers），任务就会在它们之间共享。 这个概念在网络应用中是非常有用的，它可以在短暂的HTTP请求中处理一些复杂的任务。 准备 之前的教程中，我们发送了一个包含“Hello World!”的字符串消息。现在，我们将发送一些字符串，把这些字符串当作复杂的任务。我们没有真实的例子，例如图片缩放、pdf文件转换。所以使用time.sleep()函数来模拟这种情况。我们在字符串中加上点号（.）来表示任务的复杂程度，一个点（.）将会耗时1秒钟。比如\"Hello...\"就会耗时3秒钟。 我们将稍微修改前面示例中的send.go代码，以允许从命令行发送任意消息。该程序将发送任务到我们的工作队列，所以我们将其命名为new_task.go： body := bodyFrom(os.Args) err = ch.Publish( \"\", // exchange q.Name, // routing key false, // mandatory false, amqp.Publishing { DeliveryMode: amqp.Persistent, ContentType: \"text/plain\", Body: []byte(body), }) failOnError(err, \"Failed to publish a message\") log.Printf(\" [x] Sent %s\", body) 我们旧的receive.go也需要进行一些更改：它需要为消息体中每一个点号（.）模拟1秒钟的操作。它会从队列中获取消息并执行，我们把它命名为worker.go: msgs, err := ch.Consume( q.Name, // queue \"\", // consumer true, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) failOnError(err, \"Failed to register a consumer\") forever := make(chan bool) go func() { for d := range msgs { log.Printf(\"Received a message: %s\", d.Body) dot_count := bytes.Count(d.Body, []byte(\".\")) t := time.Duration(dot_count) time.Sleep(t * time.Second) log.Printf(\"Done\") } }() log.Printf(\" [*] Waiting for messages. To exit press CTRL+C\") 请注意，我们的假任务模拟执行时间。 像在教程一中那样运行它们 # shell 1 go run worker.go # shell 2 go run new_task.go 循环调度: 使用工作队列的一个好处就是它能够并行的处理队列。如果堆积了很多任务，我们只需要添加更多的工作者（workers）就可以了，扩展很简单。 首先，我们先同时运行两个worker.go，它们都会从队列中获取消息，到底是不是这样呢？我们看看。 你需要打开三个终端，两个用来运行worker.go，这两个终端就是我们的两个消费者（consumers）—— C1 和 C2。 # shell 1 go run worker.go # => [*] Waiting for messages. To exit press CTRL+C # shell 2 go run worker.go # => [*] Waiting for messages. To exit press CTRL+C 第三个终端，我们用来发布新任务。你可以发送一些消息给消费者（consumers）： # shell 3 go run new_task.go First message. go run new_task.go Second message.. go run new_task.go Third message... go run new_task.go Fourth message.... go run new_task.go Fifth message..... 看看到底发送了什么给我们的工作者（workers）： # shell 1 go run worker.go # => [*] Waiting for messages. To exit press CTRL+C # => [x] Received 'First message.' # => [x] Received 'Third message...' # => [x] Received 'Fifth message.....' # shell 2 go run worker.go # => [*] Waiting for messages. To exit press CTRL+C # => [x] Received 'Second message..' # => [x] Received 'Fourth message....' 默认来说，RabbitMQ会按顺序得把消息发送给每个消费者（consumer）。平均每个消费者都会收到同等数量得消息。这种发送消息得方式叫做——轮询（round-robin）。试着添加三个或更多得工作者（workers）。 消息确认 当处理一个比较耗时得任务的时候，你也许想知道消费者（consumers）是否运行到一半就挂掉。当前的代码中，当消息被RabbitMQ发送给消费者（consumers）之后，马上就会在内存中移除。这种情况，你只要把一个工作者（worker）停止，正在处理的消息就会丢失。同时，所有发送到这个工作者的还没有处理的消息都会丢失。 我们不想丢失任何任务消息。如果一个工作者（worker）挂掉了，我们希望任务会重新发送给其他的工作者（worker）。 为了防止消息丢失，RabbitMQ提供了消息响应（acknowledgments）。消费者会通过一个ack（响应），告诉RabbitMQ已经收到并处理了某条消息，然后RabbitMQ就会释放并删除这条消息。 如果消费者（consumer）挂掉了，没有发送响应，RabbitMQ就会认为消息没有被完全处理，然后重新发送给其他消费者（consumer）。这样，即使工作者（workers）偶尔的挂掉，也不会丢失消息。 消息是没有超时这个概念的；当工作者与它断开连的时候，RabbitMQ会重新发送消息。这样在处理一个耗时非常长的消息任务的时候就不会出问题了。 在本教程中，我们将使用手动消息确认，通过为auto-ack参数传递false，一旦有任务完成，使用d.Ack（false）向RabbitMQ服务器发送消费完成的确认（这个确认消息是单次传递的）。 msgs, err := ch.Consume( q.Name, // queue \"\", // consumer false, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) failOnError(err, \"Failed to register a consumer\") forever := make(chan bool) go func() { for d := range msgs { log.Printf(\"Received a message: %s\", d.Body) dot_count := bytes.Count(d.Body, []byte(\".\")) t := time.Duration(dot_count) time.Sleep(t * time.Second) log.Printf(\"Done\") d.Ack(false) } }() log.Printf(\" [*] Waiting for messages. To exit press CTRL+C\") 运行上面的代码，我们发现即使使用CTRL+C杀掉了一个工作者（worker）进程，消息也不会丢失。当工作者（worker）挂掉这后，所有没有响应的消息都会重新发送。 忘记确认 忘记ack是一个常见的错误。这是一个简单的错误，但后果是严重的。当客户端退出时，消息将被重新传递（这可能看起来像随机重新传递），但是RabbitMQ将会占用越来越多的内存，因为它无法释放任何未经消息的消息 为了排除这种错误，你可以使用rabbitmqctl命令，输出messages_unacknowledged字段： sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged Windows上执行： rabbitmqctl.bat list_queues name messages_ready messages_unacknowledged 消息持久化 如果你没有特意告诉RabbitMQ，那么在它退出或者崩溃的时候，将会丢失所有队列和消息。为了确保信息不会丢失，有两个事情是需要注意的：我们必须把“队列”和“消息”设为持久化。 首先，为了不让队列消失，需要把队列声明为持久化（durable）： q, err := ch.QueueDeclare( \"hello\", // name true, // durable false, // delete when unused false, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") 尽管这行代码本身是正确的，但是达不到我们预期的结果。因为我们已经定义过一个叫hello的非持久化队列。RabbitMq不允许你使用不同的参数重新定义一个队列，它会返回一个错误。但我们现在使用一个快捷的解决方法——用不同的名字，例如task_queue。 q, err := ch.QueueDeclare( \"task_queue\", // name true, // durable false, // delete when unused false, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") 这个durable必须在生产者（producer）和消费者（consumer）对应的代码中修改。 此时，已经确保即使RabbitMQ重新启动，task_queue队列也不会丢失。现在我们需要将消息标记为持久性 - 通过设置amqp.Publishing的amqp.Persistent属性完成。 err = ch.Publish( \"\", // exchange q.Name, // routing key false, // mandatory false, amqp.Publishing { DeliveryMode: amqp.Persistent, ContentType: \"text/plain\", Body: []byte(body), }) 注意：消息持久化 将消息设为持久化并不能完全保证不会丢失。以上代码只是告诉了RabbitMq要把消息存到硬盘，但从RabbitMq收到消息到保存之间还是有一个很小的间隔时间。因为RabbitMq并不是所有的消息都使用fsync(2)——它有可能只是保存到缓存中，并不一定会写到硬盘中。并不能保证真正的持久化，但已经足够应付我们的简单工作队列。如果您需要更强的保证，那么您可以使用publisher confirms.。 公平调度 你应该已经发现，它仍旧没有按照我们期望的那样进行分发。比如有两个工作者（workers），处理奇数消息的比较繁忙，处理偶数消息的比较轻松。然而RabbitMQ并不知道这些，它仍然一如既往的派发消息。 这时因为RabbitMQ只管分发进入队列的消息，不会关心有多少消费者（consumer）没有作出响应。它盲目的把第n-th条消息发给第n-th个消费者。 我们可以设置预取计数值为1。告诉RabbitMQ一次只向一个worker发送一条消息。换句话说，在处理并确认前一个消息之前，不要向工作人员发送新消息。 err = ch.Qos( 1, // prefetch count 0, // prefetch size false, // global ) failOnError(err, \"Failed to set QoS\") 关于队列大小 如果所有的工作者都处理繁忙状态，你的队列就会被填满。你需要留意这个问题，要么添加更多的工作者（workers），要么使用其他策略。 整合代码 new_task.go的完整代码： package main import ( \"log\" \"os\" \"strings\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func main() { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() q, err := ch.QueueDeclare( \"task_queue\", // name true, // durable false, // delete when unused false, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") body := bodyFrom(os.Args) err = ch.Publish( \"\", // exchange q.Name, // routing key false, // mandatory false, amqp.Publishing{ DeliveryMode: amqp.Persistent, ContentType: \"text/plain\", Body: []byte(body), }) failOnError(err, \"Failed to publish a message\") log.Printf(\" [x] Sent %s\", body) } func bodyFrom(args []string) string { var s string if (len(args) (new_task.go源码) worker.go： package main import ( \"bytes\" \"github.com/streadway/amqp\" \"log\" \"time\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func main() { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() q, err := ch.QueueDeclare( \"task_queue\", // name true, // durable false, // delete when unused false, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") err = ch.Qos( 1, // prefetch count 0, // prefetch size false, // global ) failOnError(err, \"Failed to set QoS\") msgs, err := ch.Consume( q.Name, // queue \"\", // consumer false, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) failOnError(err, \"Failed to register a consumer\") forever := make(chan bool) go func() { for d := range msgs { log.Printf(\"Received a message: %s\", d.Body) dot_count := bytes.Count(d.Body, []byte(\".\")) t := time.Duration(dot_count) time.Sleep(t * time.Second) log.Printf(\"Done\") d.Ack(false) } }() log.Printf(\" [*] Waiting for messages. To exit press CTRL+C\") (worker.go 源码) 使用消息响应和prefetch_count你就可以搭建起一个工作队列了。这些持久化的选项使得在RabbitMQ重启之后仍然能够恢复。 现在我们可以移步教程3学习如何发送相同的消息给多个消费者（consumers）。 "},"tutorials_with_golang/[3]Publish_Subscribe.html":{"url":"tutorials_with_golang/[3]Publish_Subscribe.html","title":"发布/订阅","keywords":"","body":" 原文：Publish/Subscribe状态：待校对翻译：Bingjian-Zhu校对： 发布／订阅 （使用Go客户端） 在上篇教程中，我们搭建了一个工作队列，每个任务只分发给一个工作者（worker）。在本篇教程中，我们要做的跟之前完全不一样 —— 分发一个消息给多个消费者（consumers）。这种模式被称为“发布／订阅”。 为了描述这种模式，我们将会构建一个简单的日志系统。它包括两个程序——第一个程序负责发送日志消息，第二个程序负责获取消息并输出内容。 在我们的这个日志系统中，所有正在运行的接收方程序都会接受消息。我们用其中一个接收者（receiver）把日志写入硬盘中，另外一个接受者（receiver）把日志输出到屏幕上。 最终，日志消息被广播给所有的接受者（receivers）。 交换机（Exchanges） 前面的教程中，我们发送消息到队列并从中取出消息。现在是时候介绍RabbitMQ中完整的消息模型了。 让我们简单的概括一下之前的教程： 发布者（producer）是发布消息的应用程序。 队列（queue）用于消息存储的缓冲。 消费者（consumer）是接收消息的应用程序。 RabbitMQ消息模型的核心理念是：发布者（producer）不会直接发送任何消息给队列。事实上，发布者（producer）甚至不知道消息是否已经被投递到队列。 发布者（producer）只需要把消息发送给一个交换机（exchange）。交换机非常简单，它一边从发布者方接收消息，一边把消息推送到队列。交换机必须知道如何处理它接收到的消息，是应该推送到指定的队列还是是多个队列，或者是直接忽略消息。这些规则是通过交换机类型（exchange type）来定义的。 有几个可供选择的交换机类型：direct, topic, headers和fanout。我们在这里主要说明最后一个 —— fanout。先创建一个fanout类型的交换机，命名为logs： err = ch.ExchangeDeclare( \"logs\", // name \"fanout\", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) fanout交换机很简单，你可能从名字上就能猜测出来，它把消息发送给它所知道的所有队列。这正是我们的日志系统所需要的。 交换器列表 rabbitmqctl能够列出服务器上所有的交换器：sudo rabbitmqctl list_exchanges 这个列表中有一些叫做amq.*的匿名交换器。这些都是默认创建的，不过这时候你还不需要使用他们。 匿名的交换器 前面的教程中我们对交换机一无所知，但仍然能够发送消息到队列中。因为我们使用了命名为空字符串(\"\")的匿名交换机。 回想我们之前是如何发布一则消息： err = ch.Publish( \"\", // exchange q.Name, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", Body: []byte(body), }) exchange参数就是交换机的名称。空字符串代表默认或者匿名交换机，消息将会根据指定的routing_key分发到指定的队列。 现在，我们就可以发送消息到一个具名交换机了： err = ch.ExchangeDeclare( \"logs\", // name \"fanout\", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare an exchange\") body := bodyFrom(os.Args) err = ch.Publish( \"logs\", // exchange \"\", // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", Body: []byte(body), }) 临时队列 你还记得之前我们使用的队列名吗（ hello和task_queue）？给一个队列命名是很重要的——我们需要把工作者（workers）指向正确的队列。如果你打算在发布者（producers）和消费者（consumers）之间共享同队列的话，给队列命名是十分重要的。 但是这并不适用于我们的日志系统。我们打算接收所有的日志消息，而不仅仅是一小部分。我们关心的是最新的消息而不是旧的。为了解决这个问题，我们需要做两件事情。 首先，当我们连接上RabbitMQ的时候，我们需要一个全新的、空的队列。我们可以手动创建一个随机的队列名，或者让服务器为我们选择一个随机的队列名（推荐）。 其次，当与消费者（consumer）断开连接的时候，这个队列应当被立即删除。 在amqp客户端中，当我们将队列名称作为空字符串提供时，我们创建一个具有生成名称的非持久队列： q, err := ch.QueueDeclare( \"\", // name false, // durable false, // delete when usused true, // exclusive false, // no-wait nil, // arguments ) 该方法返回时，队列实例包含RabbitMQ生成的随机队列名称。例如，它可能看起来像amq.gen-JzTY20BRgKO-HjmUJj0wLg。 当声明它的连接关闭时，队列将被删除，因为它被声明为exclusive。 您可以在guide on queues了解有关exclusive和其他队列属性的更多信息 绑定（Bindings） 我们已经创建了一个fanout交换机和一个队列。现在我们需要告诉交换机如何发送消息给我们的队列。交换器和队列之间的联系我们称之为绑定（binding）。 err = ch.QueueBind( q.Name, // queue name \"\", // routing key \"logs\", // exchange false, nil, ) 现在，logs交换机将会把消息添加到我们的队列中。 绑定（binding）列表 你可以使用rabbitmqctl list_bindings 列出所有现存的绑定。 代码整合 发布日志消息的程序看起来和之前的没有太大区别。最重要的改变就是我们把消息发送给logs交换机而不是匿名交换机。在发送的时候我们需要提供routing_key参数，但可以忽略它的值。以下是emit_log.go： package main import ( \"log\" \"os\" \"strings\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func main() { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() err = ch.ExchangeDeclare( \"logs\", // name \"fanout\", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare an exchange\") body := bodyFrom(os.Args) err = ch.Publish( \"logs\", // exchange \"\", // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", Body: []byte(body), }) failOnError(err, \"Failed to publish a message\") log.Printf(\" [x] Sent %s\", body) } func bodyFrom(args []string) string { var s string if (len(args) (emit_log.go 源码) 正如你看到的那样，在连接成功之后，我们声明了一个交换器，这一个是很重要的，因为不允许发布消息到不存在的交换器。 如果没有绑定队列到交换器，消息将会丢失。但这个没有所谓，如果没有消费者监听，那么消息就会被忽略。 receive_logs.go:的代码： package main import ( \"log\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func main() { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() err = ch.ExchangeDeclare( \"logs\", // name \"fanout\", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare an exchange\") q, err := ch.QueueDeclare( \"\", // name false, // durable false, // delete when usused true, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") err = ch.QueueBind( q.Name, // queue name \"\", // routing key \"logs\", // exchange false, nil, ) failOnError(err, \"Failed to bind a queue\") msgs, err := ch.Consume( q.Name, // queue \"\", // consumer true, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) failOnError(err, \"Failed to register a consumer\") forever := make(chan bool) go func() { for d := range msgs { log.Printf(\" [x] %s\", d.Body) } }() log.Printf(\" [*] Waiting for logs. To exit press CTRL+C\") (receive_logs.go 源码) 这样我们就完成了。如果你想把日志保存到文件中，只需要打开控制台输入： $ go run receive_logs.go > logs_from_rabbit.log 如果你想在屏幕中查看日志，那么打开一个新的终端然后运行： $ go run receive_logs.go 当然还要发送日志： $ go run emit_log.go 使用rabbitmqctl list_bindings你可确认已经创建的队列绑定。你可以看到运行中的两个receive_logs.go程序： sudo rabbitmqctl list_bindings # => Listing bindings ... # => logs exchange amq.gen-JzTY20BRgKO-HjmUJj0wLg queue [] # => logs exchange amq.gen-vso0PVvyiRIL2WoV3i48Yg queue [] # => ...done. 显示结果很直观：logs交换器把数据发送给两个系统命名的队列。这就是我们所期望的。 如何监听消息的子集呢？让我们移步教程4 "},"tutorials_with_golang/[4]Routing.html":{"url":"tutorials_with_golang/[4]Routing.html","title":"路由","keywords":"","body":" 原文：Routing状态：待校对翻译：Bingjian-Zhu校对： 路由(Routing) （使用Go客户端） 在前面的教程中，我们实现了一个简单的日志系统。可以把日志消息广播给多个接收者。 本篇教程中我们打算新增一个功能 —— 使得它能够只订阅消息的一个字集。例如，我们只需要把严重的错误日志信息写入日志文件（存储到磁盘），但同时仍然把所有的日志信息输出到控制台中 绑定（Bindings） 前面的例子，我们已经创建过绑定（bindings），代码如下： err = ch.QueueBind( q.Name, // queue name \"\", // routing key \"logs\", // exchange false, nil) 绑定（binding）是指交换机（exchange）和队列（queue）的关系。可以简单理解为：这个队列（queue）对这个交换机（exchange）的消息感兴趣。 绑定的时候可以带上一个额外的routing_key参数。为了避免与Channel.Publish的参数混淆，我们把它叫做绑定键binding key。以下是如何创建一个带绑定键的绑定。 err = ch.QueueBind( q.Name, // queue name \"black\", // routing key \"logs\", // exchange false, nil) 绑定键的意义取决于交换机（exchange）的类型。我们之前使用过fanout 交换机会忽略这个值。 直连交换机（Direct exchange） 我们的日志系统广播所有的消息给所有的消费者（consumers）。我们打算扩展它，使其基于日志的严重程度进行消息过滤。例如我们也许只是希望将比较严重的错误（error）日志写入磁盘，以免在警告（warning）或者信息（info）日志上浪费磁盘空间。 我们使用的fanout 交换机没有足够的灵活性 —— 它能做的仅仅是广播。 我们将会使用direct 交换机来代替。路由的算法很简单 —— 交换机将会对binding key和routing key进行精确匹配，从而确定消息该分发到哪个队列。 下图能够很好的描述这个场景： 在这个场景中，我们可以看到direct交换机 X和两个队列进行了绑定。第一个队列使用orange作为binding key，第二个队列有两个绑定，一个使用black作为binding key，另外一个使用green。 这样以来，当消息发布到routing key为orange的交换机时，就会被路由到队列Q1。routing key为black或者green的消息就会路由到Q2。其他的所有消息都将会被丢弃。 多个绑定（Multiple bindings） 多个队列使用相同的binding key是合法的。这个例子中，我们可以添加一个X和Q1之间的绑定，使用black为binding key。这样一来，direct交换机就和fanout交换机的行为一样，会将消息广播到所有匹配的队列。带有routing key为black的消息会同时发送到Q1和Q2。 发送日志 我们将会发送消息到一个fanout，把日志等级作为routing key。这样接收日志就可以根据日志级别来选择它想要处理的日志。我们先看看发送日志。 我们需要创建一个交换机（exchange）： err = ch.ExchangeDeclare( \"logs_direct\", // name \"direct\", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) 然后我们发送一则消息： err = ch.ExchangeDeclare( \"logs_direct\", // name \"direct\", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare an exchange\") body := bodyFrom(os.Args) err = ch.Publish( \"logs_direct\", // exchange severityFrom(os.Args), // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", Body: []byte(body), }) 我们假设日志等级的值是info、warning、error中的一个。 订阅 处理接收消息的方式和之前差不多，只有一个例外，我们将会为我们感兴趣的每个严重级别分别创建一个新的绑定。 q, err := ch.QueueDeclare( \"\", // name false, // durable false, // delete when usused true, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") if len(os.Args) 代码整合 emit_log_direct.go的代码： package main import ( \"log\" \"os\" \"strings\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func main() { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() err = ch.ExchangeDeclare( \"logs_direct\", // name \"direct\", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare an exchange\") body := bodyFrom(os.Args) err = ch.Publish( \"logs_direct\", // exchange severityFrom(os.Args), // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", Body: []byte(body), }) failOnError(err, \"Failed to publish a message\") log.Printf(\" [x] Sent %s\", body) } func bodyFrom(args []string) string { var s string if (len(args) receive_logs_direct.go的代码： package main import ( \"log\" \"os\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func main() { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() err = ch.ExchangeDeclare( \"logs_direct\", // name \"direct\", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare an exchange\") q, err := ch.QueueDeclare( \"\", // name false, // durable false, // delete when usused true, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") if len(os.Args) 如果你希望只是保存warning和error级别的日志到磁盘，只需要打开控制台并输入： $ go run receive_logs_direct.go warning error > logs_from_rabbit.log 如果你希望所有的日志信息都输出到屏幕中，打开一个新的终端，然后输入： go run receive_logs_direct.go info warning error # => [*] Waiting for logs. To exit press CTRL+C 如果要触发一个error级别的日志，只需要输入： go run emit_log_direct.go error \"Run. Run. Or it will explode.\" # => [x] Sent 'error':'Run. Run. Or it will explode.' 这里是完整的代码：(emit_log_direct.go和receive_logs_direct.go) "},"tutorials_with_golang/[5]Topics.html":{"url":"tutorials_with_golang/[5]Topics.html","title":"主题交换机","keywords":"","body":" 原文：Topics状态：待校对翻译：Bingjian-Zhu校对： 为什么需要topic交换机？ （使用Go客户端） 上一篇教程，我们改进了我们的日志系统。我们使用direct交换机替代了fanout交换机，从只能盲目的广播消息改进为有可能选择性的接收日志。 尽管direct交换机能够改善我们的系统，但是它也有它的限制 —— 没办法基于多个标准执行路由操作。 在我们的日志系统中，我们不只希望订阅基于严重程度的日志，同时还希望订阅基于发送来源的日志。Unix工具syslog就是同时基于严重程度-severity (info/warn/crit...) 和 设备-facility (auth/cron/kern...)来路由日志的。 如果这样的话，将会给予我们非常大的灵活性，我们既可以监听来源于“cron”的严重程度为“critical errors”的日志，也可以监听来源于“kern”的所有日志。 为了实现这个目的，接下来我们学习如何使用另一种更复杂的交换机 —— topic交换机。 topic交换机 发送到topic交换机的消息不可以携带随意routing_key，它的routing_key必须是一个由.分隔开的词语列表。这些单词随便是什么都可以，但是最好是跟携带它们的消息有关系的词汇。以下是几个推荐的例子：\"stock.usd.nyse\", \"nyse.vmw\", \"quick.orange.rabbit\"。词语的个数可以随意，但是不要超过255字节。 binding key也必须拥有同样的格式。topic交换机背后的逻辑跟direct交换机很相似 —— 一个携带着特定routing_key的消息会被topic交换机投递给绑定键与之想匹配的队列。但是它的binding key和routing_key有两个特殊应用方式： * (星号) 用来表示一个单词. # (井号) 用来表示任意数量（零个或多个）单词。 下边用图说明： 这个例子里，我们发送的所有消息都是用来描述小动物的。发送的消息所携带的路由键是由三个单词所组成的，这三个单词被两个.分割开。路由键里的第一个单词描述的是动物的手脚的利索程度，第二个单词是动物的颜色，第三个是动物的种类。所以它看起来是这样的： ..。 我们创建了三个绑定：Q1的绑定键为 *.orange.*，Q2的绑定键为 *.*.rabbit 和 lazy.# 。 这三个绑定键被可以总结为： Q1 对所有的桔黄色动物都感兴趣。 Q2 则是对所有的兔子和所有懒惰的动物感兴趣。 一个携带有 quick.orange.rabbit 的消息将会被分别投递给这两个队列。携带着 lazy.orange.elephant 的消息同样也会给两个队列都投递过去。另一方面携带有 quick.orange.fox 的消息会投递给第一个队列，携带有 lazy.brown.fox 的消息会投递给第二个队列。携带有 lazy.pink.rabbit 的消息只会被投递给第二个队列一次，即使它同时匹配第二个队列的两个绑定。携带着 quick.brown.fox 的消息不会投递给任何一个队列。 如果我们违反约定，发送了一个携带有一个单词或者四个单词（\"orange\" or \"quick.orange.male.rabbit\"）的消息时，发送的消息不会投递给任何一个队列，而且会丢失掉。 但是另一方面，即使 \"lazy.orange.male.rabbit\" 有四个单词，他还是会匹配最后一个绑定，并且被投递到第二个队列中。 Topic交换机 Topic交换机是很强大的，它可以表现出跟其他交换机类似的行为 当一个队列的binding key为 \"#\"（井号） 的时候，这个队列将会无视消息的routing key，接收所有的消息。 当 * (星号) 和 # (井号) 这两个特殊字符都未在binding key中出现的时候，此时Topic交换机就拥有的direct交换机的行为。 代码整合 接下来我们会将Topic交换机应用到我们的日志系统中。在开始工作前，我们假设日志的routing key由两个单词组成，routing key看起来是这样的：. 代码跟上一篇教程差不多。 emit_log_topic.go的代码： package main import ( \"log\" \"os\" \"strings\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func main() { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() err = ch.ExchangeDeclare( \"logs_topic\", // name \"topic\", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare an exchange\") body := bodyFrom(os.Args) err = ch.Publish( \"logs_topic\", // exchange severityFrom(os.Args), // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", Body: []byte(body), }) failOnError(err, \"Failed to publish a message\") log.Printf(\" [x] Sent %s\", body) } func bodyFrom(args []string) string { var s string if (len(args) receive_logs_topic.go的代码： package main import ( \"log\" \"os\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func main() { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() err = ch.ExchangeDeclare( \"logs_topic\", // name \"topic\", // type true, // durable false, // auto-deleted false, // internal false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare an exchange\") q, err := ch.QueueDeclare( \"\", // name false, // durable false, // delete when usused true, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") if len(os.Args) 执行下边命令 接收所有日志： go run receive_logs_topic.go \"#\" 执行下边命令 接收来自”kern“设备的日志： go run receive_logs_topic.go \"kern.*\" 执行下边命令 只接收严重程度为”critical“的日志： go run receive_logs_topic.go \"*.critical\" 执行下边命令 建立多个绑定： go run receive_logs_topic.go \"kern.*\" \"*.critical\" 执行下边命令 发送路由键为 \"kern.critical\" 的日志： go run emit_log_topic.go \"kern.critical\" \"A critical kernel error\" 执行上边命令试试看效果吧。另外，上边代码不会对路由键和绑定键做任何假设，所以你可以在命令中使用超过两个路由键参数。 如果你现在还没被搞晕，想想下边问题: 绑定键为 * 的队列会取到一个routing key为空的消息吗？ 绑定键为 #.* 的队列会获取到一个名为..的路由键的消息吗？它会取到一个routing key为单个单词的消息吗？ a.*.# 和 a.#的区别在哪儿？ （完整代码参见emit_logs_topic.go and receive_logs_topic.go) "},"tutorials_with_golang/[6]RPC.html":{"url":"tutorials_with_golang/[6]RPC.html","title":"远程过程调用","keywords":"","body":" 原文：RPC状态：待校对翻译：Bingjian-Zhu校对： 远程过程调用（RPC） （使用Go客户端） 在第二篇教程中我们介绍了如何使用工作队列（work queue）在多个工作者（woker）中间分发耗时的任务。 可是如果我们需要将一个函数运行在远程计算机上并且等待从那儿获取结果时，该怎么办呢？这就是另外的故事了。这种模式通常被称为远程过程调用（Remote Procedure Call）或者RPC。 这篇教程中，我们会使用RabbitMQ来构建一个RPC系统：包含一个客户端和一个RPC服务器。现在的情况是，我们没有一个值得被分发的足够耗时的任务，所以接下来，我们会创建一个模拟RPC服务来返回斐波那契数列。 关于RPC的注意事项： 尽管RPC在计算领域是一个常用模式，但它也经常被诟病。当一个问题被抛出的时候，程序员往往意识不到这到底是由本地调用还是由较慢的RPC调用引起的。同样的困惑还来自于系统的不可预测性和给调试工作带来的不必要的复杂性。跟软件精简不同的是，滥用RPC会导致不可维护的. 考虑到这一点，牢记以下建议： 确保能够明确的搞清楚哪个函数是本地调用的，哪个函数是远程调用的。给你的系统编写文档。保持各个组件间的依赖明确。处理错误案例。明了客户端该如何处理RPC服务器的宕机和长时间无响应情况。 当对避免使用RPC有疑问的时候。如果可以的话，你应该尽量使用异步管道来代替RPC类的阻塞。结果被异步地推送到下一个计算场景。 回调队列 一般来说通过RabbitMQ来实现RPC是很容易的。一个客户端发送请求信息，服务器端将其应用到一个回复信息中。为了接收到回复信息，客户端需要在发送请求的时候同时发送一个回调队列callback queue的地址。我们试试看： q, err := ch.QueueDeclare( \"\", // name false, // durable false, // delete when usused true, // exclusive false, // noWait nil, // arguments ) err = ch.Publish( \"\", // exchange \"rpc_queue\", // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", CorrelationId: corrId, ReplyTo: q.Name, Body: []byte(strconv.Itoa(n)), }) 消息属性 AMQP协议给消息预定义了一系列的14个属性。大多数属性很少会用到，除了以下几个： persistent（持久性）：将消息标记为持久性（值为true）或瞬态（false）。第二篇教程中有说明这个属性。 content_type（内容类型）:用来描述编码的mime-type。例如在实际使用中常常使用application/json来描述JOSN编码类型。 reply_to（回复目标）：通常用来命名回调队列。 correlation_id（关联标识）：用来将RPC的响应和请求关联起来。 关联标识 上边介绍的方法中，我们建议给每一个RPC请求新建一个回调队列。这不是一个高效的做法，幸好这儿有一个更好的办法 —— 我们可以为每个客户端只建立一个独立的回调队列。 这就带来一个新问题，当此队列接收到一个响应的时候它无法辨别出这个响应是属于哪个请求的。correlation\\_id 就是为了解决这个问题而来的。我们给每个请求设置一个独一无二的值。稍后，当我们从回调队列中接收到一个消息的时候，我们就可以查看这条属性从而将响应和请求匹配起来。如果我们接手到的消息的correlation\\_id是未知的，那就直接销毁掉它，因为它不属于我们的任何一条请求。 你也许会问，为什么我们接收到未知消息的时候不抛出一个错误，而是要将它忽略掉？这是为了解决服务器端有可能发生的竞争情况。尽管可能性不大，但RPC服务器还是有可能在已将应答发送给我们但还未将确认消息发送给请求的情况下死掉。如果这种情况发生，RPC在重启后会重新处理请求。这就是为什么我们必须在客户端优雅的处理重复响应，同时RPC也需要尽可能保持幂等性。 总结 我们的RPC如此工作: 当客户端启动的时候，它创建一个匿名独享的回调队列。 在RPC中，客户端发送带有两个属性的消息：一个是设置回调队列的 reply_to 属性，另一个是设置唯一值的 correlation_id 属性。 将请求发送到一个 rpc_queue 队列中。 RPC工作者（又名：服务器）等待请求发送到这个队列中来。当请求出现的时候，它执行他的工作并且将带有执行结果的消息发送给reply_to字段指定的队列。 客户端等待回调队列里的数据。当有消息出现的时候，它会检查correlation_id属性。如果此属性的值与请求匹配，将它返回给应用。 代码整合 斐波那列函数： func fib(n int) int { if n == 0 { return 0 } else if n == 1 { return 1 } else { return fib(n-1) + fib(n-2) } } 声明斐波那契函数，假定只有有效的正整数输入。 （不要指望这个函数能适用于大数字，它可能是最慢的递归实现）。 rpc_server.go代码： package main import ( \"log\" \"strconv\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func fib(n int) int { if n == 0 { return 0 } else if n == 1 { return 1 } else { return fib(n-1) + fib(n-2) } } func main() { conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") failOnError(err, \"Failed to connect to RabbitMQ\") defer conn.Close() ch, err := conn.Channel() failOnError(err, \"Failed to open a channel\") defer ch.Close() q, err := ch.QueueDeclare( \"rpc_queue\", // name false, // durable false, // delete when usused false, // exclusive false, // no-wait nil, // arguments ) failOnError(err, \"Failed to declare a queue\") err = ch.Qos( 1, // prefetch count 0, // prefetch size false, // global ) failOnError(err, \"Failed to set QoS\") msgs, err := ch.Consume( q.Name, // queue \"\", // consumer false, // auto-ack false, // exclusive false, // no-local false, // no-wait nil, // args ) failOnError(err, \"Failed to register a consumer\") forever := make(chan bool) go func() { for d := range msgs { n, err := strconv.Atoi(string(d.Body)) failOnError(err, \"Failed to convert body to integer\") log.Printf(\" [.] fib(%d)\", n) response := fib(n) err = ch.Publish( \"\", // exchange d.ReplyTo, // routing key false, // mandatory false, // immediate amqp.Publishing{ ContentType: \"text/plain\", CorrelationId: d.CorrelationId, Body: []byte(strconv.Itoa(response)), }) failOnError(err, \"Failed to publish a message\") d.Ack(false) } }() log.Printf(\" [*] Awaiting RPC requests\") 服务器端代码相当简单： 像往常一样，我们建立连接，声明队列 为了在多个服务器上平均分配负载，我们希望运行多个服务器进程，需要在通道上设置prefetch 我们为 basic_consume 声明了一个回调函数，这是RPC服务器端的核心。它执行实际的操作并且作出响应。 我们使用Channel.Consume来获取接收消息的队列的go频道。然后使用goroutine来处理并作出回应 rpc_client.go 代码: package main import ( \"log\" \"math/rand\" \"os\" \"strconv\" \"strings\" \"time\" \"github.com/streadway/amqp\" ) func failOnError(err error, msg string) { if err != nil { log.Fatalf(\"%s: %s\", msg, err) } } func randomString(l int) string { bytes := make([]byte, l) for i := 0; i （完整的rpc_client.go 和 rpc_server.go代码) 我们的RPC服务已经准备就绪了，现在启动服务器端： go run rpc_server.go # => [x] Awaiting RPC requests 运行客户端，请求一个fibonacci队列。 go run rpc_client.go 30 # => [x] Requesting fib(30) 此处呈现的设计并不是实现RPC服务的唯一方式，但是他有一些重要的优势： 如果RPC服务器运行的过慢的时候，你可以通过运行另外一个服务器端轻松扩展它。试试在控制台中运行第二个 rpc_server.go 在客户端，RPC请求只发送或接收一条消息。不需要像 queue_declare 这样的异步调用。所以RPC客户端的单个请求只需要一个网络往返。 我们的代码依旧非常简单，而且没有试图去解决一些复杂（但是重要）的问题，如： 当没有服务器运行时，客户端如何作出反映。 客户端是否需要实现类似RPC超时的东西。 如果服务器发生故障，并且抛出异常，应该被转发到客户端吗？ 在处理前，防止混入无效的信息（例如检查边界） 如果你想做一些实验，你会发现management UI 在观测队列方面是很有用处的 "}}